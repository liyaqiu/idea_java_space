常用命令:
  命令网址:
    - https://try.redis.io/
    - http://doc.redisfans.com/
    - https://redis.com.cn/documentation.html
    - http://www.redis.cn/commands.html
    - https://redis.io/commands/
  命令禁用或改名: "
    rename-command KEYS ''
    rename-command FLUSHDB ''
    rename-command FLUSHALL ''
  "
  命令:
    基本命令: "
      帮助文档 
        help [@string | @list | @hash | @Set | Sorted-Set]
      查询所有
        KEY keys *
      查看key数据类型 
        TYPE k1
      根据参数名查看配置
        CONFIG GET [dir|dbfilename|参数名]
      清空当前数据库所有数据
        FLUSHDB
      情况所有数据库所有数据
        FLUSHALL
      查看某一个库下面的数据总量
        DBSIZE
      删除
        DEL k1 (同步)
        UNLINK k1 (异步)
  "
    遍历命令: "
      0为游标号，根据返回的游标继续往下执行，可以查找所有类型的key
        SCAN 0 MATCH * COUNT 2 
      只对某一个Set类型的值进行查找，0为游标号，根据返回的游标继续往下执行
        SSCAN s1 0 MATCH * count 2
      只对某一个Hash类型的值进行查找，0为游标号，根据返回的游标继续往下执行
        HSCAN h1 0 MATCH * COUNT 2
      只对某一个Sort-Set类型的值进行查找，0为游标号，根据返回的游标继续往下执行
        ZSCAN z1 0 MATCH *  COUNT 2
    "
bigkey:
  概述: 大于10kb或者大于5000个元素
  查找bigkey: "
    查找bigkey
      redis-cli -h 192.168.88.11  -a 123456 -p 7771 -n 1 --bigkeys
    统计bigkey占用字节数
      redis-cli -h 192.168.88.11  -a 123456 -p 7771 -n 1 MEMORY USAGE k1
  "
  bigkey删除:
    概述:
      - 字符串可以使用del或者unlink删除
      - 其他类型则使用sscan hscan zscan进行渐进性删除(先把内容情况，在使用del进行删除)
  惰性删除(异步处理): "
    lazyfree-lazy-eviction no
    lazyfree-lazy-expire no
    lazyfree-lazy-server-del yes 更改后del编译异步删除
    replica-lazy-flush yes
    lazyfree-lazy-user-del yes
  "
双写一致性:
  概述:
    - 先写MYSQL，给redis缓存设置过期时间，可以保证最终一致性
    - "
      我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。
      也就是说如果数据库写入成哥，缓存更新失败，那么只要达到过期时间，则后面的读请求自然会从数据库
      中读取最新值然后回填redis缓存，达到双写最终一致性。
    "
  方案1:
    读策略: 双检锁实现读操作同步
    写策略: 先更新mysql，在删除redis（会读到一部分没更新前的数据）
  方案2: 利用canal来监听binlog（会读到一部分没更新前的数据，实时性较高）
布隆过滤器(bitmap):
  概述:
    - 布隆过滤器实际上是一个很长的二进制位数组，利用N个hash函数做值(key)的运算，得出的hash值存储于二进制位数组中
    - 用redis的bitmap来实现布隆过滤器，因为bitmap用位存储，所以占用空间较小
    - 一般情况下，布隆过滤器不允许删，会出现误删(hash冲突导致的每个位可能存在多条记录)
  hash冲突: "
    Aa 和 BB hash值为2112
    柳柴 和 柴柕 hash值为851553
  "
  结论:
    - 当集合中有，可能有(hash冲突导致的)
    - 当集合中无，一定无
  案例:
    - 判断某个网址是否在黑名单
    - 判断某个用户是否在，如果存在则可以进一步跑逻辑程序，否则直接返回
    - 可以解决缓存透传问题
  缺点: 布隆过滤器预热(初始化布隆过滤器麻烦)
缓存穿透:
  概述:
    - "
      一般情况下，先查询缓存redis是否有该记录，缓存中没有时，在查询数据库。
      当数据库也不存在该记录时，每次查询都要访问数据库，这就是缓存穿透。
      
      缓存穿透带解决的问题是，当有大量请求查询数据库不存在的记录时，就会给数据库带来压力，甚至会拖垮数据库
    "
  解决缓存穿透: 利用布隆过滤器
  产生原因: 恶意攻击
缓存击穿:
  概述: "
    大量的请求同时查询一个热点key时，此时这个热点key正在做数据切换，就会导致大量的请求都请求到数据库上
  "
  解决方案1(推荐): "
      可以利用A和B两个缓存，做到无缝切换热点key数据
              查询，先A后B
              删除，先B后A
    "
  解决方案2: 使用双检锁实现，降低MYSQL查询频率
  产生原因: 热点key失效
Lua脚本:
  概述: Redis调用Lua脚本通过Eval命令保证代码执行的原子性
  案例:
    案例1: "
      井号替换成双引号
      语法 EVAL script numkeys [key [key ...]] [arg [arg ...]]
      
      入门
        EVAL # return 'hello-world' # 0 
      0个key，0个参数  
        EVAL # redis.call('set','k1','v1') return redis.call('get','k1')  # 0 
      2个key，0个参数  
        EVAL # redis.call('set',KEYS[1],'v1') return redis.call('get',KEYS[2])  # 2 k1 k1
      1个key，1个参数  
        EVAL # redis.call('set',KEYS[1],'v1') return redis.call('get',ARGV[1])  # 1 k1 k1
      0个key，2个参数  
        EVAL # redis.call('set',ARGV[1],'v1') return redis.call('get',ARGV[2])  # 0 k1 k1
    "
    案例2(*): "
      井号替换成双引号
      语法 EVAL script numkeys [key [key ...]] [arg [arg ...]]
        利用lua来做原子删除命令
          EVAL #
          if redis.call('get',KEYS[1]) == ARGV[1] then
            return redis.call('del',KEYS[1])
          else
            return 0
          end
          # 1 k1 v1
          
          EVAL # if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end # 1 k1 v1
    "
RedLock(redission):
  概述:
    - https://redis.io/docs/manual/patterns/distributed-locks/
    - https://github.com/redisson/redisson
    - https://redisson.org/
    - https://github.com/redisson/redisson/wiki/8.-distributed-locks-and-synchronizers 分布式锁介绍
    - https://zhuanlan.zhihu.com/p/374732293 比较好的博客
    - https://blog.csdn.net/weixin_47533244/article/details/131391276 参考案例
  机器部署台数: N台机器  = 2X（宕机多少台还能正常运行） + 1
  设计理念: "
    设理该方案也是基于 (set 加锁、Lua 脚本解锁)进行改良的，所以redis之父antirez 只描述了差异的地方，大致方案如下假设我们有N个Redis主节点，
    例如 N = 5这些节点是完全独立的，我们不使用复制或任何其他隐式协调系统为了取到锁客户端执行以下操作:
    
      1.获取当前时间，以毫秒为单位。
      2.依次尝试从5个实例，使用相同的 key 和随机值(例如 UUID)获取锁。当向Redis 请求获取锁时，
        客户端应该设置一个超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为 10 秒，
        则超时时间应该在 5-50 毫秒之间。这样可以防止客户端在试图与一个宕机的 Redis 节点对话时长时间处于阻塞状态。
        如果一个实例不可用，客户端应该尽快尝试去另外个 Redis 实例请求获取锁。
      3.客户端通过当前时间减去步骤 1 记录的时间来计算获取锁使用的时间。当且仅当从大多数(N/2+1，这里是 3 个节点)的Redis 节点都取到锁，
        并且获取锁使用的时间小于锁失效时间时，锁才算获取成功。
      4.如果取到了锁，其真正有效时间等于初始有效时间减去获取锁所使用的时间(步骤 3 计算的结果)。
      5.如果由于某些原因未能获得锁(无法在至少 N/2 +1 Redis 实例获取锁、或获取锁的时间超过了有效时间》，
        客户端应该在所有的 Redis 实例上进行解锁(即便某些Redis实例根本就没有加锁成功，
        防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁)。
    
    该方案为了解决数据不一致的问题，直接舍弃了异步复制只使用 master 节点，同时由于舍弃了 slave，为了保证可用性，引入了 N 个节点，官方建议是 5。
    客户端只有在满足下面的这两个条件时，才能认为是加锁成功。
      条件1:客户端从超过半数(大于等于N/2+1) 的Redis实例上成功获取到了锁
      条件2:客户端获取锁的总耗时没有超过锁的有效时间。
  "
  Redlock实现: "
    antirez提出的redlock算法大概是这样的:
      在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。
      我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，
      同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。
    为了取到锁，客户端应该执行以下操作:
      1.获取当前Unix时间，以毫秒为单位
      2.依次尝试从5个实例，使用相同的key和具有唯一性的value (例如UUID)获取锁。
        当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。
        例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。
        如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。
      3.客户端使用当前时间减去开始获取锁时间 (步骤1记录的时间)就得到获取锁使用的时间
        当且仅当从大多数(N/2+1，这里是3个节点)的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。
      4.如果取到了锁，kev的真正有效时间等于有效时间减去获取锁所使用的时间 (步骤3计算的结)
      5.如果因为某些原因，获取锁失败 (没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间)，
        客户端应该在所有的Redis实例上进行解锁(即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁
        但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁)。
  "
  总结: "
    这个锁的算法实现了多redis实例的情况，相对于单redis节点来说，优点在于 防止了 单节点故障造成整个服务停止运行的情况且在多节点中锁的设计，及多节点同时崩溃等各种意外情况有自己独特的设计方法。
    Redisson 分布式锁支持 Mu tiLocK 机制可以将多个锁合并为一个大锁，对一个大锁进行统一的申请加锁以及释放锁。
    
    最低保证分布式锁的有效性及安全性的要求如下:
      1.瓦斥:任何时刻只能有一个client获取锁
      2.释放死锁:即使锁定资源的服务崩溃或者分区，仍然能释放锁
      3.容错性;只要多数redis节点(一半以上) 在使用，client就可以获取和释放锁
      
    网上讲的基于故障转移实现的redis主从无法真正实现Redlock:
      因为redis在进行主从复制时是异步完成的，比如在clientA获取锁后，主redis复制数据到从redis过程中崩溃了，
      导致没有复制到从redis中，然后从redis选举出一个升级为主redis,造成新的主redis没有clientA 设置的锁，
      这是clientB尝试获取锁，并且能够成功获取锁，导致互斥失效
  "
缓存驱逐策略:
  概述: CONFIG GET xxx
  内存相关: "
      maxmemory 1024  设置内存最大值(单位字节)，默认为0（无限大）
      INFO MEMORY 查看内存使用情况
  "
  过期键的删除策略:
    立即删除: "
      1.立即删除是指，在设置键的过期时间时，创建一个回调事件，当过期时间达到时，由时间处理器自动执行键的删除操作。
      2.立即删除能保证内存中数据的最大新鲜度，因为它保证过期键值会在过期后马上被删除，其所占用的内存也会随之释放。但是立即删除对cpu是最不友好的。因为删除操作会占用cpu的时间，如果刚好碰上了cpu正在做排序等计算的时候，就会给cpu造成额外的压力。
      3.而且目前redis事件处理器对时间事件的处理方式--无序链表，查找一个key的时间复杂度为O(n)，所以并不适合用来处理大量的时间事件。
    "
    惰性删除: "
      1.惰性删除是指，某个键值过期后，此键值不会马上被删除，而是等到下次被使用的时候，才会被检查到过期，此时才能得到删除。所以惰性删除的缺点很明显：浪费内存。
      2.举个例子，对于一些按时间点来更新的数据，比如log日志，过期后在很长的一段时间内可能都得不到访问，这样在这段时间内就要浪费这么多内存来存log。
      redis开启惰性驱逐，lazyfree-lazy-eviction yes
    "
    定时删除: "
      1.从上面分析来看，立即删除会短时间内占用大量cpu，惰性删除会在一段时间内浪费内存，所以定时删除是一个折中的办法。
      2.定时删除是指：每隔一段时间执行一次删除操作，并通过限制删除操作执行的时长和频率，来减少删除操作对cpu的影响。另一方面定时删除也有效的减少了因惰性删除带来的内存浪费。
    "
  reids的8种缓存驱逐策略:
    概述:
      配置更改: maxmemory-policy noeviction
      LRU（淘汰长时间未被使用的）: 最近最少使用页面置换算法淘汰最长时间未被使用的页面，在页面最后一次被使用到发生调度的时间长短，淘汰最长时间未被使用的页面。
      LFU（淘汰时间范围内访问次数较少的）: 最近最不常用页面置换算法，淘汰一定时期内被访问次数最少的页，在一定时间段内页面被使用的频率，淘汰一定时期内被访问次数最少的页。
    策略:
      1.noeviction(默认): 不会驱逐任何key，表示即使内存达到上限也不进行置换，所有能引起内存增加的命令都会返回error
      2.allkeys-lru(推荐): 对所有key使用LRU算法进行删除，优先删除掉最近最不经常使用的key，用以保存新数据
      3.volatile-lru: 对所有设置了过期时间的key使用LRU算法进行删除
      4.allkeys-random: 对所有key随机删除
      5.volatile-random: 对所有设置了过期时间的key随机删除
      6.volatile-ttl: 删除马上要过期的key
      7.allkeys-lfu: 对所有key使用LFU算法进行删除
      8.volatile-lfu: 对所有设置了过期时间的key使用LFU算法进行删除
    总结: "
      1.在所有的 key 都是最近最经常使用，那么就需要选择allkeys-lru 进行置换最近最不经常使用的key，如果你不确定使用哪种策略，那么推荐使用 allkeys-lru
      2.如果所有的 key的访问概率都是差不多的，那么可以选用allkeys-random策略去置换数据
      3.如果对数据有足够的了解，能够为 key 指定 hint (通过expire/ttl指定)，那么可以选择 volatile-ttl进行置换
    "


