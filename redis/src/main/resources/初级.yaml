介绍:
  - 性能极高，Redis能读的速度是110000次/秒，写的速度是81000次/秒
  - Redis数据类型丰富，不仅支持简单的key-value类型的数据，同时还是提供list，set，zset，hash等数据结构的存储
  - Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用
  - Redis支持数据的备份，即Master-Slave模式的数据备份
安装:
  下载:
    概述:
      - https://redis.io/download/#redis-downloads
      - https://download.redis.io/releases/ 下载第二位为偶数版本的
      - http://www.redis.cn/
      - https://redis.com.cn/documentation.html
  安装&启动: "
    1编译(需要安装gcc)
      cd redis-7.0.14
      make && make install
      默认安装的路径为  /usr/local/bin/
        redis-benchmark 性能测试工具
        redis-check-aof 修复有问题的(RDB或AOF)文件
        redis-check-rdb 修复有问题的dump.rdb文件
        redis-sentinel 集群工具
        redis-cli 客户端连接工具
        redis-server 服务端启动
    2修改配置文件
      mkdir redis7 && cp redis-7.0.14/redis.conf redis7/
        daemonize yes 后台启动
        protected-mode no 取消保护模式
        bind 0.0.0.0 绑定ip
        requirepass 123456 设置密码
    3启动redis
      启动服务
        redis-server /root/redis7/redis.conf
      关闭服务
        redis-cli -h 192.168.88.11  -a 123456 -p 6379 shutdown
      连接服务
        redis-cli -h 192.168.88.11  -a 123456 -p 6379
        redis-cli -h 192.168.88.11  -a 123456 -p 6379 --raw  解决中文乱码
        redis-cli -h 192.168.88.11  -a 123456 -p 6379 -n 1  指定数据库索引
      查看redis版本
        redis-server --version
  "
10大数据类型(针对value类型):
  String字符串:
    概述:
      - 最大可以是512M
      - "
        增 set k1 eric
        查 get k1
        改 set k1 eric
        删 del k1
        异步删除 unlink k1
      "
  List列表:
    概述:
      - 你可以从头部或者尾部添加(底层是双向链表)
      - 最多可以包含40亿个
      - "
        增 RPUSH k1 1 2 3 4 5
        查 LRANGE k1 0 -1
        插入 LINSERT k1 BEFORE 1 newElement
        删 del k1
        删除 LREM k1 count element
        弹出 RPOP k1 count
        查询数量 LLEN k1
      "
  Hash哈希表:
    概述:
      - hash如同map，适合存储对象类型数据
      - 最多可以包含40亿个
      - "
        增 HSET k1 f1 f1v f2 f2v
        查 HGET k1 f1
        查所有key HKEYS k1
        差所有value HVALS k1
        改 HSET k1 f1 f1vv
        删 del k1
      "
  Set无序无重复集合:
    概述:
      - 最多可以包含40亿个
      - "
        增 SADD k1 1 2 3 4 5
        查所有 SMEMBERS k1
        查某一个是否存在 SISMEMBER k1 member
        删 del k1
        删除某个 SREM k1 member
        随机弹出，弹出元素会被删除 SPOP k1 [count]
        随机弹出，弹出元素不会被删除 SRANDMEMBER k1 [count]
        查询数量 SCARD k1
        差集 SDIFF k1 k2
        并集 SUNION k1 k2
        交集 SINTER k1 k2
      "
  Sorted-Set(ZSet)有序无重复集合:
    概述:
      - 最多可以包含40亿个
      - "
        增 ZADD k1 1 v1 2 v2 3 v3
        根据分数升序查 ZRANGE k1 0 -1
        根据分数倒叙查 ZREVRANGE k1 0 -1
        查询包含分数0.2和2 ZRANGEBYSCORE k1 0.2 2 WITHSCORES
        查询不包含分数0.2和2 ZRANGEBYSCORE k1 (0.2 (2 WITHSCORES
        修改某个值的分数 ZINCRBY k1 100 v1
        删 del k1
        删除某个 ZREM k1 v1
        查询数量 ZCARD k1
        弹出最大分数 ZPOPMAX k1 [count]
        弹出最小分数 ZPOPMAX k1 [count]
      "
  Stream流:
    概述:
      - redis5.0版本新增的数据结构
      - Stream主要用于消息队列，Redis本身是有一个发布订阅来实现消息队列的功能，但它有个缺陷就是消息无法持久化，如果出现网络断开，宕机等，消息就会被丢弃
      - Stream提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失
      - "
        队列操作命令
          查询队列数量
            XLEN k1
          从小到大查询
            XRANGE  k1  - + COUNT 3  
          指定ID删除
            XDEL k1 1701461441742-
          比次ID小的删除
            XTRIM  k1 MINID 1701461441742-0
          $以当前最新ID为界限，往后读取2条
            XREAD COUNT  2 STREAMS k1 $
          0/00/0-0/0000代表从最小的开始读，读取2条
            XREAD COUNT  2 STREAMS k1 0
          阻塞读取
            XREAD BLOCK 0 STREAMS k1 $
          查看队列的信息
            XINFO STREAM  k1
            XINFO STREAM  k1 FULL 查看详细
        生产者操作命令
          XADD k1 * id 11 name eric age 17 自动ID生成
          XADD k1 1701461441742-1 id 11 name eric age 17 手动指定ID
        消费者操作命令
          创建消费组
            XGROUP CREATE k1 g1 0 从最老的数据开始
            XGROUP CREATE k1 g1 $ 从最新的数据开始
          创建消费者
            XREADGROUP GROUP g1 consumer1 COUNT 1 STREAMS k1 > 从未读取过的记录开始
            XREADGROUP GROUP g1 consumer1 BLOCK 0  STREAMS k1 > 阻塞消费
          查看PENDING状态数据(读取，但未ACK的记录)
            XPENDING k1 g1 查看某一个消费组的消费情况
            XPENDING k1 g1 - + 100  consumer1 查看某一个消费组的消费者消费情况
          提交ACK确认
            XACK k1 g1  1701463286742-0 
      "
  GEO地理空间:
    概述:
      - 用于存储地理位置信息，并对存储的信息进行操作
      - 包括添加地理位置坐标，获取地理位置坐标，计算两个地理位置之间的距离，根据用户给定的经纬度坐标来获取指定范围内的地理位置集合
      - "
        添加 GEOADD k1 116.403963 39.915115 天安门 116.403414 39.924091 故宫
        查看 GEOPOS k1 天安门
        计算2个坐标之间的距离 GEODIST k1 天安门 故宫 M
        查找某个位置10公里内的 GEORADIUS k1 116.418017 39.914402 10 km WITHDIST WITHHASH WITHCOORD COUNT 10 DESC
        根据名字查找10公里内的 GEORADIUSBYMEMBER k1 天安门 10 km WITHDIST WITHHASH WITHCOORD COUNT 10 ASC
      "
  HyperLogLog基数统计:
    概述:
      - 在输入元素数量或者体积非常大，计算基数所需空间总是固定且很小
      - 每个HyperLogLog键只需要花费12KB内存，就可以计算接近2^64个不同元素的基数
      - HyperLogLog做基数去重统计，但是集合不返回具体元素
      - "
        增 PFADD K1 1 2 3 4 4 5
        统计个数 PFCOUNT K1
        对多个合并 PFMERGE mk k1 k2
      "
  Bitmap位图:
    概述:
      -
      - 用String类型作为底层数据结构实现的一种统计二值状态的数据类型
      - 位图本质是数组，它是机遇String类型的按位的操作。该数组由多个二进制位组成，每个二进制位都对应一个偏移量(称之为一个索引)
      - "
        增 SETBIT k1 20 1
        改 SETBIT k1 20 0
        统计一共设置多少次1 BITCOUNT k1
        统计一共有多少字节 STRLEN k1
      "
  Bitfield位域:
    概述:
      - 可以一次性操作多个比特位域(连续的多个比特位)，它会执行一系列操作并返回一个响应数组，这个数组中的元素对应参数列表中的响应操作的执行结果
      - "
        SET k1 hello
        BITFIELD k1 SET i8 8 120  对无符号8位操作，从第8位开始，设置为120
        BITFIELD k1 GET i8 8
        GET k1
      "
持久化:
  RDB与AOF同时开启的时候: 优先加载AOF文件
  RDB(Redis DataBase):
    概述:
      - RDB持久化以指定的时间间隔执行数据集的时间点快照(在时间范围内数据变化的频率触发快照)
    RDB快照策略: "
      Redis6.0.16以下
        save 900 1
        save 300 10
        save 60 1000
      Redis6.2及Redis-7.0.0
        3600秒(1小时)发生1次变化写一份dump.rdb文件
        300秒(5分钟)发生60次变化写一份dump.rdb文件
        60秒(1分钟)发生10000次变化写一份dump.rdb文件
        save 3600 1 300 100 60 10000
      修改持久化目录的路径
        dir ./
      修改文件名
        dbfilename dump.rdb
    "
    RDB文件恢复数据: "
      根据如下参数，把dump.rdb文件放入对应位置，重启redis既可以重新加载备份文件到内存中
        修改RDB快照文件的路径
          dir ./
        修改文件名
          dbfilename dump.rdb
    "
    自动触发备份: "
      自动触发，当操作满足以下任一条件，即可触发RDB备份
        save 3600 1 300 100 60 10000
    "
    手动触发备份:
      save(慎用): "
        同步执行，在主程序中执行会阻塞当前redis服务器，直到持久化工作完成执行save命令期间，redis不能处理其它命令，一般不用于线上
      "
      bgsave: "
        异步执行，redis会在后台异步进行快照操作，不阻塞快照同时还可以响应客户端请求，该触发方式会fork一个子进程由子进程复制持久化过程
      "
    查看最后一次备份时间: "
        LASTSAVE 
        date -d @1701474390
    "
    RDB文件修复: "
        redis-check-rdb ./dump.rdb
    "
    优点:
      - 适合大规模的数据恢复
      - 按照业务定时备份
      - 对数据完整性和一致性要求不高
      - RDB文件在内存中的加载速度要比AOF快得多，而且文件的占用体积可能会比AOP要小
    缺点:
      - "
        RDB会出现数据丢失问题
        save 3600 1 300 100 60 10000
        因为上面的保存策略的存在，如果突然宕机的情况下，RDB会丢失一次策略的数据
      "
      - 内存数据的全量同步，如果数据量太大会导致I/O严重影响服务器性能
      - RDB在fork内存的数据被克隆一份(占用更多的内存)
      - RDB依赖于主进程的fork，在更大的数据集中，这可能会导致服务器请求的瞬间延迟(可能会导致Redis停止为客户端服务几毫秒甚至1秒钟)。
    禁用RDB快照: "
      默认开始RDB，禁用RDB快照，把策略更改为空
        save ''
    "
  AOF(Append Only File):
    概述:
      - AOF以日志的形式来记录每个【写操作】，只允许追加文件，但不可以改写文件。
    AOF持久化过程: "
      Client作为命令的来源，会有多个源头以及源源不断的请求命令。
      在这些命令到达Redis Server 以后并不是直接写入AOF文件，会将其这些命令先放入AOF缓存中进行保存。这里的AOF缓冲区实际上是内存中的一片区域，存在的目的是当这些命令达到一定量以后再写入磁盘，避免频繁的磁盘IO操作。
      AOF缓冲会根据AOF缓冲区同步文件的【三种写回策】将命令写入磁盘上的AOF文件
      随着写入AOF内容的增加为避免文件膨胀，会根据规则进行命令的合并(又称AOF重写)，从而起到AOF文件压缩的目的。
      当Redis Server 服务器重启的时候会从AOF文件载入数据。
    "
    AOF开启: "
      1.关闭默认的RDB 
        save ''
      2.开启AOF
        appendonly yes 默认情况下redis只开启了RDB持久化
        dir ./ 修改持久化目录的路径
        appendfilename 'appendonly.aof' AOF文件名   
        appenddirname 'appendonlydir' AOF目录
        aof-use-rdb-preamble yes 是否开启AOF混合方式
    "
    AOF文件恢复数据: "
      根据如下参数，把aof目录或文件放入对应位置，重启redis既可以重新加载备份文件到内存中
        appendonly yes 默认情况下redis只开启了RDB持久化
        dir ./ 修改持久化目录的路径
        appendfilename 'appendonly.aof' AOF文件名   
        appenddirname 'appendonlydir' AOF目录
    "
    AOF策略: "
      同步写回，可靠性高，数据基本不丢失，每个写命令都要落磁盘，性能影响较大
        appendfsync always
      默认策略，每秒写回，性能适中，宕机时丢失1秒内的数据
        appendfsync everysec
      操作系统控制写会，性能最好，宕机时丢失数据较多
        appendfsync no
    "
    AOF文件修复: "
      直接给清单文件对所有文件修复，或者给某一个AOF文件
      redis-check-aof --fix  /root/appendonlydir/appendonly.aof.manifest
    "
    AOF重写机制:
      概述:
        - 由于AOF持久化是Redis不断将写命令记录到AOF文件中，随着Redis不断的进行，AOF的文件会越来越大，占用服务器磁盘也就越大， 以及AOF恢复时间越长。
        - 为了解决这个问题，Redis新增了AOF重写机制，当AOF文件的大小超过了所设定的阈值时，Redis就会自动启动AOF文件内容压缩，只保留可以恢复数据的最小指令集
      重写原理: "
        1.在重写开始前，redis会创建一个“重写子进程”，这个子进程会读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。
        2.与此同时，主进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。
        3.当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中
        4.当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中
        5.【重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据内容用命令的方式重写了一个新的aof文件，这点和RDB快照有点类似】
      "
      自动触发重写机制: "
        根据上次重写后的AOF文件大小，判断当前AOF的大小是否增长了1倍，并且AOF文件是否达到64mb
        auto-aof-rewrite-percentage 100
        auto-aof-rewrite-min-size 64mb
      "
      手动触发重写机制: 命令 BGREWRITEAOF
    AOF混合方式: "
      reids7
        混合方式文件 aof-use-rdb-preamble yes(默认)
          appendonly.aof.4.base.rdb（自动触发重写机制或手动触发重写机制，全量RDB记录方式）
          appendonly.aof.4.incr.aof（增量AOF记录方式）
          appendonly.aof.manifest
        非混合方式文件 aof-use-rdb-preamble no
          appendonly.aof.4.base.aof（自动触发重写机制或手动触发重写机制，全量AOF记录方式）
          appendonly.aof.4.incr.aof（增量AOF记录方式）
          appendonly.aof.manifest
    "
    优点:
      - 使用AOF Redis 更加持久，您可以有不同的 fsync 策略，根本不fsync、每秒fsync、每次查询时fsync。使用每秒fsync的默认策略，写入性能仍然很棒。fsync 是使用后台线程执行的，当没有 fsync正在进行时，主线程将努力执行写入，因此您只能丢失一秒钟的写入。
      - AOF日志是一个仅附加日志，因此不会出现寻道问题，也不会在断电时出现损坏问题。即使由于某种原因(磁盘已满或其他原因) 日志以写一半的命令结尾，redis-check-aof 工具也能够轻松修复它
      - 当AOF 变得太大时，Redis 能够在后台自动重写AOF。重写是完全安全的，因为当 Redis继续附加到旧文件时，会使用创建当前数据集所需的最少操作集生成一个全新的文件，一旦第二个文件准备就绪，Redis 就会切换两者并开始附加到新的那一个。
      - AOF 以易于理解和解析的格式依次包含所有操作的日志。您甚至可以轻松导出AOF 文件。例如，职使您不小心使用该FLUSHALL命令刷新了所有内容，只要在此期间没有执行日志重写，您仍然可以通过停止服务器、删除最新命令并重新启动 Redis 来保存您的数据集。
    缺点:
      - AOF文件通常比相同数据集的等效 RDB文件大。
      - 根据确切的fsync 策略，AOF 可能比RDB 慢一般来说，将fsync 设置为每秒性能仍然非常高，并且在禁用 fsync 的情况下，即使在高负载下它也应该与 RDB 一样快。即使在巨大的写入负载的情况下，RDB 仍然能够提供关于最大延迟的更多保证。
  RDB与AOF总结:
    - RDB体积小，恢复快，数据安全低
    - AOF体积大，恢复慢，数据安全高
  开启纯缓存模式: "
    虽然禁用了持久化，但是BGREWRITEAOF SAVE GBSAVE仍可以使用生成文件
    save '' 关闭RDB持久化
    appendonly no 关闭AOF持久化
  "
事务:
  概述:
    - 可以一次执行多个命令所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞
    - 一个队列中，一次性顺序性、排他性的执行一系列命令
    - Redis事务可以理解为多个命令仅仅只是进行一次批处理，而没有像传统数据库一样支持回滚
  事务流程:
    开启: MULTI，开启事务
    入队: CMD1 CMD2 CMD3，把命令添加入队列
    执行: EXEC 执行事务
  Redis事务 Vs 数据库事务: "
     1.单独的隔离操作，Redis的事务仅仅是保证事务里的操作会被连续独占的执行，redis命令执行是单线程架构，在执行完事务内所有指令前是不可能再去同时执行其他客户端的请求的
     2.没有隔离级别的概念，因为事务提交前任何指令都不会被实际执行，也就不存在【事务内的查询要看到事务里的更新，在事务外查询不能看到】这种问题了
     3.不保证原子性，Redis的事务不保证原子性，也就是不保证所有指令同时成功或同时失败，只有决定是否开始执行全部指令的能力，没有执行到一半进行回滚的能力
     4.排它性，Redis会保证一个事务内的命令依次执行，而不会被其它命令插入
    "
  案例1-成功执行: "
    MULTI
    SET k1 v1
    SET k2 v2
    EXEC
  "
  案例2-取消执行: "
      MULTI
      SET k1 v1
      SET k2 v2
      DISCARD
    "
  案例3-有语法错误-导致全部失败: "
      MULTI
      SET k1 v1
      SET k2 v2
      SET k3
      EXEC
    "
  案例4-没语法错误-导致部分失败: "
        MULTI
        SET k1 v1
        SET k2 v2
        INCR k1  --此语法会通过，但是执行会失败
        EXEC
      "
  案例5-watch: "
    1.在监控期间，如果一旦有人修改了事务内任何一个key的值，那么会导致整个事务失败
    2.使用UNWATCH或者EXEC都会取消监控
    3.WATCH和UNWATCH写在事务内无效
    
    WATCH k1
    UNWATCH k1  
    MULTI
      SET k1 v11
      SET k2 v22
    EXEC
    
  "
管道:
  概述:
    - redis pipeline 类似于 http1.0和http1.1的keeplive的概念
    - redis pipeline解决多次命令的反复请求和响应(RTT)，尽量在一次请求中处理多个命令
  案例: "
  创建命令
    vi cmd.txt
      HSET k2 f1 f1v f2 f2v
      SET k1 v1
  利用管道执行  
    cat cmd.txt  | redis-cli -h 192.168.88.11  -a 123456 -p 6379 --pipe
  "
发布订阅:
  概述:
    - "
      发布订阅可以使用Stream来代替，Stream的数据可以持久化，而pus/sub的数据不持久化
    "
  案例: "
     订阅 SUBSCRIBE c1 c2
     发布 PUBLISH c1 msg
     查看活跃的队列 PUBSUB CHANNELS
     查看队列有多少个订阅者 PUBSUB NUMSUB c1
     取消订阅c1队列 UNSUBSCRIBE c1
  "
主从复制集群(replica)(1主多从):
  概述:
    - 当master数据变化的时候，自动将新的数据异步同步到slave数据库
    - 主从复制，可以实现读写分离，容灾恢复，数据备份，水平扩容支撑高并发
  配置（以下配置没开始持久化）: "
    master
      dir  '/root/node1/'
      port 7771
      pidfile '/var/run/redis_7771.pid'
      logfile '/root/node1/redis.log'
      save ''
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
    slave 1
      dir  '/root/node2/'
      port 7772
      pidfile '/var/run/redis_7772.pid'
      logfile '/root/node2/redis.log'
      save ''
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      replicaof 192.168.88.11 7771
      masterauth 123456
    slave 2
      dir  '/root/node3/'
      port 7773
      pidfile '/var/run/redis_7773.pid'
      logfile '/root/node3/redis.log'
      save ''
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      replicaof 192.168.88.11 7771
      masterauth 123456
  "
  案例: "
    支持复制模式 
      主->多从
      主->即从即主->从
    
    配置redis.conf
      此案例为同一台机器进行，不同机器则不需要区分配置
      基本配置
        不同的
          dir  /root/node1/ 指定RDB或者AOF日志文件目录
          port 指定端口
          pidfile /var/run/redis_7771.pid 进行PID号
          logfile '/root/node1/redis.log' 日志文件，可以通过loglevel指定日志级别
        相同的
          save '' 禁用RDB
          appendonly no 禁用AOF
          protected-mode no 是否开启保护模式
          daemonize yes 后台启动
          bind 0.0.0.0 绑定ip
          requirepass 123456 设置密码
      主从复制配置，master不需要配置
        slave配置永久指定(跟mysql一样，从也可以作为主)
          replicaof 192.168.88.11 7771
          masterauth 123456
        slave配置临时指定(跟mysql一样，从也可以作为主)
          SLAVEOF 192.168.88.11 7771
          CONFIG SET masterauth 123456
    启动服务
      redis-server /root/node1/redis.conf --port 7771 &&
      redis-server /root/node2/redis.conf --port 7772 &&
      redis-server /root/node3/redis.conf --port 7773 
    关闭服务
      redis-cli -h 192.168.88.11  -a 123456 -p 7771 shutdown &&
      redis-cli -h 192.168.88.11  -a 123456 -p 7772 shutdown &&
      redis-cli -h 192.168.88.11  -a 123456 -p 7773 shutdown
    连接服务
      redis-cli -h 192.168.88.11  -a 123456 -p 7771
      redis-cli -h 192.168.88.11  -a 123456 -p 7772
      redis-cli -h 192.168.88.11  -a 123456 -p 7773
    查看主从信息
      INFO replication
    取消主从同步
      SLAVEOF NO ONE
      清空当前数据库所有数据
        FLUSHDB
      情况所有数据库所有数据
        FLUSHALL
  "
  工作原理: "
    slave启动，同步初请
      slave启动成功连接到master后会发送一个sync命令
      slave首次全新连接master,一次完全同步 (全量复制)将被自动执行，slave自身原有数据会被master数据覆盖清除
    首次连接，全量复制
      master节点收到sync命令后会开始在后台保存快照(即RDB持久化，主从复制时会触发RDB)，司时收集所有接收到的用于修改数据集命令缓得起来，master节点执行RDB持久化完后，master将rdb快照文件和所有缓存的命令发送到所有slave,以完成一全量同步
      而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中，从而完成复制初始化
    心跳持续，保持通信
      master发出PING包的周期，默认是10秒（参数 repl-ping-replica-period 10）
    进入平稳，增量复制
      master会检查backlog里面的offset，master和slave都会保存一个复制的offset还有一个masterId，offset是保存在backlog中的。Master只会把已经复制的offset后面的数据复制给Slave，类似断点续传
    从机下线，重连续传
      master继续将新的所有收集到的修改命令自动依次传给slave,完成同步（断点续传）
  "
  缺点:
    master宕机: 默认情况下，不会在slave节点中自动重选一个master，而slave只能读不允许写操作
    复制延时，信号衰减: 由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁亡的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题重加严重。
哨兵(sentinel)(动态切换的1主多从):
  概述:
    - 哨兵集群是用来监控redis主从复制集群，一旦主从复制集群的master宕机，哨兵集群会主从复制集群中选举出一个slave来当选master，从而保持主从复制集群的健壮性
    - "
      主从监控，监控主从复制redis集群运行是否正常
      消息通知，哨兵可以将故障转移的结果发送到客户端
      故障转移，如果master异常，则会进行主从切换，将其中一个slave作为新的master
      配置中心，客户端通过连接哨兵来获得当前redis服务的主节点地址
    "
  哨兵集群工作原理:
    概述:
      - 更改原有的sentinel.conf配置，以及更改redis.conf的配置，并且维护redis主从复制集群的关系
    主观下线&客观下线: "
        主观下线 转为 客观下线，最后由sentinel leader选取一个redis master

        主观下线(Subjective Down): sentinel down-after-milliseconds mymaster 30000
          主观下线是指单个哨兵节点认为一个特定的Redis节点（主节点、从节点或其他哨兵）不可用。主观下线是一种主观的判断，是基于单个哨兵节点的观察结果得出的。当一个哨兵无法连接到某个Redis节点，它会将该节点标记为主观下线。多个哨兵节点可能会对同一个节点发出主观下线标记。
        客观下线(Objective Down): sentinel monitor <master-name> <ip> <redis-port> <quorum>
          客观下线是指在整个哨兵集合中达成一致，认为某个特定的Redis节点不可用。客观下线是一种更客观的判断，需要多个哨兵节点共同达成一致。
          当多个哨兵节点都主观下线同一个Redis节点时，这个节点会被认为是客观下线。 
          quorum表示客观下线最少哨兵数量，意思就是，当你有3台哨兵机器的时候，法定人数那么配置为机器数量的一半加1(3/2+1 = 2)
          我们知道，网络是不可靠的，有时候一个sentinel会因为网络堵塞而误认为一个master已经死掉，在sentinel集群环境下需要多个sentinel相互沟通来确认某个master是否真的死掉
      "
    哨兵之间的选举: 通过RAFT算法来选出leader
  主从复制+哨兵集群步骤:
    1主从复制集群配置（以下配置没开始持久化）: "
      master mkdir /root/node1 && touch /root/node1/redis.conf
        vi /root/node1/redis.conf
        dir  '/root/node1/'
        port 7771
        pidfile '/var/run/redis_7771.pid'
        logfile '/root/node1/redis.log'
        save ''
        appendonly no
        protected-mode no
        daemonize yes
        bind 0.0.0.0
        requirepass 123456
        masterauth 123456 #将来有可能成为slave
      slave1 mkdir /root/node2 && touch /root/node2/redis.conf
        vi /root/node2/redis.conf
        dir  '/root/node2/'
        port 7772
        pidfile '/var/run/redis_7772.pid'
        logfile '/root/node2/redis.log'
        save ''
        appendonly no
        protected-mode no
        daemonize yes
        bind 0.0.0.0
        requirepass 123456
        replicaof 192.168.88.11 7771
        masterauth 123456
      slave2 mkdir /root/node3 && touch /root/node3/redis.conf
        vi /root/node3/redis.conf
        dir  '/root/node3/'
        port 7773
        pidfile '/var/run/redis_7773.pid'
        logfile '/root/node3/redis.log'
        save ''
        appendonly no
        protected-mode no
        daemonize yes
        bind 0.0.0.0
        requirepass 123456
        replicaof 192.168.88.11 7771
        masterauth 123456
      "
    2主从复制集群启动命令: "
      启动服务
        redis-server /root/node1/redis.conf --port 7771 &&
        redis-server /root/node2/redis.conf --port 7772 &&
        redis-server /root/node3/redis.conf --port 7773 
      关闭服务
        redis-cli -h 192.168.88.11  -a 123456 -p 7771 shutdown &&
        redis-cli -h 192.168.88.11  -a 123456 -p 7772 shutdown &&
        redis-cli -h 192.168.88.11  -a 123456 -p 7773 shutdown
      连接服务
        redis-cli -h 192.168.88.11  -a 123456 -p 7771
        redis-cli -h 192.168.88.11  -a 123456 -p 7772
        redis-cli -h 192.168.88.11  -a 123456 -p 7773
      查看主从信息
        INFO replication
      取消主从同步
        SLAVEOF NO ONE
        清空当前数据库所有数据
          FLUSHDB
        情况所有数据库所有数据
          FLUSHALL
    "
    3哨兵集群配置: "
      mkdir /root/sentinel1 && touch /root/sentinel1/sentinel.conf
        bind 0.0.0.0
        daemonize yes
        protected-mode no
        port 8881
        pidfile /var/run/redis-sentinel-8881.pid
        logfile /root/sentinel1/sentinel.log
        dir  /root/sentinel1  
        sentinel monitor mymaster 192.168.88.11 7771 2
        sentinel auth-pass mymaster 123456
      mkdir /root/sentinel2 && touch /root/sentinel2/sentinel.conf
        bind 0.0.0.0
        daemonize yes
        protected-mode no
        port 8882
        pidfile /var/run/redis-sentinel-8882.pid
        logfile /root/sentinel2/sentinel.log
        dir  /root/sentinel2
        sentinel monitor mymaster 192.168.88.11 7771 2
        sentinel auth-pass mymaster 123456
      mkdir /root/sentinel3 && touch /root/sentinel3/sentinel.conf
        bind 0.0.0.0
        daemonize yes
        protected-mode no
        port 8883
        pidfile /var/run/redis-sentinel-8883.pid
        logfile /root/sentinel3/sentinel.log
        dir  /root/sentinel3
        sentinel monitor mymaster 192.168.88.11 7771 2
        sentinel auth-pass mymaster 123456
    "
    4哨兵集群启动命令: "
      启动
        redis-sentinel /root/sentinel1/sentinel.conf --sentinel &&
        redis-sentinel /root/sentinel2/sentinel.conf --sentinel &&
        redis-sentinel /root/sentinel3/sentinel.conf --sentinel
      
      停止
        ps -ef | grep sentinel 
        kill 2659  
    "
  总结:
    - 哨兵节点的数量应为多个，哨兵本身应该是集群，保证高可用
    - 哨兵节点的数量应该是奇数(跟zookeeper一样，防止选举脑裂)
    - 各个哨兵节点的配置应该一致
  缺点: 哨兵集群+主从复制集群，并不能保证数据零丢失(在master宕机时，从slave中选取master过程中[假设5分钟切换成功]，会丢失部分之前访问原有master的请求)
集群(cluster)(动态切换的多主多从):
  概述:
    - redis分片集群支持多个master，每个master又可以挂载多个slave
    - 由于分片集群自带哨兵集群的故障转移机制，内置了高可用的支持，无需在使用哨兵功能
    - 客户端与redis的节点连接，不在需要连接集群中的所有的节点，只需要任意连接集群中的一个可用节点即可
    - 槽位slot负责分配到各个物理服务器服务节点，由对应的集群来负责维护节点、插槽和数据之间的关系
  分片算法:
    哈希取余:
      概述: 值 = hash(key) mod 节点数量，在根据值找到具体节点
      缺点: 不方便扩缩容(如果扩缩容需要对【全部数据】重新计算hash)，数据切斜问题
    一致性哈希取余:
      概述:
        - 因为hash是int类型的，所以hash范围是2^32-1
        - 值 = hash(key) mod (2^32-1)，在根据值顺时针找到具体节点
      一致性哈希算法3个步骤: "
        1.算法构建一致性哈希环
          利用hash范围是2^32-1构建哈希环
        2.服务器IP节点映射
          通过某种算法将机器落在哈希环上
        3.key落到服务器的规则
        存储key在哈希环上顺时针落地，往前走就是自己要存储的机器
      "
      缺点: 不方便扩缩容(如果扩缩容需要对【部分数据】重新计算hash)，数据切斜问题
    哈希槽(*):
      概述:
        - 节点与哈希槽绑定(16384个哈希槽)
        - 哈希槽位 = CRC16(key) mod 16384，在根据哈希槽位找到对应节点
      为什么使用16384个槽: "
        1.如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大
            因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了浪费带宽。
        2.redis的集群主节点数量基本不可能超过1000个
            集群节点越多，心跳包的消息体内携带的数据越多。如果dis cluster节点数量超过节点过1000个，也会导致网络拥堵。因此redis作者不建议re1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。
        3.槽位越小，节点少的情况下，压缩比高容易传输
            Redis主节点的配置信息中它所负责的哈希槽是通过一张itmap的形式来保存的，在传输过程中会对bitmap进行压缩但是如果bitmap的填充率slots/ N很高的话(N表示节点数)，bitmap的压缩率就低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。
      "
      优点: 方便扩缩容(如果扩缩容需要对【部分数据】重新计算slot)
      个人总结: "
        redis集群一共有16384个槽位（固定大小），然后分别将这些槽位一定的范围域分散到各个集群节点中。
        后续对数据的CRUD都通过算法(SLOT = CRC16(16) mod 16384)来操作，这样做的好处就是方面了后续的水平扩缩容
      "
  分片集群配置(关闭持久化): "
    至少需要6个节点，3主3从
      *** ERROR: Invalid configuration for cluster creation.
      *** Redis Cluster requires at least 3 master nodes.
      *** This is not possible with 4 nodes and 1 replicas per node.
      *** At least 6 nodes are required.
    
    mkdir /root/cluster1 && touch /root/cluster1/redis.conf &&
    mkdir /root/cluster2 && touch /root/cluster2/redis.conf &&
    mkdir /root/cluster3 && touch /root/cluster3/redis.conf &&
    mkdir /root/cluster4 && touch /root/cluster4/redis.conf &&
    mkdir /root/cluster5 && touch /root/cluster5/redis.conf &&
    mkdir /root/cluster6 && touch /root/cluster6/redis.conf 
    
    vi /root/cluster1/redis.conf
      dir  /root/cluster1
      port 7771
      pidfile /var/run/redis_7771.pid
      logfile /root/cluster1/redis.log
      save '' #改成双引号
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      masterauth 123456
      cluster-enabled yes
      cluster-config-file nodes-7771.conf
      cluster-node-timeout 15000
    
    vi /root/cluster2/redis.conf
      dir  /root/cluster2
      port 7772
      pidfile /var/run/redis_7772.pid
      logfile /root/cluster2/redis.log
      save '' #改成双引号
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      masterauth 123456
      cluster-enabled yes
      cluster-config-file nodes-7772.conf
      cluster-node-timeout 15000
      
    vi /root/cluster3/redis.conf
      dir  /root/cluster3
      port 7773
      pidfile /var/run/redis_7773.pid
      logfile /root/cluster3/redis.log
      save '' #改成双引号
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      masterauth 123456
      cluster-enabled yes
      cluster-config-file nodes-7773.conf
      cluster-node-timeout 15000
      
    vi /root/cluster4/redis.conf
      dir  /root/cluster4
      port 7774
      pidfile /var/run/redis_7774.pid
      logfile /root/cluster4/redis.log
      save '' #改成双引号
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      masterauth 123456
      cluster-enabled yes
      cluster-config-file nodes-7774.conf
      cluster-node-timeout 15000
      
    vi /root/cluster5/redis.conf
      dir  /root/cluster5
      port 7775
      pidfile /var/run/redis_7775.pid
      logfile /root/cluster5/redis.log
      save '' #改成双引号
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      masterauth 123456
      cluster-enabled yes
      cluster-config-file nodes-7775.conf
      cluster-node-timeout 15000
      
    vi /root/cluster6/redis.conf
      dir  /root/cluster6
      port 7776
      pidfile /var/run/redis_7776.pid
      logfile /root/cluster6/redis.log
      save '' #改成双引号
      appendonly no
      protected-mode no
      daemonize yes
      bind 0.0.0.0
      requirepass 123456
      masterauth 123456
      cluster-enabled yes
      cluster-config-file nodes-7776.conf
      cluster-node-timeout 15000
  "
  启动命令步骤: "
    1.启动服务
      redis-server /root/cluster1/redis.conf --port 7771 &&
      redis-server /root/cluster2/redis.conf --port 7772 &&
      redis-server /root/cluster3/redis.conf --port 7773 &&
      redis-server /root/cluster4/redis.conf --port 7774 &&
      redis-server /root/cluster5/redis.conf --port 7775 &&
      redis-server /root/cluster6/redis.conf --port 7776 
      
    2.组建集群，--cluster-replicas 1表示1个slave
      redis-cli -h 192.168.88.11  -a 123456 -p 7771 --cluster create --cluster-replicas 1 192.168.88.11:7771 192.168.88.11:7772 192.168.88.11:7773 192.168.88.11:7774 192.168.88.11:7775 192.168.88.11:7776
      
    3.查看集群状态
      方式1
        redis-cli -h 192.168.88.11  -a 123456 -p 7771 -c
          CLUSTER NODES  #查看集群的槽分配情况，以及集群master、slave关系
          INFO REPLICATION
          CLUSTER INFO
          CLUSTER KEYSLOT k1 #查看Key隶属于哪个哈希槽
          CLUSTER COUNTKEYSINSLOT 8157 #查看这个槽一共有多少个key(注意：需要用get k1去到本机器的槽才能查看到)
      方式2
        redis-cli -h 192.168.88.11  -a 123456  --cluster check 192.168.88.11:7771 #查看集群的槽分配情况，以及集群master、slave关系
        
    4.关闭服务，测试发现，只要3台master集群正常，反之集群异常(不能进行数据存储)
      redis-cli -h 192.168.88.11  -a 123456 -p 7772 shutdown
    
    5.数据存储命令 -c代表以集群方式进行连接
      redis-cli -h 192.168.88.11  -a 123456 -p 7774 -c
        set k1 v1 存储数据
        get k1 获取数据
  "
  手动主从切换调整:
    概述: 让某一个slave机器切换成master
    操作: "
      1.登陆想让salve变为master的机器
        redis-cli -h 192.168.88.11  -a 123456 -p 7774
      2.查看集群关系
        CLUSTER NODES
      3.将slave切换成master
        CLUSTER FAILOVER
    "
  集群扩缩容及从新分配插槽:
    扩容(1主1从):
      步骤:
        1master配置: "
          1.master配置
            mkdir /root/cluster7 && touch /root/cluster7/redis.conf
            vi /root/cluster7/redis.conf
              dir  /root/cluster7
              port 7777
              pidfile /var/run/redis_7777.pid
              logfile /root/cluster7/redis.log
              save '' #改成双引号
              appendonly no
              protected-mode no
              daemonize yes
              bind 0.0.0.0
              requirepass 123456
              masterauth 123456
              cluster-enabled yes
              cluster-config-file nodes-7777.conf
              cluster-node-timeout 15000
          2.启动
            redis-server /root/cluster7/redis.conf --port 7777
          3.加入集群命令
            redis-cli -a 123456 --cluster add-node 需要加入机器地址  集群机器地址
            redis-cli -a 123456 --cluster add-node 192.168.88.11:7777 192.168.88.11:7771
          4.查看集群状态
            方式1
              redis-cli -h 192.168.88.11  -a 123456 -p 7771
                CLUSTER NODES  #查看集群的槽分配情况，以及集群master、slave关系
                INFO REPLICATION
                CLUSTER INFO
                CLUSTER KEYSLOT k1 #查看Key隶属于哪个哈希槽
            方式2
              redis-cli -h 192.168.88.11  -a 123456  --cluster check 192.168.88.11:7771 #查看集群的槽分配情况，以及集群master、slave关系
          5.重新分片，一般按照机器数量平均分 16384/4 = 4096
            redis-cli -a 123456 --cluster reshard 192.168.88.11:7771
              方式1，从所有master的槽分配一部分到新的master
                How many slots do you want to move (from 1 to 16384)? 4096
                What is the receiving node ID? 1be96b44d3ad81bc7d991567084632c18fcc4416 #目标机器
                Source node #1: all
              方式2，从指定的master的槽分配一部分到新的master
                How many slots do you want to move (from 1 to 16384)? 4096
                What is the receiving node ID? 1be96b44d3ad81bc7d991567084632c18fcc4416 #目标机器
                Source node #1: 55cde4d14338c7efde81c684aa9fc1fe9ebd77d9
                Source node #2: 6e72a779ffac1f1277d7c13aab3a880c761c1e03
                Source node #3: done
      "
        2slave配置: "
          1.slave配置 
            mkdir /root/cluster8 && touch /root/cluster8/redis.conf 
            vi /root/cluster8/redis.conf
              dir  /root/cluster8
              port 7778
              pidfile /var/run/redis_7778.pid
              logfile /root/cluster8/redis.log
              save '' #改成双引号
              appendonly no
              protected-mode no
              daemonize yes
              bind 0.0.0.0
              requirepass 123456
              masterauth 123456
              cluster-enabled yes
              cluster-config-file nodes-7778.conf
              cluster-node-timeout 15000
          2.启动
            redis-server /root/cluster8/redis.conf --port 7778
          3.加入到主节点，成为slave
            redis-cli -a 123456 --cluster add-node 需要加入机器地址  集群机器地址 --cluster-slave --cluster-master-id masterID号
            redis-cli -a 123456 --cluster add-node 192.168.88.11:7778 192.168.88.11:7771 --cluster-slave --cluster-master-id 1be96b44d3ad81bc7d991567084632c18fcc4416
          4.查看集群状态
          方式1
            redis-cli -h 192.168.88.11  -a 123456 -p 7771
              CLUSTER NODES  #查看集群的槽分配情况，以及集群master、slave关系
              INFO REPLICATION
              CLUSTER INFO
              CLUSTER KEYSLOT k1 #查看Key隶属于哪个哈希槽
          方式2
            redis-cli -h 192.168.88.11  -a 123456  --cluster check 192.168.88.11:7771 #查看集群的槽分配情况，以及集群master、slave关系
        "
    缩容(1主1从):
      步骤:
        1删除slave: "
          1.查看集群状态
            方式1
              redis-cli -h 192.168.88.11  -a 123456 -p 7771
                CLUSTER NODES  #查看集群的槽分配情况，以及集群master、slave关系
                INFO REPLICATION
                CLUSTER INFO
                CLUSTER KEYSLOT k1 #查看Key隶属于哪个哈希槽
            方式2
              redis-cli -h 192.168.88.11  -a 123456  --cluster check 192.168.88.11:7771 #查看集群的槽分配情况，以及集群master、slave关系
          2.找出所有的slave先删除
            redis-cli -a 123456 --cluster del-node 192.168.88.11:7771 55cde4d14338c7efde81c684aa9fc1fe9ebd77d9
        "
        2删除master: "
          1.查看集群状态
            方式1
              redis-cli -h 192.168.88.11  -a 123456 -p 7771
                CLUSTER NODES  #查看集群的槽分配情况，以及集群master、slave关系
                INFO REPLICATION
                CLUSTER INFO
                CLUSTER KEYSLOT k1 #查看Key隶属于哪个哈希槽
            方式2
              redis-cli -h 192.168.88.11  -a 123456  --cluster check 192.168.88.11:7771 #查看集群的槽分配情况，以及集群master、slave关系
          2.将master碎片移除
            redis-cli -a 123456 --cluster reshard 192.168.88.11:7771
              How many slots do you want to move (from 1 to 16384)? 4096
              What is the receiving node ID? 5bd8a666464d9b5c02ef10f30dbdd2e7c9e91285 #目标机器
              Source node #1: 1be96b44d3ad81bc7d991567084632c18fcc4416
              Source node #3: done
          3.删除slave
            redis-cli -a 123456 --cluster del-node 192.168.88.11:7771 1be96b44d3ad81bc7d991567084632c18fcc4416
        "
  优势: "
    方便扩缩容和数据分派查找
      这种结构很容易添加或者删除节点，比如如果我想新添加个节点D，我需要从节点 A、B、C中得部分槽到D上，如果我想移除节点A，需要将A中的槽移到B和C节点上，然后将没有任何槽的A节点从集群中移除即可。
      由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成【集群不可用的状态】。
  "
  缺点: 分片集群，并不能保证数据零丢失(在master宕机时，从slave中选取master过程中[假设5分钟切换成功]，会丢失部分之前访问原有master的请求)
  分片集群对多key操作支持不友好*: "
    错与操作
      set k1 v1
      set k2 v2
      set k3 v3
      mget k1 k2 k3
    查看槽位 redis-cli -h 192.168.88.11  -a 123456 -p 7771 CLUSTER KEYSLOT k1  
    查看槽位 redis-cli -h 192.168.88.11  -a 123456 -p 7771 CLUSTER KEYSLOT k2  
    查看槽位 redis-cli -h 192.168.88.11  -a 123456 -p 7771 CLUSTER KEYSLOT k3  
    
    正确操作  
      set k1{xx} v1
      set k2{xx} v2 
      set k3{xx} v3
      mget k1{xx} k2{xx} k3{xx}
    查看槽位 redis-cli -h 192.168.88.11  -a 123456 -p 7771 CLUSTER KEYSLOT k1{xx}  
    查看槽位 redis-cli -h 192.168.88.11  -a 123456 -p 7771 CLUSTER KEYSLOT k2{xx} 
    查看槽位 redis-cli -h 192.168.88.11  -a 123456 -p 7771 CLUSTER KEYSLOT k3{xx}
  "
  集群是否需所有master都存活才对外服务: "
    默认是yes，例如3主3从，那么3主需要存活整个集群才可以对外服务
    cluster-require-full-coverage yes  
  "































