批量创建数据: "
   DROP TABLE IF EXISTS t1;
   CREATE TABLE IF NOT EXISTS t1(
   		id int,
   		salary DECIMAL(10,2),
   		last_name VARCHAR(255)
   );


   DROP PROCEDURE IF EXISTS batch_insert;
   DELIMITER $
   CREATE PROCEDURE batch_insert()
   BEGIN
   		DECLARE count INT DEFAULT 0;
   		loop_label:LOOP

   				IF count > 10000 THEN LEAVE loop_label;
   				ELSE INSERT INTO t1(id,salary,last_name) VALUES(count,count*10,CONCAT('eric',count));
   				END IF;
   				SET count = count + 1;

   		END LOOP loop_label;

   END $

   DELIMITER ;

   CALL  batch_insert();
"
架构篇:
  字符集&比较规则操作:
    概述: "
          与创建数据库有关
          character_set_server	    utf8    服务器级别的字符集(修改这里直接影响character_set_database)
          character_set_database	utf8    当前数据库的字符集
          与客服端和服务器之间传输有关
          character_set_client	    utf8    服务器解码请求时用的字符集(必须和客户端编码一直，需要做解码)
          character_set_connection	utf8    放服务器处理请求时会把请求字符串从character_set_client转为character_set_connection(必须和表的编码一直，需要做转码，因为涉及到查表)
          character_set_results	    utf8    服务器向客户端返回数据时使用的字符集(必须和客户端编码一直，需要做编码)

          character_set_filesystem	binary
          character_set_system	    utf8
          character_sets_dir	    /usr/share/mysql/charsets/
        "
    查看系统全部字符集: "
      查看数据库支持的所有字符集
        SHOW CHARACTER SET
        SHOW CHARSET
        SHOW CHARACTER SET LIKE 'utf8%'
        SHOW CHARACTER SET WHERE Charset = 'utf8'
      查看当前使用的字符集
        SHOW GLOBAL VARIABLES LIKE 'character%';
        SHOW SESSION VARIABLES LIKE 'character%';
    "
    临时修改修改字符集: "
      全局系统变量
      SHOW GLOBAL VARIABLES LIKE 'char%'

      SET @@global.character_set_client = utf8mb4;
      SET @@global.character_set_connection = utf8mb4;
      SET @@global.character_set_results = utf8mb4;

      会话系统变量
      SHOW SESSION VARIABLES LIKE 'char%'
      #方式1
      SET @@session.character_set_client = utf8mb4;
      SET @@session.character_set_connection = utf8mb4;
      SET @@session.character_set_results = utf8mb4;
      #方式2
      SET NAMES utf8mb4;
      #方式3
      SET character_set_client = utf8;
      SET character_set_connection = utf8;
      SET character_set_results = utf8;
    "
    查看比较规则: "
      SHOW COLLATION
      SHOW COLLATION LIKE 'utf8%'
      SHOW COLLATION WHERE Collation = 'utf8_general_ci'
    "
    修改字符集(my.cnf): "
      [client]
      default-character-set=utf8
        character_set_client	    utf8    服务器解码请求时用的字符集(必须和客户端编码一直，需要做解码)
        character_set_connection	utf8    放服务器处理请求时会把请求字符串从character_set_client转为character_set_connection(必须和表的编码一直，需要做转码，因为涉及到查表)
        character_set_results	    utf8    服务器向客户端返回数据时使用的字符集(必须和客户端编码一直，需要做编码)
      [mysqld]
      character_set_server=utf8
        character_set_server	    utf8    服务器级别的字符集(修改这里直接影响character_set_database)
        character_set_database	    utf8    当前数据库的字符集
    "
  SQL大小写敏感问题:
    概述:
      - SHOW VARIABLES LIKE '%lower_case_table_names%'
      - 设置0大小写敏感(Linux)，数据库、表名、表的别名、变量名是严格区分大小写，其他则不区分。
      - 设置1大小写不敏感(Window)，创建的表、数据库都是以小写形式存放在磁盘上，对于SQL语句都是转换为小写对表和数据库进行查找
    修改:
      MYSQL5.7: 在my.cnf文件中的[mysqld]中加入 lower_case_table_names = 1 然后重启数据库
      MYSQL8.0: "
        1.停止Mysql服务
        2.删除数据库目录 /var/lib/mysql（禁止删除，严重）
        3.在my.cnf文件中的[mysqld]中加入 lower_case_table_names = 1
        4.启动Mysql服务
      "
    SQL编写规则: 关键字和函数名称全部大写，其他则为小写
  严格模式vs轻松模式(sql_mode):
    概述:
      - 查看 SHOW SESSION VARIABLES LIKE '%sql_mode%' / SHOW GLOBAL VARIABLES LIKE '%sql_mode%'
      - 临时修改 SET SESSION sql_mode = 'ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION'
      - 永久修改 在my.cnf文件[mysqlId]中添加 sql_mode = ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION
    模式介绍:
      默认:
        ONLY_FULL_GROUP_BY: 对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY语句中
        STRICT_TRANS_TABLES: 在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制。
        NO_ZERO_IN_DATE: 不允许日期和月份为零
        NO_ZERO_DATE: MYSQL数据库不允许插入零日期，插入零日期会抛出错误而不是警告
        ERROR_FOR_DIVISION_BY_ZERO: 在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如果未给出该模式，那么数据被零除时MYSQL返回NULL
        NO_ENGINE_SUBSTITUTION: 如果需要的存储引擎被禁用或未编译，那么抛出错误，不设置此值时，用默认的存储引擎替代，并抛出一个异常
      非默认:
        NO_AUTO_VALUE_ON_ZERO: 该值影响自增长列的插入。默认设置下，插入0或者NULL代表生成下一个自增长值。如果用户希望插入的值为0，而该列又是自增长的，那么这个选项就有用了。
        NO_AUTO_CREATE_USER: 禁止GTANT创建密码为空的用户
        PIPES_AS_CONCAT: 将 '||' 视为字符串的连接操作符而非运算符，这和ORACLE数据库是一样的，也和字符串的拼接函数CONCAT相类似
        ANSI_QUOTES: 不能用双引号来引用字符串，因为它被编译为识别符
  数据目录:
    概述:
      - 查看数据目录(/var/lib/mysql/)存放位置 SHOW VARIABLES LIKE '%datadir%'
    核心数据库介绍:
      mysql: 它存储了MYSQL的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。
      information_schema: 它存储了MYSQL服务器维护的所有其他数据库的信息，比如有哪些表，哪些视图，哪些触发器，哪些列，哪些索引。这些信息并不是真实的用户数据，而是一些描述信息，有时候也称为元数据。有一部分以innodb_sys开头的表，用于表示内部系统表
      performance_schema: 它存储了MYSQL服务器运行过程的一些状态信息，可以用来监控MYSQL服务的各类性能指标。包括统计最近执行了哪些语句，在执行过程的每个阶段花费了多长时间，内存的使用情况等信息。
      sys: 这个数据库主要是通过视图的形式把information_schema和performance_schema结合起来，帮助系统管理员和开发人员监控MYSQL的性能
    表空间:
      概述:
        - 常见的表空有，系统表空间(ibdata1文件)和独立表空间(ibd文件)
        - 表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。
        - 表空间是一个逻辑容器，表空间存储的对象是段，在一个表空间可以有一个或多个段，但是一个段只能属于一个表空间
        - 表空间数据库由一个或多个表空间组成，表空间从管理上可以划分为系统表空间(System Tablespace)、独立表空间(File-per-table Tablespace)、撤销表空间(Undo Tablespace)、临时表空间(Temporary Tablespace)等
      独立表空间:
        - 独立表空间，即每张表有一个独立的表空间，也就是数据数据和索引信息都会保存在自己的表空间中。
        - 独立表空间可以在不同的数据之间进行迁移。
        - DROP TABLE指令可以回收表空间。
        - 如果对于统计分析或者是日志表，删除大量数据后可以通过，ALTER TABLE t1 ENGIN = InnoDB来回收没有的表空间。
        - 多余使用独立表空间，不管怎么删除，表空间的碎片不会太严重的影响性能。
      系统表空间:
        - 系统表空间的结构和独立表空间基本类似，只不过由于整个MYSQL的进行只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页面，这部分是独立表空间中没有的。
      Innodb存储引擎下:
        概述:
          - 查看 SHOW GLOBAL VARIABLES LIKE '%innodb_file_per_table%'
          - (默认)值为1代表使用独立表空间(../数据目录/xxx数据库/.ibd文件中)
          - 值为0代表使用系统表空间(../数据目录/ibdata1文件中)
        永久修改: 在my.cnf文件的[server]中 innodb_file_per_table = 1
      MyISAM存储引擎下:
        - 结构则不同，更多细节查看，https://www.bilibili.com/video/BV1iq4y1u7vj?p=104&spm_id_from=pageDriver&vd_source=cc17fab1d456bc3958dcb51e2fdd520b
  配置文件的使用(my.cnf): "
    配置文件有如下常用组
      [server]
      [mysqld]
      [mysqld_safe]
      [mysql.server]
      [mysql]
      [client]
      [mysqladmin]
      [mysqldump]
    启动命令加载到的组
      mysqld         启动服务器  [server] [mysqld]
      mysqld_safe    启动服务器  [server] [mysqld]    [mysqld_safe]
      mysql.server   启动服务器  [server] [mysqld]    [mysql.server]
      mysql          启动客户端  [client] [mysql]
      mysqladmin     启动客户端  [client] [mysqladmin]
      mysqldump      启动客户端  [client] [mysqldump]
  "
  MYSQL逻辑架构:
    概述:
      - MYSQL语句底层执行流程(SQL语句 -> 解析器(语法分析、语义分析，得到语法分析树) -> 优化器(逻辑优化、物理优化、得到查询计划) -> 执行器 -> 查询结果并返回)
    连接层: 连接池
    服务层:
      概述:
        - 查询缓存、SQL接口、解析器、优化器
      MYSQL5.7查询缓存:
        概述:
          - 在mysql5.7有查询缓存，在mysql8.0已经移除
          - 查询缓存非常鸡肋，命中率极低(同样的sql多一个空格都不会被命中)
        使用: "
          #在my.cnf文件中的[mysqld]中设置query_cache_type = 1，默认为关闭，可以开启查询缓存0代表关闭OFF，1代表开启ON，2代表按需使用DEMAND(select SQL_CACHE * from mysql.db,select SQL_NO_CACHE * from mysql.db)
          #查看查询缓存是否开启
          SHOW VARIABLES LIKE '%query_cache_type%'

          SELECT * from mysql.db
          SELECT user from mysql.db

          #查看所有执行过的sql记录
          SHOW PROFILES

          #查询最近一次执行sql的情况
          SHOW PROFILE
          SHOW PROFILE CPU,BLOCK IO
          #查询指定某一次执行sql的情况
          SHOW PROFILE FOR QUERY 2
          SHOW PROFILE CPU,BLOCK IO FOR QUERY 58
        "
    引擎层:
      概述:
        - 可插拔存储引擎 Innodb、MyISAM
      数据库缓冲池:
        概述: 缓冲池装载着磁盘中的数据，避免每次加载磁盘数据过慢，会把热数据加载到缓冲池中
        设置: "
          #缓冲池大小
            #innodb存储引擎默认为128mb，MYISAM存储引擎为key_buffer_size
            SHOW GLOBAL VARIABLES LIKE '%innodb_buffer_pool_size%'

            #临时设置
            #SET @@GLOBAL.innodb_buffer_pool_size = 134217728

            #永久设置
            #在my.cnf文件中的[SERVER]中设置innodb_buffer_pool_size = 134217728


          #缓冲实例个数
            #在并发场景下，多线程访问缓冲池时都需要加锁处理，单一的缓冲池请求的处理速度会慢，所以在缓冲池特别大的时候，我们可以把他们拆分成若干戈小的缓冲池，每个缓冲池都称为一个实例
            #他们都是独立的，独立的去申请内存空间，独立的管理各种链表，在并发访问并不会相互影响，从而提高并发处理能力
            #每个缓冲池大小 = 总大小innodb_buffer_pool_size/实例数innodb_buffer_pool_instances
            #Innodb规定，当innodb_buffer_pool_size小于1GB的时候设置多个缓冲池实例是无效的，Innodb会把实例个数改为1

            #缓存池数量，默认为1个
            SHOW GLOBAL VARIABLES LIKE '%innodb_buffer_pool_instances%'

            #临时设置
            #SET @@GLOBAL.innodb_buffer_pool_instances = 2
            #永久设置
            #在my.cnf文件中的[SERVER]中设置innodb_buffer_pool_instances = 2
        "
      存储引擎:
        概述:
          - 存储引擎就是指标的类型，其实存储引擎以前叫表处理器，后面改名为存储引擎。
          - 存储引擎的功能就是接收上层传下来的指令，然后对表中的数据进行提取或写入操作。
        分类:
          InnoDB:
            概述:
              - mysql5.5之后默认使用
            优点:
              - 支持事务和外键约束
              - 除了insert和select，还有update和delete操作，那么优先选择InnoDB存储引擎
              - InnoDB是为处理巨大数量的最大性能设计的
              - 如果由于硬件或软件的原因导致服务器崩溃，在重启服务器之后不需要进行额外的操作，InnoDB崩溃恢复功能自动将之前提交的内容定型，然后撤销没有提交的进程，重启之后继续从崩溃点开始执行
              - InnoDB存储引擎在主内存中维护了缓冲池，高频率使用的数据将在内存中直接被处理。
            缺点:
              - 相比MYISAM存储引擎，InnoDB对写的处理效率差一些，并且占用更多的磁盘空间以保存数据和索引。
              - MYISAM只缓存索引，不缓存真实数据，InnoDB不仅缓存索引还缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响。
          MYISAM:
            概述:
              - mysql5.5之前默认使用
              - MYISAM提供了全文索引、压缩、空间函数(GIS)等
            优点:
              - 对insert和select效率高
            缺点:
              - 不支持事务和外键约束
              - 不支持行级锁
              - 如果出现宕机后可能导致数据无法恢复
          Archive:
            概述:
              - 归档引擎，仅仅支持insert和select，不支持update和delete
              - MYSQL5.5以后支持索引
              - 拥有很好的压缩机制，使用zlib压缩库。
              - 在记录请求的时候实时的进行压缩，经常被用来作为仓库使用。
              - 归档引擎才用了行级锁，支持AUTO_INCREMENT列属性，AUTO_INCREMENT列可以具有唯一索引或非唯一索引。尝试在任何其他列上创建索引会导致错误。
            优点:
              - 在相同数据量的情况下，相比MYISAM表要节约75%，相比InnoDB表要节约83%
              - 拥有很高的插入速度
            缺点:
              - 对查询的支持较差
            场景:
              - 归档引擎适合日志和数据归档类应用。适合存储大量的独立的作为历史记录的数据
            功能细节:
              B树索引: 不支持
              集群数据库支持: 不支持
              聚集索引: 不支持
              压缩数据: 支持
              数据缓存: 不支持
              加密数据: 支持
              外键: 不支持
              全文检索索引: 不支持
              地理空间数据类型: 支持
              地理空间索引: 不支持
              哈希索引: 不支持
              索引缓存: 不支持
              锁粒度: 行锁
              MVCC: 不支持
              存储限制: 没有任何限制
              交易: 不支持
              更新数据字段的统计信息: 支持
          Blackhole:
            概述:
              - 丢弃写操作，读操作会返回空内容
              - Blackhole存储没有实现任何存储机制，它会丢弃所有的insert插入的数据，不做任何保存。
              - 但服务器会记录Blackhole表的日志，所以它可以用于复制数据库到备库，或者简单的记录日志。但这种应用复方石会碰到很多问题，因为不推荐使用。
          CSV:
            概述:
              - CSV存储引擎存储数据时，以逗号分隔各个数据项。
              - CSV引擎可以将普通的CSV文件作为MYSQL的表来处理，但不支持索引。
              - CSV引擎可以作为一种数据交换的机制，非常有用(普通的CSV文件直接放到数据库文件中，或者拿出数据库文件直接可以打开使用)
          Memory:
            概述:
              - Memory存储引擎采用的逻辑介质是内存，响应速度很快，但是当mysqld守护京城崩溃的时候数据会丢失。
              - 要求数据类型是固定的，长度不固定的不可用(Blob和Text类型的不可用)
              - Memory存储引擎支持哈希索引和B+树索引，默认使用哈希索引。
              - 由于数据只存储在内存中，索引底层的只有一个元数据文件用于存储表结构。
              - Memory存储引擎表的大小是受限制的，取决于2个参数，max_rows和max_heap_table_size，其中max_rows可以在创建表指定，max_heap_table_size默认大小为16MB，可以按需进行扩容
            场景:
              - 目标数据比较小，而且非常频繁的进行访问，在内存中存放数据，如果太大的数据会造成内存溢出。
          Federated:
            概述:
              - Federated存储引擎是访问其他MYSQL服务器的一个代理，尽管改引擎看起来提供了一种很好的跨服务器的灵活性，但是也经常带来问题，因此默认是禁用的。
          Merge:
            概述:
              - Merge存储引擎是管理多个MYISAM表，构成的表集合
          NDB:
            概述:
              - NDB存储引擎是MYSQL集群专用的存储引擎，主要用于MYSQL Cluster分布式集群环境，类似于Oracle的RAC集群。
        InnoDB和MYISAM对比:
          引擎:      MYISAM                     InnoDB
          外键:      不支持                       支持
          事务:      不支持                       支持
          行锁:      不支持                       支持
          表锁:      支持                         支持
          并发:      不适合(操作1条记录导致整表锁住)   适合
          缓存:      只缓存索引                    缓存索引+真实数据
          内存:      内存使用小                    内存使用多
        设置: "
          #查看数据库所有的引擎
          SHOW ENGINES

          #查看默认的存储引擎
          SHOW GLOBAL VARIABLES LIKE '%default_storage_engine%'

          #设置存储引擎
          	#临时设置
          	SET GLOBAL default_storage_engine = InnoDB
          	#永久设置my.cnf
          	# default_storage_engine = InnoDB
        "
索引篇:
  概述:
    - 索引是存储引擎用于快速找到数据记录的一种数据结构
    - 索引的本质就是数据结构，可以理解为排好序的快速查找数据结构，这些数据结构以某种方式指向数据，这样就可以在这些数据结构的基础上实现高级查找算法。
    - 索引是在存储引擎中实现的，因此妹子存储引擎的索引不一定完全相同，并且每种存储引擎不一定支持所有的索引类型。
    - 存储引擎可以定义每个表的最大索引数和最大索引长度。
    - 存储引擎支持每个表至少16个索引，总索引长度至少位256字节。有些存储引擎支持更多的索引数和更大的索引长度。
    - 如果是大批量的insert、delete、update操作，可以考虑先把索引删除，等把操作做完在从新添加索引。
  优点:
    - 提高数据检索的效率，降低数据库的IO成本
    - 通过创建唯一索引，可以保证数据库表中每一行数据的唯一性
    - 在实现数据的参考完整性方面，可以加速表和表之间的连接。换句话说，对有依赖关系的从表和主表联合查询时，可以提高查询速度
    - 在使用分组和排序子句进行数据查询时，可以显著减少查询中分钟和排序的时间，降低了CPU的消耗(因为索引的排序好的数据结构)
  缺点:
    - 创建索引和维护索引要消耗时间，并且随着数据量的增加，所耗费的时间也会增加
    - 索引需要占用磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间(存储在磁盘上)，如果有大量的索引，索引文件有可能比数据文件更快达到最大文件尺寸
    - 索然索引大大提高了查询速度，同时却会降低更新表的速度。当对表中的数据进行insert、delete、update的时候，索引也要动态维护，这样就降低了数据的维护速度
    - 从空间角度，每建立一个索引都要为它建立一颗b+树，每一颗数的每一个节点都是一个数据页，一个数据页默认会占用16kb的存储空间，一颗很大的树由许多数据页组成，那就是很大的一片存储空间
    - 从时间角度，每次对表的数据进行insert、delete、update，都需要去修改各个b+树索引。
  b+tree、索引、数据结构:
    b-tree与b+tree的对比:
      - https://www.bilibili.com/video/BV1iq4y1u7vj?p=120&vd_source=cc17fab1d456bc3958dcb51e2fdd520b
      - 在b+tree中，有k个儿子的节点就有k个关键字，也就是儿子数量 = 关键字数，而在b-tree中，儿子数量 = 关键字数量 + 1
      - 在b-tree中非叶子节点的关键字也会同时存在子节点中，并且是在子节点中所有关键字最大(或最小)
      - 在b+tree中，非叶子节点仅用于索引，不保存数据记录，跟记录相关的信息都存放在叶子节点中，而b-tree中，非叶子节点既保存索引，也保存数据记录。
      - 在b+tree中，所有关键字都在叶子节点出现，叶子节点构成一个有序单向链表，而且叶子节点本身按照关键字的大小从小到大顺序链接
    InnoDB存储引擎中的b+tree:
      聚集索引vs非聚集索引:
        概述:
          - 聚集索引也叫聚簇索引(只能1个)
          - 非聚集索引也叫二级索引，或者辅助索引(1个或多个)
        聚集索引:
          概述:
            - img_5聚集索引.png
            - 数据页与数据页之间用双向链表，并且有序
            - 数据与数据之间用单向链表，并且有序
            - 最底部叶子节点存储(完整数据)
          优点:
            - 数据访问更快，因为聚集索引将索引和数据保存在同一个B+树种，因次从聚集索引中获取数据比非聚集索引更快
            - 聚集索引对于主键的排序查询和范围查找速度非常快，因为(数据页和数据)都是按照顺序存放的
            - 按照聚集索引排序顺序，查询显示一定范围数据的时候，由于数据都是紧密相连，数据库不用从多个数据页中提取数据，所以节省了大量IO操作
          缺点:
            - 插入速度严重依赖插入顺序，按照主键的顺序插入是最快的方式，否则有可能会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自动增长的主键列
            - 更新主键的代价很高，影响聚集索引和非聚集索引的更新。因此，对于InnoDB表，我们一般定义主键为不可更新
            - 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据
          表中聚集索引的产生:
            - 对于MYSQL数据库，目前只有InnoDB数据引擎支持聚集索引，而MYISAM并不支持聚集索引。
            - 由于数据物理存储排序方式只能有一种，所以每个表只能有一个聚集索引(一个表只能有一个主键)。
            - 如果没有定义主键，InnoDB会选择一个非空+唯一约束的列生成聚集索引。
            - 如果连非空+唯一约束的列都没有，InnoDB会隐式生成一个聚集索引。
            - 为了充分利用聚集索引，所以InnoDB表的主键列尽量选用有序的ID，不建议使用无需的ID，比如(UUID、MD5、HASH、字符串)，因为主键无分发保证数据的顺序增长(维护聚集索引困难)。
        非聚集索引:
          概述:
            - img_6非聚集索引.png
            - 数据页与数据页之间用双向链表，并且有序
            - 数据与数据之间用单向链表，并且有序
            - 最底部叶子节点存储(该列+主键列)
          回表操作:
            - select * from dept where f2 = 4 ，需要回表操作，先在非聚集索引中查找，拿到主键列的值，在去聚集索引中接着查找
            - select f2 from dept where f2 = 4 ，不需要回表操作
      b+tree是如何进行记录检索:
        - 如果通过b+tree的索引查询行记录，首先是从b+tree的根页开始，将数据页加载到内存中，页目录中的槽采用二分查找的方式先找到一个粗略的记录分组，然后在分组中通过链表遍历的方式查找到记录，逐层检索，直到找到叶子节点，也就是找到对应的数据为止。
      普通索引和唯一索引在查询效率上的不同:
        唯一索引: 唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索
        普通索引:
          - 普通索引可能会存在关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页加载到内存中进行读取。
          - InnoDB存储引擎的页大小为16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中"多几次判断下一条记录的操作"，对于CPU来说，这些操作所小号的时间是可以忽略不计的。
          - 所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本没有差别。
      一般情况下不存在4层b+tree:
        - 一般情况下不存在4层b+tree，所以IO一般为1-3次，因为根层常驻内存
        - 一个数据页有16kb
        - 1层情况下，假设，100(数据页-真实数据) = 100(100条)
        - 2层情况下，假设，1000(数据页-目录) x 100(数据页-真实数据) = 100,000(10万条)
        - 3层情况下，假设，1000(数据页-目录) x 1000(数据页-目录) x 100(数据页-真实数据) = 100,000,000(1亿条)
        - 4层情况下，假设，1000(数据页-目录) x 1000(数据页-目录) x 1000(数据页-目录) x 100(数据页-真实数据) = 100,000,000,000(1千亿条)
      在InnoDB中b+树索引创建机制:
        - 自上而下的创建过程
        - 根节点位置保持不变
        - 内节点中目录项的记录是唯一的(针对非聚集索引产生的非唯一索引)
        - 一个数据页至少存储2条数据
      InnoDB数据存储结构:
        概述:
          - 详情可以参考图，img_9页结构.png
        表空间:
          - 表空间包含段（叶节点段，非叶节点段，回滚段）
          - 表空间是一个逻辑容器
          - 表空间从管理上可以华恩为系统表空间，独立表空间，用户表空间，撤销表空间，临时表空间等。
          - 系统表空间，/root/mysql/data/ibdata1
          - 独立表空间，/root/mysql/data/数据库名/表名.ibd
        段:
          - 段包含区
          - 段是数据库中分配的单位，不同类型的数据对象以不同的段形式存在，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段
          - "
            对于范围查询，其实是对B+tree树叶子节点中的记录进行顺序扫描，而如果不分区分叶子节点和非叶子节点，统统把节点代表的页放到申请区中的话，进行范围扫描的效果就大打折扣了。
            所以InnoDB对B+tree的叶子节点和非叶子节点进行了区别的对待，也就是说叶子节点有自己独有的区，非叶子节点也有自己独立的区。存放叶子节点的区的集合就算是一个段，存放非
            叶子节点的区的集合也算是一个段。也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段。

            除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为存储一些特殊的数据而定义的段，比如回滚段，所以，场景的段有数据段、索引段、回滚段。数据段即为B+tree的叶子节点，索引段即为B+tree的非叶子节点。

            在InnoDB存储引擎中，多段的管理都是由引擎自神所完成的，DBA不能也没有必要对其进行控制。这从一定程度上简化了DBA对于段的管理。
            段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页以及一些完整的区组成。
          "
        区:
          - 区包含页
          - 在InnoDB存储引擎中，一个区会分配64个连续的页(目的是为了磁盘的顺序IO)。然而一个页默认的大小为16KB，那么一个区的大小为1MB = 64*16KB
          - "
            B+tree的每一层中的页都会形成一个双向链表，如果是以页为单位来分配存储空间的话，双向链表项链的两个页之间的物理位置可能离的非常远。
            我们介绍B+tree索引的适用场景的时候特别提到范围查询，只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了。
            而如果链表中项链的两个页物理位置离非常远，就是所谓的随机I/O。再一次强调，磁盘的速度和内存的速度差了好几个数量级，随机I/O是非常慢的，
            所以我们应该尽量让链表中相邻的页的物理位置也相邻，这样进行范围查询的时候才可以使用所谓的顺序I/O。

            引入区的概念，一个区就是在物理位置上的连续的64个页。因为InnoDB中的页大小默认是16KB，所以一个区的大小是64*16KB=1MB。
            在链表中数据量大的时候，为某个索引分配空间的时候就不在按照页为单位分配了，而是按照【区为单位分配】，甚至在表中的数据特别多的时候，
            可以一次性分配多个连续的区。虽然可能造成一点点空间的浪费(数据不足以填充满整个区)，但是从性能角度看，可以消除很多的随机I/O，功大于过
          "
        碎片区: "
          默认情况下，一个使用InnoDB存储引擎的表只有一个聚集索引，一个索引会产生2个段，而段是以区为单位申请存储空间的，一个区默认占用1M=64*16KB存储空间，
          所以默认情况下一个只存了几条记录的小表也需要2M的存储空间，以后每次添加一个索引都要多申请2M的存储空间，多余存储记录比较少的表简直是有点过于浪费。
          这个问题的症结在于到现在为止我们介绍的区都是非常纯粹的，也就是一个区被整个分配给某一个段，或者说区中的所有页面都是为了存储同一个段的数据而存在的，
          即使段的数据填不满区中的所有页，那余下的页也不能挪给其他地方用。

          为了考虑完整的区为单位分配给某个段多于数据量较小的表太浪费存储空间的这种情况，InnoDB提出了一个碎片区的概念。在一个碎片区中，并不是所有的页都是为了存储
          同一个段的数据而存储在，而是碎片区中的页可以用于不同的目的，比如有些页用于段A，有些页用于段B，有些页甚至哪个段都不属于。【碎片区直属于表空间】，并不属于任何一个段
        "
        页:
          概述:
            - 页包含行
            - InnoDB将数据划分为若干个页，默认大小为16kb。
            - 查看innodb数据页的大小 SHOW VARIABLES LIKE '%innodb_page_size%'
            - 以页作为磁盘和内存之间交互的基本单位，也就是一次最少从磁盘中读取16KB的数据到内存中，一次最少把内存中的16KB数据刷到磁盘中
            - 在数据库中，不论读一行，还是读多行，都是将这些行所在的页进行加载。
            - 数据库管理存储空间的基本单位为页，数据库IO操作的最小单位是页，一个页中可以存储多个行记录。
            - 记录是按照行来存储的，但是数据库的读取并不以行为单位，否则一次读取只能处理一行数据，效率会非常低，IO次数也会变多。
            - 常见的页有，数据页(B+tree节点)，系统页，Undo页，事务数据页等
          数据页结构:
            文件头FileHeader(38字节):
              概述:
                - 描述各种页的通用信息，比如页的编号，上一页和下一页的信息等。
              结构:
                FIL_PAGE_TYPE(2字节):
                  概述:
                    - 该页的类型
                  如下类型:
                    FIL_PAGE_TYPE_ALLOCATED: 0x0000 最新分配，还没使用
                    FIL_PAGE_UNDO_LOG: 0x0002 Undo日志页
                    FIL_PAGE_INODE: 0x0003 段信息节点
                    FIL_PAGE_IBUFF_FREE_LIST: 0x0004 Insert Buffer空间列表
                    FIL_PAGE_IBUF_BITMAP: 0x0005 Insert Buffer位图
                    FIL_PAGE_TYPE_SYS: 0x0006 系统页
                    FIL_PAGE_TYPE_TRX_SYS: 0x0007 事务系统数据
                    FIL_PAGE_TYPE_FSP_HDR: 0x0008 表空间头部信息
                    FIL_PAGE_TYPE_XDES: 0x0009 扩展描述页
                    FIL_PAGE_TYPE_BLOB: 0x000A 溢出页
                    FIL_PAGE_INDEX: 0x45BF 索引页，也就是我们说的数据页
                File_PAGE_SPACE_OR_CHKSUM(4字节):
                  概述:
                   - 页的校验和checksum值
                   - 该校验和在文件头和文件尾都有，用于刷盘的时候做校验，判断是否全部刷盘完成，如何文件头和文件尾的校验和是一致，则代表完成，如果不一直，有可能是中途出现宕机等情况，则需要做相应的恢复操作。
                FIL_PAGE_LSN(8字节): 页面被最后修改时对应的日志序列位置（英文名是 Log Sequence Number）
                FIL_PAGE_OFFSET(4字节): 每一个页都有一个单独的页号，就跟你的身份证号码一样，InnoDB通过页号可以唯一定位一个页
                FIL_PAGE_PREV(4字节): 上一个页的页号，实现页与页之间逻辑连接(双向链表)
                FIL_PAGE_NEXT(4字节): 下一个页的页号，实现页与页之间逻辑连接(双向链表)
                FIL_OAGE_FILE_FLUSH_LSN(8字节): 仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值
                FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID(4字节): 页属于哪个表空
            文件尾FileTrailer(8字节):
              概述:
                - 文件尾，检验页是否完整，配合文件头FileHeader一起使用。
                - 前4字节代表页的校验和，和FileHeader中的File_PAGE_SPACE_OR_CHKSUM对应
                - 后4字节代表页面被最后修改时对应的日志序列位置（英文名是 Log Sequence Number），和FileHeader中的FIL_PAGE_LSN对应
            空闲空间FreeSpace(不确定):
              概述:
                - 空闲空间，页中还有多少可以使用的空间
                - 我们自己存储的记录会按照指定的行格式存储到UserRecords部分，但是在一开始生成页的时候，其实并没有UserRecords这个部分。
                - 当我们插入一条记录，都会从FreeSpace中申请一个记录大小的空间划分到UserRecords，当FreeSpace部分的空间全部被UserRecords申请完，如果有还记录插入，就需要去申请新的页了
            用户记录UserRecords(不确定):
              概述:
                - 用户记录，存储行记录内容
                - 记录按照指定的行格式，一条一条的记录在UserRecords部分，相互之间形成单链表。
              结构(以Compact格式为例):
                变长字段长度列表(2字节):
                  - 对变长的数据类型做记录，比如VARCHAR、TEXT、BLOB等。
                  - 在Compact行格式中，把所有边长字段的真实数据占用的字节长度哦度存放在记录的开头部位，从而形成一个边长字段长度列表
                NULL值列表(1字节):
                  - Compact行格式会把可以为NULL的列统一管理起来，存在一个标记为NULL值列表中。如果表中没有允许存储NULL的列，则NULL值列表也不存在了
                  - 之所以要存储NULL是因为数据都是需要对齐的，如果没有标注出来NULL值的位置，就有可能在查询数据的时候出现混乱，如果使用一个特定的符号放到响应的数据位表示的话，虽然能达到效果，但是这样很浪费空间，所以直接就在行数据头统一记录
                记录头信息(5字节):
                  结构:
                    预留位1(1bit): 没有使用
                    预留位2(1bit): 没有使用
                    DELETE_MASK(1bit):
                      概述:
                        - 标记该记录是否被删除，0代表没删除，1代表删除
                        - 这些被删除的记录不会立即从磁盘上移除，因为出一他们之后其他的记录在磁盘上需要重新排列和移动，导致性能消耗
                        - 被删除的记录只是标记而已，所有被删除掉的记录会利用(NEXT_RECORD)组成一个所谓的垃圾链表，在这个链表中的记录占用的空间称之为可重用空间，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。
                    MIN_REC_MASK(1bit):
                      概述:
                        - B+tree的每层非叶子节点中的最小记录都会添加该标记，MIN_REC_MASK = 1
                        - 我们自己插入的记录MIN_REC_MASK = 0 ，以为着他们都不是B+tree的非叶子节点中的最小记录
                    RECORD_TYPE(3bit):
                      概述:
                        - 表示当前记录的类型
                        - 0表示普通记录
                        - 1表示B+tree树非叶子节点记录
                        - 2表示最小记录
                        - 3表示最大记录
                    HEAP_NO(13bit):
                      - 表示当前记录在记录堆的位置信息
                      - 存储引擎会自动给每个页里面加了2个记录，由于这2个记录并不是我们这插入的，所以成为伪记录或者叫虚拟记录。
                      - 这两个虚拟记录一个代表最小记录(0)，一个代表最大记录(1)
                      - 用户插入的记录则标记为(2,3,4,5,6,.....)
                    N_OWNED(4bit):
                      概述:
                        - 页目录PageDirectory中每个组中最后一条记录的会利用该部分N_OWNED会记录该组一共有多少条记录，其他记录则用0表示
                    NEXT_RECORD(16bit):
                      概述:
                        - 该部分就是形成记录的单向链表，不论我们怎么对页中的记录做增删改操作，InnoDB始终会维护一条记录的单向链表，链表中的各个节点是按照【索引列】的值由小到打的顺序连接起来
                        - 它表示从当前记录到下一条记录的地址偏移量，比如第一条记录的next_record的值为32，意味着从第一条记录的地址处向后找32个字节便是下一条记录
                        - 最小记录(Infimum)记录的下一条记录就是该数据页的中【索引列】最小的用户记录，该数据页中的【索引列】最大的用户记录的下一条记录就是最大记录(Supermum)
                        - 一条记录被删除的时候DELETE_MASK变为1，并且NEXT_RECORD为0，如果是多条记录，则NEXT_RECORD会形成一个垃圾链表，在这个链表中的记录占用的空间称之为可重用空间，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。
                f1列的值: 用户列
                DB_ROW_ID列的值(6字节):
                  - 隐藏列，行ID，唯一标识一条记录
                  - 当一个表创建时，没指定主键以及Unique，则默认会为表添加一个DB_ROW_ID列作为主键，所以DB_ROW_ID是在没有自定义主键以及Unique的情况下才存在
                DB_TRX_ID列的值(6字节): 隐藏列，事务ID
                DB_ROLL_PRT列的值(7字节): 隐藏列，回滚至臻
                fn列的值: 用户列
              行格式:
                概述:
                  - 查看默认的行格式 SHOW VARIABLES LIKE '%innodb_default_row_format%'
                  - 查看表的行格式 SHOW TABLE STATUS WHERE Name = 't1'
                  - 分别有Compact格式(MYSQL5.1默认)、Dynamic格式(MYSQL5.7-8.0默认)、Compressed格式、Redundant格式(MYSQL5.0之前默认)
                  - 不同的行格式存储结构数据的结构有所不同，以及对行溢出的处理方式也不同
                行溢出:
                  - 如果创建一个字节 varchar(60000) ，那么一个数据页的大小默认为16KB，这样可能出现一个页存放不了一条记录，这样现象称为行溢出。
                  - Dynamic格式和Compressed格式对于存放在BLOB中的数据采用了完全的行溢出方式，在行记录中只存放20个字节溢出页的偏移地址，实际的数据都存放在溢出页中(Off Page)
                  - Compressed格式的另一个功能就是，存储在其中的行数据会以zlib的算法进行压缩，因此对于BLOB、TEXT、VARCHAR这类大长度类型的数据能够进行非常有效的存储。
                  - Compact格式和Redundant格式会在记录真实数据处存储一部分真实数据(存放768个前缀字节)
            最小记录(Infimum)(13字节):
              概述:
                - 记录UserRecords中的最小记录，这是虚拟的行记录
              结构:
                记录头信息(5字节): 参考用户记录UserRecords的记录头
                记录体信息(8字节): Infimum(69 6E 66 69 6D 75 6D 00)
            最大记录(Supermum)(13字节):
              概述:
                - 记录UserRecords中的最大记录，这是虚拟的行记录
              结构:
                记录头信息(5字节): 参考用户记录UserRecords的记录头
                记录体信息(8字节): Supermum(73 75 70 72 65 6D 75 6D)
            页目录PageDirectory(不确定):
              概述:
                - 在数据页中，记录是以单向链表的形式进行存储的，单双链表的缺点就是查询慢，增删快。因此，在数据页中专门设计了页目录这个部分，专门给记录提供一个目录用于2分查找法进行检索定位,提升性能。
                - 将所有记录分组【最小记录(Infimum)+用户记录UserRecords+最大记录(Supermum)】，不包跨DELETE_MASK=1的记录
                - 页目录的基本单位为【槽】，用于存储每个分组中【最大值(索引列的值)记录的地址偏移量】
              分组规则:
                - 第一组，最小记录(Infimum)，1条记录，槽的偏移量为Infimum
                - 第二组，用户记录UserRecords+最大记录(Supermum)，1-8条记录，槽的偏移量为Supermum
                - 其余组，用户记录UserRecords，4-8条记录，槽的偏移量为最大值(索引列的值)记录的地址偏移量
            页头PageHeader(56字节):
              概述:
                - 这个页头记录着关于这个数据页的各项指标信息
              结构:
                PAGE_N_DIR_SLOTS(2字节): 在页目录中槽的数量
                PAGE_HEAP_TOP(2字节): 还未使用的空间最小地址，也就是说从该地址之后就是FreeSpace
                PAGE_N_HEAP(2字节): 本页中记录的数量(包括最小和最大记录以及标记为删除的记录)
                PAGE_FREE(2字节): 第一个已经标记为删除的记录地址(各个已删除的记录通过next_record也会组成一个单向链表，这个单向链表中的记录可以被重新利用)
                PAGE_GARBAGE(2字节): 已删除记录占用的字节数
                PAGE_LAST_INSERT(2字节): 最后插入记录的位置
                PAGE_DIRECTION(2字节): 记录插入的方向
                PAGE_N_DIRECTION(2字节): 一个昂新连续插入的记录数量
                PAGE_N_RECS(2字节): 该页中记录的数量(不包括最小和最大记录以及被标记为删除的记录)
                PAGE_MAX_TRX_ID(8字节): 修改当前页的最大事务ID，该值仅在非聚集索引中定义
                PAGE_LEVEL(2字节): 当前页在B+tree中所处的层级
                PAGE_INDEX_ID(8字节): 索引ID，表示当前页属于哪个索引
                PAGE_BTR_SEG_LEAF(10字节): B+tree叶子段的头部信息，仅在B+tree的Root页定义
                PAGE_BTR_SEG_TOP(10字节): B+tree非叶子段的头部信息，仅在B+tree的Root页定义
        行:
          - 行包含字段长度偏移列表，记录头信息，列1....列n
      数据页加载的三种方式:
        概述:
          - InnoDB从磁盘中读取数据的最小单位是页，而你想得到某一条具体的数据时，这时候就需要从诸多页中获取其中的一行。
          - 对于MYSQL存放的数据，逻辑概念上我们称之为表，在磁盘等物理层面是按数据页形式存放的，当其加载到MYSQL中我们称之为缓存页
          - 如果缓冲池中没有该页数据，那么缓冲池可以使用(内存读取、随机读取、顺序读取)，每种方式的读取效率都不同。
        内存读取: 如果该数据存在于内存中，基本上执行时候在1ms左右
        随机读取(随机IO): 如果数据没有在内存中，就需要在磁盘上对该页进行，整体时间预估在10ms左右 = 3ms排队 + 4ms寻道 + 2ms半圈旋转 + 1ms传输
        顺序读取(顺序IO): "
          顺序读取其实是一种批量读取方式，因为我们请求的数据在磁盘上往往都是相邻存储的，顺序读取可以帮我们批量读取页面，这样的话，一次性
          加载到缓冲池中就不需要再对其他页面单独进行磁盘IO操作了，如果一个磁盘的吞吐量是40MS/s，那么对一个16KB大小的页来说，一次可以
          顺序读取2560个页(40MB/16KB)，相当于一个页的读取时间约为0.4ms。采用批量读取的方式，即使是从磁盘上进行读取，效率也比从内存中
          单独读取一个页的效率要高
        "
      段分配存储空间策略: "
        在刚开始向表中插入数据的时候，段是从某个碎片区以单个页为单位来分配存储空间的。
        当某个段已经占用了32个碎片区页面之后，就会申请以完整的区为单位来分配存储空间。
        段应该是某个零散的页面的集合，以及一些完整的区的集合。
      "
      区的分类:
        直属于表空间的区:
          空闲区(FREE): 现在还没有用到这个区中中的任何页
          有剩余空间的碎片区(FREE_FRAG): 表示碎片区中还有可用的页
          没有剩余空间的碎片区(FULL_FRAG): 表示碎片区种方法的所有页都被使用，没有空闲的页
        直属于某个段的区:
          隶属于某个段的区(FSEG): 每一个索引都可以分为叶子节点段和非叶子节点段
    MYISAM存储引擎中的b+tree:
      概述:
        - img_8MYISAM存储引擎b-tree.png
        - MYISAM存储引擎中b-tree不分聚集和非聚集索引，但是可以理解为非聚集索引
        - MYISAM存储引擎中非聚集索引的数据页中的真实数据区域存储的是数据的偏移地址
        - MYISAM存储引擎中将索引和数据分别存储在不同文件中
        - 将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个数据页，有多少记录就往这个文件中塞多少记录就成了。
        - 由于插入数据的时候并没有刻意按照主键大小排序，所以我们并不能在这些数据上使用二分法进行查找
      回表:
        - 在MYISAM中查找到数据以后，由于叶子节点存储的是数据的偏移地址，所以还需要在去对应的文件中找到具体的数据
    InnoDB和MYISAM比对:
      - 在InnoDB存储引擎中，我们只需要根据主键值对聚集索引进行一次查找就能够找到对应的记录，而在MYISAM中却需要进行额外的一次回表操作，意味着MYISAM中建立的索引相当于全部都是非聚集索引。
      - InnoDB的数据文件本身就是索引文件，而MYISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址
      - InnoDB的非聚集索引data域存储相应的记录主键的值，而MYISAM索引记录的是地址。
      - 在非聚集索引中，MYISAM的回表操作十分快速的，因为是拿着地址偏移量直接到文件中取数据，InnoDB是通过获得主键之后在到聚集索引中查找记录，虽然说也不慢，但还是比不上直接用地址去访问
      - InnoDB要求表必须有主键(MYISAM可以没有)，在InnoDB中如果没有显示指定，则会自动选择一个非空+唯一约束的列作为主键，如果这样的列也不存在，则InnoDB表会自动生成一个隐藏列作为主键，这个列的长度为6个字节，类型为长整形
    索引(☆):
      索引介绍:
        概述: MYSQL索引主要有，普通索引、唯一索引、主键索引、全文索引、空间索引
        普通索引(NORMAL): "
          在创建普通索引时，不附加任何限制条件，只是用于提高查询效率。这类索引可以创建在任何数据类型中，其值是否需要做约束(非空和唯一)，要由字段本身的
          完整性约束条件决定。建立普通索引后，可以通过索引进行查询，一张表可以有多个普通索引
        "
        唯一索引(UNIQUE): "
          使用UNIQUE参数可以设置成唯一索引，唯一索引会限制改列的值必须唯一，但是允许改列为Null值，一张表可以有多个唯一索引
        "
        全文索引(FULLTEXT): "
          全文索引只支持字符串类型的是列。
          全文索引是一种搜索引擎使用的关键技术，它能够利用分词技术等多种算法只能分析出文本文字中关键词的频率和重要性，
          然后按照一定的算法规则智能的筛选出我们想要的结果，全文索引适合大型数据集，对于小的数据集，它的用处比较小。
          使用FULL TEXT可以设置全文索引。目前全文检索在关系型数据库并不流行，可以考虑solr和ElasticSearch等框架。
        "
        空间索引(SPATIAL): "
          使用参数SPATIAL可以创建空间索引。空间索引只能建立在空间数据类型(GEOMETRY、POINT、LINESTRING、POLYGON)上。
          目前只有MYISAM存储引擎支持空间索引，并且索引列不能为空值
        "
        主键索引(PRIMARY): "
          主键索引就是一种特殊的唯一索引，在创建唯一索引的时候，会自动帮该列增加Not Null约束，并且改列具有唯一约束，一张表只能有一个唯一索引(聚集索引)，这是由主键索引的物理实现方式
          决定的，因为数据存储在文件中只能按照一种顺序进行存储。
        "
      引擎支持的索引方式:
        InnoDB:  支持(B-TREE)
        MYISAM:  支持(B-TREE)
        Memory:  支持(B-TREE、HASH)
        NDB:     支持(HASH)
        Archive: 都不支持
      创表创建索引: "
        #SHOW INDEX FROM t1
        #创建主键索引
        	#方式1
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 INT PRIMARY KEY
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;
        	#方式2
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 INT,
        		 PRIMARY KEY (f1)
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;
        	#方式3
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 INT KEY
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;
        	#方式4，限制索引的长度，只有字符串类型支持
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 VARCHAR(100),
        		 PRIMARY KEY (f1(50))
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;

        #创建唯一索引
        	#方式1
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 INT UNIQUE KEY
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;
        	#方式2
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 INT,
        		 UNIQUE KEY f1_name (f1)
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;


        #创建普通索引
        	#方式1
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 INT,
        		 KEY f1_name (f1)
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;

        #创建全文索引，全文索引只支持字符串类型的列(char、varvhar、text)
        	#方式1
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 VARCHAR(10),
        		 FULLTEXT KEY f1_name (f1)
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;

        #创建空间索引，空间索引只支持空间类型的列(GEOMETRY、POINT、LINESTRING、POLYGON)
        	#方式1
        	DROP TABLE IF EXISTS t1;
        	CREATE TABLE t1 (
        		 f1 POINT NOT NULL,
        		 SPATIAL KEY f1_name (f1)
        	) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        	SHOW CREATE TABLE t1;
      "
      表后创建索引: "
        DROP TABLE IF EXISTS t1;
        CREATE TABLE t1 (
        	 f1 INT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        SHOW CREATE TABLE t1;
        #SHOW INDEX FROM t1

        #添加主键索引
          #方式1
          ALTER TABLE t1
          ADD CONSTRAINT PRIMARY KEY (f1)
          #方式2
          ALTER TABLE t1
          ADD PRIMARY KEY (f1)

        #添加唯一索引
          #方式1
          ALTER TABLE t1
          ADD CONSTRAINT f1_name UNIQUE KEY (f1)
          #方式2
          ALTER TABLE t1
          ADD UNIQUE KEY f1_name (f1)
          #方式3
          ALTER TABLE t1
          ADD UNIQUE KEY (f1)
          #方式4
          CREATE UNIQUE INDEX f1_name ON t1(f1)


        #添加普通索引
          #方式1
          ALTER TABLE t1
          ADD KEY f1_name (f1)
          #方式2
          ALTER TABLE t1
          ADD KEY (f1)
          #方式3
          CREATE INDEX f1_name ON t1(f1)

        #删除普通索引和唯一索引
          #方式1
          ALTER TABLE t1
          DROP KEY f1_name
          #方式2
          ALTER TABLE t1
          DROP INDEX f1_name
          #方式3
          DROP INDEX f1_name ON t1

        #删除主键索引
          ALTER TABLE t1
          DROP PRIMARY KEY
      "
      MYSQL8.0降序索引:
        使用: "
          DROP TABLE IF EXISTS t1;
          CREATE TABLE t1 (
          	 f1 VARCHAR(20),
          	 f2 VARCHAR(20)
          	 #KEY f1_name (f1(10) DESC)
          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
          SHOW CREATE TABLE t1;
          #SHOW INDEX FROM t1

          #添加一个主键索引，降序+长度
          ALTER TABLE t1
          ADD PRIMARY KEY (f1(10) DESC,f2(5) ASC)


          #添加一个唯一索引，降序+长度
          ALTER TABLE t1
          ADD UNIQUE KEY (f1(10) DESC,f2(5) ASC)

          #添加一个普通索引，降序+长度
          ALTER TABLE t1
          ADD KEY (f1(10) DESC,f2(5) ASC)
        "
        性能案例: "
          DROP TABLE IF EXISTS t1;
          CREATE TABLE t1 (
          	 f1 VARCHAR(20),
          	 f2 VARCHAR(20)
          	 #KEY f1_name (f1(10) DESC)
          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
          SHOW CREATE TABLE t1;


          #添加f1降序，f2升序
          ALTER TABLE t1
          ADD KEY (f1 DESC,f2 ASC);


          DROP PROCEDURE IF EXISTS batch_insert;
          DELIMITER $
          CREATE PROCEDURE batch_insert()
          BEGIN
          		DECLARE count INT DEFAULT 0;
          		loop_label:LOOP

          				SELECT 1;

          				IF count >= 800 THEN LEAVE loop_label;
          				ELSE INSERT INTO t1(f1,f2) VALUES(count,count*10);
          				END IF;
          				SET count = count + 1;

          		END LOOP loop_label;

          END $
          DELIMITER ;


          CALL batch_insert();
          SELECT COUNT(1) FROM t1;

          #不遵守降序索引的方式查询效率高，Using index
          EXPLAIN SELECT * FROM t1 ORDER BY f1 DESC,f2 ASC LIMIT 5;
          #不遵守降序索引的方式查询效率低，Backward index scan; Using index
          EXPLAIN SELECT * FROM t1 ORDER BY f1 ASC,f2 DESC LIMIT 5;
        "
      MYSQL8.0隐藏索引:
        概述:
          - mysql8.0支持将索引隐藏起来，不起作用。可以用于测试索引是否带来性能提高
          - 主键索引不能设置为隐藏索引。
          - 可以通过SHOW INDEX FROM t1 的VISIBLE字段查看索引是否隐藏
          - 当索引被隐藏时，它的内容仍然和正常索引一样被实时更新，如果一个被长期隐藏了，那么可以将其删除，因为索引的存在会影响插入、更新和删除的性能
          - 优化器默认是不可以见隐藏索引(SELECT @@optimizer_switch)，里面有一个值为use_invisible_indexes=off，可以通过更改参数让优化器可见，SET SESSION optimizer_switch = 'use_invisible_indexes=on'，一般不设置
        使用: "
          DROP TABLE IF EXISTS t1;
          CREATE TABLE t1 (
          	 f1 INT
          	 #KEY f1_name (f1) INVISIBLE
          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
          SHOW CREATE TABLE t1;
          #SHOW INDEX FROM t1



          #添加一个唯一索引，并且隐藏
          ALTER TABLE t1
          ADD UNIQUE KEY f1_name (f1) INVISIBLE

          #添加一个普通索引，并且隐藏
          	#方式1
          	ALTER TABLE t1
          	ADD KEY f1_name (f1) INVISIBLE
          	#方式2
          	CREATE INDEX f1_name ON t1(f1) INVISIBLE



          #修改索引更改为显示索引
          ALTER TABLE t1
          ALTER INDEX f1_name VISIBLE

          #修改索引更改为隐藏索引
          ALTER TABLE t1
          ALTER INDEX f1_name invisible
        "
      索引设计原则:
        概述:
          - 增加索引好处，提高检索速度，避免全表扫描
          - 索引是一把双刃剑，可以提高查询效率，同时也会降低插入和更新的速度，并且占用磁盘空间
        单表最好不超过6个索引:
          - 每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大
          - 索引会影响INSERT、DELETE、UPDATE等语句的性能，因为表中的数据的更变，需要对每一个b-tree的维护
          - 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引进行评估，以生成出一个最好的执行计划，如何同时有很多个索引都可以用于查询，会增加MYSQL优化器生成执行计划时间，降低查询性能
        适合创建索引场景:
          - 具有唯一性的单列或多列必须增加索引(阿里巴巴规范)
          - 频繁作为WHERE查询条件的字段，可以考虑创建【普通索引】
          - 经常GROUP BY的列，可以建立单列普通索引或者联合普通索引(因为b-tree本身是有序，并且数据与数据之间挨着)
          - 经常ORDER BY的列，可以建立单列普通索引或者联合普通索引(因为b-tree本身是有序，并且数据与数据之间挨着)
          - 经常GROUP BY + ORDER BY的列，可以建立联合普通索引，索引顺序先GROUP BY后ORDER BY，MYSQL8.0可以考虑降序的索引(因为b-tree本身是有序，并且数据与数据之间挨着)
          - 对UPDATE和DELETE的WHERE过滤的列，可以考虑增加普通索引，如果UPDATE更新的是非索引列，提升的性能更加明显，因为不需要维护b-tree
          - 经常DISTINCT的列，可以考虑增加普通索引(因为b-tree本身是有序，并且数据与数据之间挨着)
          - JOIN表时，尽量不要超过3张表，可以考虑多ON的连接字段(连接字段类型必须保持一致，触发类型的隐式转换，可能造成索引失效)进行普通索引的创建，WHERE的字段也可以考虑创建普通索引
          - 列尽量考虑小的类型，如果可以用TINYINT就不用INT，非聚集索引或者聚集索引在创建的时候页的行数据能够存放更多，从而使得整颗b-tree更加扁平，减少IO次数，进而提升性能
          - "
            使用字符串前缀创建索引(对字符串的列进行索引的创建，必须制定索引的长度，阿里巴巴规范)，使用区分度公式[SELECT COUNT(DISTINCT LEFT(f1,20)) / COUNT(*) FROM t1]去推倒，越接近1的值越好。
            字符串前缀创建索引，存在一个隐患，SELECT * FROM t1 ORDER BY f1 ASC LIMIT 10 ，加入有20条数据的前10个都是一模一样，有可能查询出来的并非是升序的那10条
          "
          - 区分度高的列适合创建索引(比如，ID字段，没有一个重复)，区分度公式[SELECT COUNT(DISTINCT LEFT(f1,20)) / COUNT(*) FROM t1]去推倒，越接近1的值越好[一般超过33%的就算是区分度比较高了]
          - 创建联合索引时，尽量遵守最左前缀原则，比如 SELECT * FROM t1 WHERE f1 = 10 AND f2 = 20  那么创建联合索引的时候，索引顺序是先f1在f2。
          - 在多个列都要创建索引的情况下，优先考虑联合索引。
        不适合创建索引场景:
          - 没有在WEHRE、GROUP BY、ORDER BY出现的列不考虑索引
          - 数据量小于1000条的表最好不建立普通索引(主键索引还是需要的)，因为非聚集索引需要回表操作，有可能性能非但不提升，反而更慢，二来就是索引还会占用磁盘空间
          - "
            对区分度低的列不需要加索引
              比如10000条数据男女列各占50%，那么不需要增加索引
              比如10000条数据男女列，男占3%，那么刚好需要查询出男生人数，这种情况下可以考虑加
            在区分度为低于0.1的时候，也不需要增加索引，区分度公式[SELECT COUNT(DISTINCT LEFT(f1,20)) / COUNT(*) FROM t1]去推倒，越接近1，区分度大
          "
          - 避免对经常更新的列创建索引，因为索引类需要进行维护
          - 不建议使用无序的值作为索引(UUID MD5 HASH 无序字符串)，因为在插入数据的时候有可能造成页分裂
          - 删除不经常使用的索引，因为索引列在INSERT、DELETE、UPDATE的时候需要进行维护
          - "
            不要定义冗余的索引

            场景1
            DROP TABLE IF EXISTS t1;
            CREATE TABLE t1 (
            	 f1 INT,
            	 KEY f1_name1 (f1),
            	 UNIQUE KEY f1_name2 (f1)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            SHOW CREATE TABLE t1;
            #SHOW INDEX FROM t1

            场景2
            DROP TABLE IF EXISTS t1;
            CREATE TABLE t1 (
            	 f1 INT,
            	 f2 INT,
            	 KEY f1_f2_name (f1,f2),
            	 KEY f1_name (f1)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            SHOW CREATE TABLE t1;
            #SHOW INDEX FROM t1

          "
      性能参数:
        语法: SHOW [GLOBAL | SESSION] STATUS LIKE '%innodb_rows%'
        常用参数:
          - connections，连接MYSQL服务器的次数
          - uptime，MYSQL服务器一共运行了多久
          - slow_queries，慢查询SQL出现的次数
          - innodb_row_read，从innodb存储引擎读取了多少条记录
          - innodb_row_inserted，从innodb存储引擎插入了多少条记录
          - innodb_row_updated，从innodb存储引擎更新了多少条记录
          - innodb_row_deleted，从innodb存储引擎删除了多少条记录
          - com_select，查询操作的次数
          - com_insert，插入操作的次数(批量操作也只算一次)
          - com_update，更新操作的次数
          - com_delete，删除操作的次数
      查询成本参数:
        last_query_cost: "
          SHOW SESSION STATUS LIKE '%last_query_cost%'，用于对比sql执行的开销成本是很有帮助的
          last_query_cost，查看当前会话最后一次sql查询的成本(从多少页中才能拿到所有查询结果，值为页的数量)
        "
        profiling:
          概述:
            - Show Profile是MYSQL提供的可以用于分析当前会话中SQL执行消耗资源情况的工具，可以用于SQL调优测量，默认情况下处于关闭状态，并保存最近15次的运行结果
            - SHOW PROFILES最好在命令行中查看，效率最佳
          参数:
            ALL: 显示所有开销信息
            BLOCK IO: 显示块IO开销
            CONTEXT SWITCHES: 上下文切换开销
            CPU: CPU开销
            IPC: 显示发送和接收开销
            MEMORY: 显示内存开销
            PAGE FAULTS: 显示页面错误开销信息
            SOURCE: 显示source_function、source_file、source_line相关开销
            SWAPS: 显示交换次数开销
          使用: "
            #查看是否开启
            SHOW VARIABLES LIKE 'profiling'

            #开启
            SET GLOBAL profiling = ON;
            SET SESSION profiling = ON;
            #关闭
            SET GLOBAL profiling = OFF;
            SET SESSION profiling = OFF;

            #查看所有执行过的sql记录
            SHOW PROFILES

            #查询最近一次执行sql的情况
            SHOW PROFILE
            SHOW PROFILE CPU,BLOCK IO
            #查询指定某一次执行sql的情况
            SHOW PROFILE FOR QUERY 2
            SHOW PROFILE CPU,BLOCK IO FOR QUERY 58
          "
          经验分享: "
            如果在使用Show Profile诊断结果中出现了如下结果的任何一条，则SQL语句需要优化
              1.converting HEAP to MyISAM，查询结构太大，内存不够，数据往磁盘上搬了
              2.Creating tmp table，创建临时表，先拷贝数据到临时表，用完后在删除临时表
              3.Copying to tmp table on disk，把内存中临时表复制到磁盘上，警惕。
              4.locked
          "
        explain:
          概述:
            - explain可以查看sql执行计划，并且真实执行SQL。
            - MYSQL中有专门负责优化SELECT语句的优化器模块，主要通过计算分析系统中手机到的统计信息，为客户端请求的Query提供它认为最有的执行计划(数据认为最优的检索方式，不代表DBA认为最优)
            - 通过explain，可以查看表的读取顺序，数据读取操作的操作类型，哪些索引可以使用，哪些索引被实际使用，表之间的引用，每张表有多少行被优化器查询
          语法: [EXPLAIN | DESCRIBE | DESC] [FORMAT = [JSON | TREE] ] [SELECT | DELETE | UPDATE | INSERT | REPLACE]
          参数介绍:
            id:
              - 在一个查询语句中每个SELECT关键字对应一个唯一的ID
              - id如果相同，可以认为是一组，从上往下顺序执行
              - 在每组id中，id值越大，执行的优先级越高
              - 每个id号代表一次独立的查询，id号越少代表查询次数越少，性能更优
            select_type:
              - MYSQL为每个SELECT关键代表的小查询都定义了一个select_type的属性，意思是我们只要知道了某个小查询的select_type属性，就知道了这个小查询在整个大查询中扮演了一个什么角色
            table:
              - 在查询语句中，只要是一个表，就会出现一个表明
            partitions:
              - 代表分区表中的命中情况，非分区表，该项为NULL，一般情况下我们创建表都不划分区，所以执行计划的partitions值一般都是Null
            type(重点):
              - https://www.bilibili.com/video/BV1iq4y1u7vj/?p=137&spm_id_from=pageDriver&vd_source=cc17fab1d456bc3958dcb51e2fdd520b
              - 执行计划的每行记录代表着MYSQL对某个表的执行查询时候的访问方式，又称为访问类型，其中的type属性就表明了这个访问方式是什么，是比较重要的一个指标。例如type为ref，那么就代表mysql即将使用ref访问方式来执行查询
              - 访问方式 system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
              - 阿里巴巴规范要求SQL性能优化目标，最差的为range级别，最好的是const级别
            possible_key: 可能用到的索引
            key: 实际用到的索引，没使用到则为Null值
            key_len(重点):
              - 对于联合索引，这个选项比较有参考价值，值越大，证明越充分利用到了联合索引
              - 比如一个联合索引，一共有3列，分别为f1,f2,f3，假设总长度为99,如果key_len显示为66，那么只用到了索引的2个列，剩余的1个列没用到
              - 实际使用到的索引长度
              - "
                长度的计算
                  可以为空则+1字节，可变长类型则+2字节
                  如果是整形int，不允许为空，那么就是4个字节
                  如果是整形int，允许为空，那么就是4+1=5个字节
                  如果是整形varchar(10)，字符集utf8mb4，不允许为空，那么就是10*4+2=40个字节
                  如果是整形varchar(10)，字符集utf8mb4，允许为空，那么就是10*4+2+1=43个字节
              "
            ref: 当使用索引字段进行等值查询时，与索引列进行等值匹配的对象信息
            rows(重点):
              - 预估需要读取的记录条数
            filtered:
              - 剩余可用记录的百分比(结合rows筛选出来的记录，然后被过滤了多少条)
              - "
                对于单表查询来说，这个字段的值没什么意义，我们更关注的是在连接查询中，驱动表对应的执行计划记录的filtered值，它决定了被驱动表要执行的次数，即(rows * filtered)
                EXPLAIN SELECT * FROM t1 JOIN t2 ON t1.f1 = t2.f1 WHERE t1.fx = 'xxx'
              "
            Extra(重点): 该列是用来说明一些额外的信息，我们通过这些额外信息，能够更准确的知道MYSQL如何执行查询语句。
          SHOW WARNINGS: 可以在执行了explain语句后在执行，SHOW WARNINGS，可以看到执行计划优化过的sql语句(只能在命令行上执行才可以看到)
        结论: "
          sql查询是一个动态过程，从页加载的角度来看，得到如下2个结论
            1.位置决定效率，如果页就在数据库缓存池中，那么效率是最好的，否则还需要从内存或者磁盘中进行读取，
              当然针对单个页的读取来说，如果页存在于内存中，会比在磁盘中读取效率高很多
            2.批量决定效率，如果我们从磁盘中对单一页进行随机读取，那么效率是很低的(差不多10ms)，而采用顺序
              读取的方式，批量对页进行读取，平均每一页的读取效率就会提升很多，甚至要快于单个页面在内存中的随机读取。
          所以说，遇到I/O并不担心，方式找对了，效率还是很高的，我们首先要考虑数据存放的位置，如果是经常使用的数据就要尽量放到缓存池中，
          其次我们可以充分利用磁盘的吞吐能力，一次性批量读取数据，这样单个页的读取效率也就得到了提升。
        "
      慢查询日志:
        概述:
          - 默认情况下MYSQL关闭慢查询日志，如果不调优的情况下，建议关闭，因为开启慢查询日志会带来一定的性能影响
          - 慢查询 = long_query_time 和 min_examined_row_limit 2个变量确定，min_examined_row_limit默认为0，代表需要扫描多少条记录
        使用: "
          #临时设置
          	#查看慢查询日志是否开启，默认为关闭
          	SHOW GLOBAL VARIABLES LIKE '%slow_query_log%'
          	#开启慢查询日志
          	SET @@GLOBAL.slow_query_log = on

          	#查看慢查询日志存储在什么位置
          	SHOW GLOBAL VARIABLES LIKE '%slow_query_log_file%'
          	#删除慢查询日志文件直接rm -f /var/lib/mysql/a54e855addcf-slow.log
          		#重新生成慢查询日志文件
          		#方式1 利用SET @@GLOBAL.slow_query_log = on 重新关闭在打开就可以生成文件
          		#方式2 mysqladmin -uroot -p123456 flush-logs slow

          	#查看慢查询日志的时间，默认为10秒
          	SHOW SESSION VARIABLES LIKE '%long_query_time%'
          	#修改慢查询日志时间
          	SET SESSION long_query_time = 0.1

          	#查看出现过慢查询的次数
          	SHOW STATUS LIKE '%slow_queries%'

          #永久设置
          	#在my.ini文件中的[mysqld]配置项配置
          	#slow_query_log = on
          	#long_query_time = 3
          	#log_output = FILE
          	#slow_query_log_file = /root/slow.log


          # 查看慢查询日志
          #用参数代替变量
          # mysqldumpslow  -s t -t 5 /var/lib/mysql/a54e855addcf-slow.log
          #不用参数代替变量
          # mysqldumpslow -a -s t -t 5 /var/lib/mysql/a54e855addcf-slow.log
        "
      索引失效:
        概述:
          - 对于单列索引，尽量选择过滤性更好的列进行索引创建
          - 对于联合索引，在查询中过滤性最好的列应该在创建联合索引的时候放在最前
          - 对于联合索引，在查询中最好包含更多的索引列
          - 对于联合索引，如果某个字段可能出现范围查询，在创建索引的时候最好放在最后
        案例:
          左前缀法则-索引失效:
            - 左前缀法则主要针对是联合索引来说
            - 过滤条件要使用索引，必须按照联合索引建立的顺序，依次满足，一旦跳过某个字段，索引后面的字段可能无法使用索引
          运算、函数、类型转换(隐式或显示)-索引失效:
            - EXPLAIN SELECT  * FROM t1 WHERE LEFT(f1,1) = 'abc'，转换有可能导致索引失效
            - EXPLAIN SELECT  * FROM t1 WHERE f1+1 = 10，运算有可能导致索引失效
            - EXPLAIN SELECT  * FROM t1 WHERE f1 = 10，隐式类型转换有可能导致索引失效，本身f1就是字符串类型，但是值是整形，存在隐式转换
          范围条件-部分索引失效:
            - 范围条件也是针对联合索引来说
            - "
              假设联合索引(f1,f2,f3)
              导致f3失效
                WHERE f1=x AND f2>y AND f3=z，此种情况会导致f3索引列用不上，key_len的总长度不会计算f3列进去
              正确做法，重新创建索引为(f1,f3,f2)即可
            "
          (!=、<>)-索引失效:
            - EXPLAIN SELECT  * FROM t1 WHERE f1 != '10'
            - EXPLAIN SELECT  * FROM t1 WHERE f1 <> '10'
            - "
              假设f1为索引列
              EXPLAIN SELECT  f1,id FROM t1 WHERE f1 <> '10'，此种情况下用到了覆盖索引，索引不失效
            "
          IS NOT NULL-索引失效:
            - 最好在设计的时候就将该字段设置为NOT NULL约束，如果改列就需要空值，可以考虑使用整形的0或者空字符串进行填充
            - EXPLAIN SELECT  * FROM t1 WHERE f1 IS NOT NULL
          NOT LIKE-索引失效:
            - EXPLAIN SELECT  * FROM t1 WHERE f1 NOT LIKE 'xxx'
          NOT IN-索引失效:
            - EXPLAIN SELECT  * FROM t1 WHERE  f1 NOT IN ('1','2')
          NOT EXIST-索引失效:
            - EXPLAIN SELECT  * FROM t1 WHERE f1 = '1' AND NOT EXISTS (SELECT 1)，会导致f1的列的索引失效
          LIKE以(_、%)开头-索引失效:
            - 阿里规范，页面搜索严禁左模糊或者全模糊查询，如果有需要请走搜索引擎解决
            - EXPLAIN SELECT  * FROM t1 WHERE f1 LIKE '%xxx'
            - EXPLAIN SELECT  * FROM t1 WHERE f1 LIKE '_xxx'
            - "
              假设f1为索引列
              EXPLAIN SELECT f1 FROM t1 WHERE f1 LIKE '%xxx'，此种情况下用到了覆盖索引，索引不失效
            "
          OR前后存在非索引列-索引失效:
            - "
              假设，f1为索引列，f2为非索引列
                EXPLAIN SELECT  * FROM t1 WHERE f1 = 'x' OR f2 = 'y'
              正确做法，为f2也加上索引列，(f1,f2)索引可以同时生效。

            "
          数据库和表的字符集不统一-索引失效:
          - 数据库、表、列字符集最好统一，避免由于字符集的转换，进行比较的有可能会造成索引失效
      连接查询以及子查询优化:
        连接查询优化:
          外连接:
            - 在做关联查询时，尽量考虑为被驱动表的字段加上索引，性能上所有提升
            - SELECT * FROM t1 LEFT JOIN t2 ON t1.f1 = t2.f1，此时最好为 t2.f1加上索引
            - "
              EXPLAIN SELECT  * FROM t1 LEFT JOIN t2 ON t1.f1 = t2.f1 WHERE t1.f2 = t2.f2 此语句会被优化器优化成内连接，可以通过 SHOW WARNINGS(需要在命令行才能看到)进行查看。
            "
          内连接:
            - 当表都有索引或者都没索引时，小表成为驱动表，大表成为被驱动表，也就是小表驱动大表（小表深层意思就是，实际结果集小并且行的数据量也要小）
            - 当某一个表有索引，另一个表没索引，那有索引的表成为被驱动表
            - SELECT * FROM t1 INNER JOIN t2 ON t1.f1 = t2.f1，此时，如果t1.f1上有索引，那么t1会成为被驱动表（通过执行计划可以看出，优化器会作出相应的优化）
          底层原理:
            概述:
              - JOIN方式连接多个表，本质就是各个表之间数据的循环匹配。
              - 从性能角度 索引嵌套循环连接 > 块嵌套循环连接 > 简单全套循环连接
              - 用为被驱动表匹配的条件增加索引(减少内层表的循环匹配次数)
              - 增加join_buffer_size的大小(一次性缓存的数据越多，那么内层表的扫描次数就越少，I/O次数也会相应的减少)
              - 减少驱动表不必要的字段查询(字段越少，JOIN Buffer所缓存的数据就越多)
            简单全套循环连接(Simple Nested-Loop Join)-两表没索引: "
              简单全套循环连接(Simple Nested-Loop Join)方式算法相当简单，从驱动表中取出一条数据，然后遍历整个被驱动表，将匹配到的
              数据放到结果集中，以此类推，驱动表中的每一条记录与被驱动表的记录进行匹配，可以说这种方式效率是非常低的。
            "
            索引嵌套循环连接(Index Nested-Loop Join)-被驱动表有索引: "
              索引嵌套循环连接(Index Nested-Loop Join)方式，其优化的思路主要是为了减少内层表数据的匹配次数，所以要求被驱动表
              上必须有索引才行。通过外层表匹配条件直接与内层表索引进行匹配，避免和内层表的每条记录去进行比较，这样极大的减少了对内层
              表的匹配次数。
            "
            块嵌套循环连接(Block Nested-Loop Join)-两表没索引: "
              如果存在索引，那么会使用索引嵌套循环连接(Index Nested-Loop Join)方式，如果没有索引，被驱动表要扫描的次数太多了。
              每次访问被驱动表，其表中的记录都会被加载到内存中，然后在从驱动表中取一条与其匹配，匹配结束后清除内存，然后在从驱动表中
              加载一条记录，然后把被驱动表的记录在加载到内存，这样周而复始，大大增加了I/O次数。为了减少被驱动表的I/O次数，就出现了
              块嵌套循环连接(Block Nested-Loop Join)的方式。

              块嵌套循环连接(Block Nested-Loop Join)方式不再是逐调获取驱动表的数据，而是一块一块的获取，引入了JOIN Buffer缓冲区，
              将驱动表JOIN相关的部分数据列(SELECT部分+ON部分)缓存到JOIN Buffer中(大小受JOIN Buffer限制)，然后全表扫描被驱动表，被驱动表的每一条记录一
              次性和JOIN Buffer中的所有驱动表记录进行匹配(内存中操作)，将简单嵌套循环中的多次比较合并成一次，降低了被驱动表的访问频率。

              注意:
                缓存的不知识关联表的列，SELECT包含的所有列都会缓存起来
                在N个JOIN关联的SQL中，会分配N-1和JOIN Buffer，所以在查询的时候尽量减少不必要的字段，让JOIN Buffer中可以存放更多的列。
            "
            设置: "
              # block_nested_loop=on 默认为开去状态
              SHOW VARIABLES LIKE '%optimizer_switch%'

              当optimizer_switch为打开状态，JOIN都没索引，或索引失效的时候，会使用，块嵌套循环连接(Block Nested-Loop Join)方式。
              然后就会用到JOIN Buffer了，此时，join_buffer_size默认为256K，可以设置大一些提高查询效率。
              SHOW VARIABLES LIKE '%join_buffer_size%'

              总结：
                驱动表能不能一次加载完，要看join_buffer_size能不能存储所有的数据，Linux系统64位可以申请大于4G
            "
            MYSQL8.0(HASH JOIN):
              - MYSQL8.0版本开始废弃块嵌套循环连接(Block Nested-Loop Join)，默认会使用HASH JOIN
              - HASH JOIN是做大数据集连接时的常用方式，优化器使用两个表中较小(相对较小)的表利用JOIN KEY在内存中建立散列表，然后扫描交大的表并探测散列表，找出玉Hash表匹配的行。
              - 这种方式使用于较小的表完全可以放于内存中的情况，这样总成本就是访问两个表的成本之和
              - 在表很大的情况下，并不能完全放入内存，这时优化器会将它分割成若干不同的分区，不能放入内存的部分就把该部分写入磁盘的临时段，此时要求有交大的临时段从而尽量提高I/O的性能
              - 它能够很好的工作于没有索引的大表和并行查询的环境中，并提供最好的性能。大多数人都说他是JOIN的重型升降机。HASH JOIN只能应用于等值连接(如WHERE t1.f1=t2.f1)，这是由HASH的特点决定的。
        子查询优化:
          概述:
            - 执行子查询时，MYSQL需要为内层查询语句的查询结果建立一个临时表，然后外层查询语句从临时表中查询记录。查询完成后，在撤销临时表，这样会消耗过多的CPU和IO资源，产生大量的慢查询。
            - 子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。
            - 对于返回结果集比较大的子查询，其查询性能的影响也就越大
          总结:
            - 可以使用连接查询(INNER JOIN OR LEFT JOIN)来代表子查询，连接查询不需要建立临时表，其速度比子查询要快，如果查询中使用索引的话，性能就会更佳。
            - 尽量不要使用NOT IN或者NOT EXISTS，用LEFT JOIN xx ON xx WHERE xx IS NULL代替
        ORDER BY优化:
          概述:
            - 在MYSQL中支持两种排序方式，分别是FileSort和Index排序，尽量使用Index排序，避免使用FileSort排序。
            - Index排序，索引可以保证数据的有序性，不需要再进行排序，效率高
            - FileSort排序则一般在内存中进行排序，占用CPU较多，如果待排序结果集较大，会产生临时文件IO到磁盘进行排序的情况，效率较低。
          索引失效案例: "
            假设联合索引(f1,f2)
            ORDER BY f1 ASC,f2 ASC，不失效
            ORDER BY f1 DESC,f2 DESC，不失效
            ORDER BY f1 ASC,f2 DESC，失效
          "
          FileSort排序算法:
            概述:
              - 当ORDER BY的字段是非索引列，则会用到FileSort排序
            双路排序(性能慢):
              - 双路排序会使用两次扫描磁盘(消耗多次IO)，最终得到数据，读取行指针和ORDER BY列，对它们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出
              - 从磁盘取排序字段，在Buffer进行排序，在从磁盘读取其它字段。
              - 二次IO读取数据时用了随机IO，因为排序好的数据都是在不同页里面了
            单路排序(性能快):
              概述:
                - 从磁盘读取查询需要的所有列，按照ORDER BY列在Buffer中进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了二次读取数据。
                - 单路排序会占用更多内存，因为一次把数据全部加载到Buffer中。
                - 单路排序使用了顺序IO，因为一次加载，页之间大部分都是相连的
              存在问题: "
                因为单路排序是把所有字段都取出，所以有可取出的数据总大小超出了sort_buffer的容量，
                导致每次只能取sort_buffer容量大小的数据进行排序(创建tmp文件，多路合并)，进而产
                生多次IO(单路本来想节省1次IO操作，反而导致了多次IO)。
              "
            优化策略: "
              SHOW VARIABLES LIKE '%innodb_sort_buffer_size%'
                不管使用哪种算法，提高这个参数都会提高效率，要根据系统的能力去提高，因为这个参数是针对每个进行(connection)的1M-8M之间调整。MYSQL5.7在InnoDB存储引擎默认为1MB

              SHOW VARIABLES LIKE '%max_length_for_sort_data%'
                提高这个参数，会增加用单路排序算法的概率，但是如果设的太高，数据容量超出了innodb_sort_buffer_size的概率就增大，明显症状是高的磁盘IO活动合底的处理器使用率。
                如果需要返回的列的总长度大于max_length_for_sort_data，使用双路排序，否则使用单路排序,1024-8192字节之间调整

              在进行OREDER BY时，SELECT * 是一个大忌，最好只选择必要的字段，原因如下
                当SELECT的字段大小总和小于max_length_for_sort_data，而排序字段不是TEXT、BLOB类型时没会用单路排序，否则用多路排序
                两种算法的数据都有可能超出innodb_sort_buffer_size的容量，超出之后，会创建temp文件进行合并排序，导致出现多次IO，但是
                用单路排序算法的风险会更大一些，所以要提高innodb_sort_buffer_size
            "
          优化建议:
            - SQL中，可以在WHERE子句和ORDER BY子句中使用索引，在WHERE子句中使用索引避免了全表扫描，在ORDER BY子句中使用索引避免FileSort排序。(某些场景全表扫描或者FileSort排序不一定比索引慢)
            - 尽量使用Index完成ORDER BY排序，如果WHERE和ORDER BY后面是相同的列就使用单列索引，如果是不同的列就使用联合索引。
            - 在某些场景无法使用Index排序时，可以考虑对FileSort方式进行调优
        GROUP BY优化:
          - GROUP BY使用索引的规则几乎跟ORDER BY一致，GROUP BY即使在HAVING过滤条件没有用到索引，也可以直接使用索引
          - GROUP BY遵守索引创建的最佳左前缀法则
          - 当无法使用索引列时，增大max_length_for_sort_data和innodb_sort_buffer_size参数的设置
          - WHERE效率高于HAVING，能写WHERE就不要写HAVING(聚合函数例外)
          - 减少使用GROUP BY、ORDER BY、DISTINCT，这些语句比较消耗CPU
          - 如果使用了GROUP BY、ORDER BY、DISTINCT，尽量用WHERE条件进行过滤，过滤出的数据最好保持在1000行以内，否则SQL会很慢
      覆盖索引:
        概述: "
          覆盖索引在非聚集索引的情况下出现，并且它是一个联合索引，假设联合索引为(f1,f2)，主键为id，如下案例都用到覆盖索引
          SELECT f1 FROM t1 WHERE f1 = xxx
          SELECT f1,f2 FROM t1 WHERE f1 = xxx
          SELECT f1,f2,id FROM t1 WHERE f1 = xxx
        "
        好处:
          - 避免InnoDB表进行索引的二次查询(回表操作)
          - 减少了IO操作，并且还减少了随机IO操作(回表操作是一次随机IO操作，因为非聚集索引的b+tree和聚聚索引的b+tree存储数据是不一致的)
        坏处:
          - 索引字段的维护需要成本，不要盲目的为了覆盖索引而去建立索引(看业务具体情况而定)
      索引条件下推(索引下推):
        概述:
          - Index Condition Pushdown(ICP)，是一种在存储引擎层使用索引过滤数据的优化方式，能够使用到索引条件下推性能提升很大
          - 通过EXPLAIN的Extra字段可以看到 Using Index condition提示信息
          - 索引下推原理就是，尽量在该非聚集索引下把所有的过滤都完成，然后在做回表操作，可以减少回表次数(回表会产生随机IO，变向减少随机IO)
        场景: "
          假设主键列id，和单列索引f1，这中情况出现索引条件下推
            SELECT * FROM t1 WHERE f1 > xx AND f1 LIKE '%xx%'

          假设主键列id，和联合索引f1，f2,这中情况出现索引条件下推
            SELECT * FROM t1 WHERE f1 > xx AND f2 LIKE '%xx%'
        "
        开启和关闭: "
          #查看优化器参数
          SHOW GLOBAL VARIABLES LIKE '%optimizer_switch%'
          SHOW SESSION VARIABLES LIKE '%optimizer_switch%'

          #开启，默认为开启状态
          SET GLOBAL optimizer_switch = 'index_condition_pushdown=on'
          SET SESSION optimizer_switch = 'index_condition_pushdown=on'

          #关闭
          SET GLOBAL optimizer_switch = 'index_condition_pushdown=off'
          SET SESSION optimizer_switch = 'index_condition_pushdown=on'
        "
        ICP的使用条件:
          - 如果表访问的类型为range、ref、eq_ref、ref_or_null可以使用ICP
          - ICP可以用于InnoDB和MYISAM表，包括分区InnoDB表和分区MYISAM表
          - 对于InnoDB表，ICP仅用于非聚集索引，ICP的目标是回表的产生的随机IO次数
          - 当SQL使用覆盖索引时，不支持ICP，因为这种情况下使用ICP不会减少IO(覆盖索引不产生回表操作)。
          - 相关子查询的条件不能使用ICP
      其他优化案例:
        EXISTS和IN: "
          什么时候适合使用EXISTS和IN，可以利用小表驱动大表方式。
            当t1为小表，t2为大表，在IN中最好使用较小的表
            SELECT * FROM t2 WHERE t2.f1 IN (SELECT t1.f1 FROM t1)

            当t1为小表，t2为大表，在EXISTS中最好使用较大的表
            SELECT * FROM t1 WHERE EXISTS (SELECT xx FROM t2 WHERE t2.f1 = t1.f1)
        "
        COUNT(*)和COUNT(1)和COUNT(字段)效率: "
          前提是COUNT(字段)，如果改字段有Null值是不会统计的，现在是默认都为非Null的值。

            1.COUNT(*)和COUNT(1)都是对所有结果进行统计，COUNT(*)和COUNT(1)本质上并没有区别，二者执行是可以可能略有区别。
              如果有WHERE子句，则是对所有符合筛选条件的部分数据进行统计，如果没有WHERE子句，则是对整张表进行统计

            2.如果是MYISAM存储引擎，统计数据表的行数为O(1)时间复杂度，因为每张MYISAM的数据表都有一个meta信息存储了row_count值，而一致性则由表级锁来保证。
              如果是InnoDB存储引擎，因为InnoDB支持事务，采用行级锁和MVCC机制，所以无法像MYISAM一样维护一个row_count变量，因此需要采用全表扫描，所以时间
              复杂度为O(n)，进行循环+计数的方式来完成统计。

            3.在InnoDB存储引擎中，如果采用COUNT(字段)，尽量采用非聚集索引，因为主键采用的是聚集索引，而聚集索引包含的数据比较多，对于COUNT(*)和COUNT(1)来说，
              他们不需要查找具体的行，只是统计行数，系统会自动采用占用空间更小的非聚集索引来进行统计。如果有多个二级索引，会使用key_len小的二级索引进行扫描，当没
              有二级索引的时候，彩会财通聚集索引进行行统计

            结论，最好使用COUNT(1)，其次是COUNT(*),最后COUNT(字段)，如果你很清楚哪个索引较小，可以考虑使用COUNT(字段)，因为减少了系统找出最小索引
        "
        关于SELECT(*): "
          在表查询中，建议明确字段，不要使用*作为查询的字段列表，原因如下
            1.在MYSQL解析的过程，会通过查询数据字段将*按表转换成所有列名，这样会大大的消耗资源和时间。
            2.无法使用覆盖索引
        "
        LIMIT 1对优化的影响: "
          1.针对全表扫描的SQL语句，如果你可以确定结果集只有1条数据，那么加上LIMIT 1的时候，当找到一条数据的时候就不会继续扫描了，这样会加快查询速度
          2.如果数据已经对该字段建立了唯一索引，那么课题通过索引进行查询，就不需要加上LIMIT 1了(因为唯一索引当找到1条数据的时候就立即停止扫描)
        "
        多使用COMMIT: "
          只要有可能，在程序中尽量多使用COMMIT，这样程序的性能得到提高，需求也会因为COMMIT所释放的资源而减少。
          COMMIT会释放如下资源
            1.回滚段上用于恢复数据的信息
            2.被程序语句获得的锁
            3.redo log buffer 和 undo log buffer 中的空间
            4.管理上述3种资源中的内部花费
        "
  主键设计:
    概述:
      - 主键值禁止被更新
    非核心业务:
      - 可以考虑主键自增ID，如告警，日志，监控等。
    核心业务:
      - 主键设置应该是全局唯一，并且单调递增(避免b-tree页分裂，性能损失)。
      - 可以考虑雪花ID，或者UUID，前提必须保证是单调递增
数据库设计规范:
  概述:
    - 在关系型数据库中，关于数据表设计的准本原则、规则就成为范式(Normal Form，简称NF)
    - 从低到高，越往后越完美，如果某个设计遵守了某一个范式，那么它也遵守了前面的范式。
    - 一般来说，在关系型数据库设计种，最高也就遵循到BCNF，普遍还是3NF。
    - 如果特殊的业务需求，有可能位了提高查询性能，我们还需要破坏范式规则，也就是反范式化。
    - 非凡士本身没有优劣之分，只有使用场景不同。没有完美的设计，只有合适的设计，在数据表设计，还需要根据需求将范式化和反范式化混合使用。
  键和属性的概念: "
    假设2张表分别为
      球员表：球员编号 | 姓名 | 身份证号 | 年龄 | 球队编号
      球队表：球队编号 | 教练 | 所在地

      超键：对于球员表，超键就是包括球员编号或者身份证号的任何组合，比如（球员编号+姓名）（身份证号+年龄）
      候选键：对于球员表，候选键就是（球员编号）或者（身份证号），候选键就是最小的超键
      主键：对于球员表，主键是（球员编号）或者（身份证号）
      外键：对于球队表，外键是（球队编号）
      主属性：对于球队表，主属性是（球员编号）或者（身份证号）
      非主属性：对于球队表，非主属性是（姓名）或者（年龄）或者（球队编号）
  "
  范式化vs反范式化:
    范式化:
      级别:
        第一范式(1NF): 确保每个字段保持原子性
        第二范式(2NF): 确保每个字段都和主键完全依赖
        第三范式(3NF): 确保每个字段都和主键直接相关(非主属性列之间不能相互依赖)
        巴斯-科德范式(BCNF):
        第四范式(4NF):
        第五范式(5NF):
      范式优点:
        - 数据标准化有助于消除数据库中的数据冗余，第三范式通常被认为在性能、扩展性、数据完整性方面达到了最好的平衡点
      范式缺点:
        - 范式级别越高，查询效率越低。
        - 范式级别越高，意味着拆出来的表就越多，在进行查询的时候需要JOIN表查询或者子查询，并且操作不当会造成索引失效。
    反范式化:
      概述:
        - 反范式化可以通过空间换取时间，增加冗余字段(存储空间变大)，提升查询效率。
        - 在数据量小的情况下，反范式化不能体现优势
      优点:
        - 提升查询效率
      缺点:
        - 存储空间变大
        - 因为冗余字段的存储，每次更新都需要额外一次更新
      增加冗余字段的建议:
        - 这个冗余字段不经常修改
        - 这个冗余字段在查询中必须出现
    选择场景:
      - 对于数据实时性要求强的情况下，选择范式化(经常增删改)
      - 对于数据实时性要求不强的情况下，选择反范式化(历史数据、快照数据)
  E-R模型(Entity-Relationship):
    概述:
      - E-R建模，简称实体关系模型
      - ER模型3中元素，实体(矩形)，属性(椭圆形)，关系(菱形)
      - 关系表示，1对1(1:1)，1对多(1:N)，多对多(N:M)
调优篇:
  概述:
    - 调优目的是达到，低延迟高吞吐
  MYSQL服务器参数优化:
    概述:
      - 将参数配置在my.cnf的[mysqld]配置中
    参数:
      innodb_buffer_pool_size: "
        这个参数是MYSQL数据最重要的参数之一，表示InnoDB类型的表和索引的最大缓存。
        它不仅仅缓存索引数据，还会缓存表的数据。这个值越大，查询的速度就会越快。但
        是这个值太大会影响操作系统的性能。
      "
      key_bufffer_size: "
        表示索引缓冲区的大小。索引缓冲区是所有的线程共享。增加索引缓冲区可以得到更好处理的索引(对虽有读和多重写)。
        当然，这个值不是越大越好，它的大小取决于内存的大小。如果这个值太大，就会导致操作系统频繁换页，也会降低系统
        性能。对于内存在4GB左右的服务器该参数可以设置为256M或384M。
      "
      table_cache: "
        表示同时打开表的个数。这个值越大，同时打开表的个数越多。如果物理内存越大，就设置越大。
        默认为2402，调到512-1024最佳。这个值不是越大越好，因为同时打开的表太多会影响操作系统性能。
      "
      query_cache_size: "
        表示查询缓冲区的大小。可以通过在MYSQL控制台观察，如果Qcache_lowmem_prunes的值非常大，则
        表明经常出现缓冲不够的情况，就要增加Query_cache_size的值。如果Qcache_hits的值非常大，则表
        明查询缓冲使用非常频繁，如果该值较小反而会影响效率，那么可以考虑不使用查询缓存。Qcache_free_blocks如果
        该值非常打，则表明缓冲区碎片很多。该值在MYSQL8.0之后失效。该参数需要query_cache_type参数打开启动才生效，否则只会占用空间，但不生效
      "
      query_cache_type: "
        该值为0时，所又的查询都不使用查询缓存区。但是query_cache_type = 0并不会导致MYSQL释放query_cache_size所配置的缓冲区内存。
        当query_cache_type = 1时，所有查询都将使用查询缓存区，除非在查询语句中指定SQL_NO_CACHE，如 SELECT SQL_NO_CACHE * FROM t1
        当query_cache_type = 2时，只有在查询语句中使用SQL_CACHE关键字时，才会使用查询缓存区。使用查询缓存区可以提高查询速度，如 SELECT SQL_CACHE * FROM t1
      "
      sort_buffer_size: "
        表示每个需要进行排序的线程分配的缓冲区的大小。增加这个参数的值可以提高ORDER BY、GROUP BY操作的速度。
        默认值是2097144字节(约2MB)，对于内存在4GB左右的放服务器推荐设置为6-8MB，如果有100个连接，那么实际
        分配的总共排序缓冲区大小为100*6=600MB。
      "
      join_buffer_size: "
        表示联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。默认为(262144)
      "
      read_buffer_size: "
        表示每个线程连续扫描时扫描的每个表分配的缓冲区的大小(字节)。当线程
        从表中连续读取记录时需要用到这个缓冲区。默认为64K，可以设置为4M。
      "
      innodb_flush_log_at_trx_commit(☆): "
        值为0时
          只能依靠master thread每隔1秒中进行一次重做日志的fsync操作，master thread是负载将换缓冲池中的数据异步刷新到磁盘。
          如果出现数据库挂或者服务器宕机，会丢失1秒的数据，这种情况下无法满足ACID中的D。
        值为1时(默认值)
          只要提交事务成功，就会立即刷盘，REDO LOG记录就一定在硬盘里面，就算操作系统宕机或者数据库挂了，也不会有任何数据丢失风险。
        值为2时
          只要事务提交成功，REDO LOG Buffer中的内容只写入文件系统缓存(page cache)
          如果仅仅只是MYSQL挂了，不会有任何数据丢失，但是操作系统宕机可能会有1秒数据的丢失(master thread会隔1秒做一次刷盘)，这种情况下无法满足ACID中的D。
      "
      innodb_log_buffer_size: "
        这是InnoDB存储引擎的事务日志所使用的缓冲区。为了提高性能，也是先将信息写入InnoDB Log Buffer中，
        当满足innodb_flush_log_at_trx_commit参数所设置的相应条件(或者日志缓冲区写满)之后，才会将日志写到文件(或者同步到磁盘)中。
      "
      innodb_buffer_pool_instances: "
        这个参数可以将InnoDB的缓存区分成几个部分，这样可以提高系统的并行处理能力，因为可以允许多个进行同时处理不同部分的缓存区。
        默认值为1，当修改为64时，意思就是把InnoDB的缓存区分成64个分区，这样就可以同时有多个进行进行数据操作，CPU的效率就高多了。
      "
      max_connections: "
        表示允许连接到MYSQL数据库的最大连接数量，默认是151。
        如果SHOW STATUS LIKE '%Connection_errors_max_connections%'不为0时，并且一直增长，有连接已经超出了max_connections的最大值而导致的失败。
        这个时候可以考虑增加max_connections的值。在Linux平台下，性能好的服务，支持500-1000个连接不是难事，需要根据服务器性能进行评估设定。这个连接数不是
        越大越好，因为这些连接会浪费内存的资源，过多的连接可能会导致MYSQL服务器僵死。
      "
      back_log: "
        如果需要数据库在较短的时间内处理大量连接请求，可以考虑适当增加back_log的值。
        用于控制MYSQL监听TCP端口时设置的积压请求栈大小。如果MYSQL的连接数达到了max_connections时，新来的请求
        将会被存在堆栈中，以等待某一连释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授
        予连接资源，将会报错。对于Linux系统推荐设置小于512，但最大不超过900。
      "
      thread_cache_size: "
        线程池缓存线程数量的大小，当客户端断开连接后将当前线程缓存起来，当在接到新的连接请求时快速响应无序创建新的线程。
        这尤其对那些使用短连接的应用程序来说可以极大的提高创建连接的效率。那么为了提高性能可以增大该参数的值。默认为60，可以设置为120。

        通过观察 SHOW GLOBAL STATUS LIKE 'Thread%'，
          当Threads_cached越来越小，Threads_connected始终不降，并且Threads_created持续提升，可以增加thread_cache_size的大小。
      "
      wait_timeout: "
        指定一个请求的最大连接时间，对于4GB左右内存的服务器可以设置5-10
      "
      interactive_timeout: "
        表示服务器在关闭连接前等待行动的秒数
      "
  分析表:
    概述:
      - ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE t1,t2,...(加上LOCAL或者NO_WRITE_TO_BINLOG，代表不写入binlog日志)
      - ANALYZE TABLE在执行过程中会给表加上只读锁(意味着在执行过程中不允许DML操作)
      - ANALYZE TABLE适用于InnoDB和MYISAM
    案例: "
      DROP TABLE IF EXISTS t1;
      CREATE TABLE IF NOT EXISTS t1(
      	id int,
      	salary DECIMAL(10,2),
      	last_name VARCHAR(255),
      	KEY (last_name)
      ) ENGINE INNODB;


      DROP PROCEDURE IF EXISTS batch_insert;
      DELIMITER $
      CREATE PROCEDURE batch_insert()
      BEGIN
      	DECLARE count INT DEFAULT 0;
      	loop_label:LOOP

      			IF count > 1000 THEN LEAVE loop_label;
      			ELSE INSERT INTO t1(id,salary,last_name) VALUES(count,count*10,'eric');
      			END IF;
      			SET count = count + 1;

      	END LOOP loop_label;

      END $

      DELIMITER ;

      CALL  batch_insert();

      SELECT * FROM t1;

      SELECT COUNT(1) FROM t1;

      #查看区分度的字段Cardinality，这个值越接近总记录数，证明区分度越高，此时的索引越有价值。
      SHOW INDEX FROM t1;

      #总记录数为10001，但是Cardinality的值只有1，做一次更行
      UPDATE t1 SET last_name = 'eric2' WHERE id = 2;

      #此时如果执行了，那么就会立即更行Cardinality的字段值。
      ANALYZE TABLE t1;
      #重新查看了以后Cardinality的值发生了改变
      SHOW INDEX FROM t1;
    "
  优化表:
    概述:
      - OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE t1,t2,...(加上LOCAL或者NO_WRITE_TO_BINLOG，代表不写入binlog日志)
      - OPTIMIZE TABLE在执行过程中会给表加上只读锁(意味着在执行过程中不允许DML操作)
      - OPTIMIZE TABLE适用于InnoDB和MYISAM
      - 如果经常多删除和更新操作，产生了大量的空间碎片。使用 OPTIMIZE TABLE t1来重新利用未使用的空间，并整理数据文件的碎片(可以对VARCHAR、BLOB、TEXT类型的字段进行优化)
    案例:
      - "
        DROP TABLE IF EXISTS t1;
        CREATE TABLE IF NOT EXISTS t1(
          id int,
          salary DECIMAL(10,2),
          last_name VARCHAR(255)
        );


        DROP PROCEDURE IF EXISTS batch_insert;
        DELIMITER $
        CREATE PROCEDURE batch_insert()
        BEGIN
          DECLARE count INT DEFAULT 0;
          loop_label:LOOP

                  IF count > 100000 THEN LEAVE loop_label;
                  ELSE INSERT INTO t1(id,salary,last_name) VALUES(count,count*10,CONCAT('eric',count));
                  END IF;
                  SET count = count + 1;

          END LOOP loop_label;

        END $

        DELIMITER ;

        CALL  batch_insert();

        SELECT COUNT(1) FROM t1;

        DELETE FROM t1 WHERE id > 20000 AND id < 40000;

        OPTIMIZE TABLE t1;
      "
      - "
        可以使用命令行方式进行优化表-o代表optimize
          方式1，优化某一个表
            mysqlcheck -o 数据库 表名 -uroot -p123456
          方式2，优化全部表，因为要加读锁，谨慎执行
            mysqlcheck -o --all-databases -uroot -p123456
      "
事务篇:
  概述:
    - 事务是数据库区别于文件系统的重要特性之一，当我们有了事务就会让数据库始终保持一致性。
    - 我们还能通过事务的机制恢复到某个时间点，这样可以保证已提交到数据库的修改不会因为系统崩溃而丢失。
    - 事务是一组逻辑操作单元，使数据从一种状态变换到另一种状态。
    - 目前只有InnoDB存储引擎支持事务(SHOW ENGINES)
  事务ACID特性:
    概述:
      - ACID是事务的四大特性，原子性是基础，隔离性是手段，一致性是约束条件，持久性是目的。
      - 事务隔离性是由锁来实现的
      - 事务持久性是由REDO LOG实现的
      - 事务原子性、一致性是由UNDO LOG实现的
      - REDO LOG(重做日志)和UNDO LOG(回滚日志)都是一种【恢复操作】
    原子性(atomic): "
      原子性是指事务是一个不可分割的工作单位，要么全部提交(commit)，要么全部失败(rollback)

      案例
        A账户向B账户转账，要么转账成功，要么转账失败，是不存在中间状态。
    "
    一致性(consistency): "
      一致性是指事务执行前后，数据从一个合法性状态变换到另一个合法性状态。这种状态是语义上的，而不是语法上的，跟具体的业务有关。
      什么是合法性状态？满足预定约束的状态就叫合法状态。通俗一点，这个状态是由你自己来定义的。满足这个状态，数据就是一致性的，不
      满足这个状态，数据就是不一致性的。如果事务中的某个操作失败了，系统就会自动撤销当前执行的事务，返回到事务操作之前的状态。

      案例1：
        A账户有200块，转账300块出去，此时A账户余额为-100块。此时这个数据就不是一致性的，因为你定义了一个状态余额必须>=0
      案例2：
        A账户有200块，转账50块给B账户，A扣钱了，B因为意外，余额并没有增加。此时这个数据就是不一致性的，因为你定义了一个状态，要求A+B的总余额必须跟原来一样。
      案例3：
        在数据表中我们将f1字段设置了唯一约束，当事务进行提交或回滚的时候，如果数据表中的f1产生了相同的数据，此时这个数据就是不一致性的，因为你定义了一个状态f1字段必须唯一。
    "
    隔离性(isolation): "
      隔离性是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间互不干扰。
    "
    持久性(duration): "
      持久性是指一个事务一旦被提交，它对数据库中数据的改变是永久性的。接下来的其他操作和数据库故障不应该对其有任何影响。
      持久性是通过事务日志来保证的。日志包括了redo(重做日志)和undo(回滚日志)。当我们通过事务对数据进行修改的时候，首
      先会将数据库的变化信息记录到重做日志中，然后在对数据库中对应的行进行修改。这样做的好处是，即使数据系统崩溃，数据库
      重启后也能找到没有更新到数据库系统中的重做日志，进行重新执行，从而使事务具有持久性。
    "
  事务状态:
    活动状态(active): 事务对应的数据库操作正在执行过程中
    部分提交状态(partially committed): 当事务中一个或N个操作执行完成时，并没有刷新到磁盘(操作都在内存中执行)
    失败状态(failed): 当事务处于活动状态或者部分提交状态时，遇到某些错误(数据库自身错误、操作系统错误、断电、宕机、人为中止)导致失败
    中止状态(aborted): 当事务处于失败状态时，就需要做回滚操作，此时事务处于中止状态
    提交状态(committed): 当事务将修改过的数据都同步到磁盘上时，此时事务处于提交状态
  事务使用案例: "
    DROP TABLE IF EXISTS t1;
    CREATE TABLE IF NOT EXISTS t1(
    	id int,
    	salary DECIMAL(10,2),
    	last_name VARCHAR(255),
    	KEY (last_name)
    ) ENGINE INNODB;


    DROP PROCEDURE IF EXISTS batch_insert;
    DELIMITER $
    CREATE PROCEDURE batch_insert()
    BEGIN
      DECLARE count INT DEFAULT 0;
      loop_label:LOOP
        IF count > 10 THEN LEAVE loop_label;
        ELSE INSERT INTO t1(id,salary,last_name) VALUES(count,count*10,'eric');
        END IF;
        SET count = count + 1;
      END LOOP loop_label;
    END $
    DELIMITER ;
    CALL  batch_insert();
    SELECT * FROM t1;

    #------------------------------------------------------------------------------
    #设置隔离级别
    #MYSQL5.7.20，transaction_isolation替换了tx_isolation
    	#方式1
    	  #SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL [READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE]
    	#方式2，在my.cnf中的mysqld中配置
    	  #transaction_isolation = SERIALIZABLE
    	#方式3
          SET SESSION transaction_isolation = 'READ-UNCOMMITTED'
          SET SESSION transaction_isolation = 'READ-COMMITTED'
          SET SESSION transaction_isolation = 'REPEATABLE-READ'
          SET SESSION transaction_isolation = 'SERIALIZABLE'

    #查看隔离级别
    	SHOW SESSION VARIABLES LIKE '%transaction_isolation%'

    #开启事务，
    #针对DML操作有效，针对DDL操作无效
      #显式事务
        #重复的开启事务会导致上一次事务被提交
        #方式1
        #BEGIN;
        #方式2(默认)，开启一个读写事务
        START TRANSACTION; #START TRANSACTION READ WRITE;
        #方式3，开启一个只读事务，不允许写操作
        #START TRANSACTION READ ONLY;
        #方式4，开启一个只读事务和一致性读，不允许写操作
        #START TRANSACTION READ ONLY,WITH CONSISTENT SNAPSHOT;
        #方式5，开启一个读写事务和一致性读
        #START TRANSACTION READ WRITE,WITH CONSISTENT SNAPSHOT;
      #隐式事务
        #默认事务为自动提交
        #SHOW SESSION VARIABLES LIKE '%autocommit%';
        #设置关闭自动提交事务，当OFF切换到ON时，会自动提交上一次事务
        #SET SESSION autocommit = OFF;

    SELECT * FROM t1;
    DELETE FROM t1 WHERE id = 1;


    #设置保存点
    SAVEPOINT s1;
    #删除保存点
    RELEASE SAVEPOINT s1;

    #回滚到某个保存点
    ROLLBACK TO s1;

    #回滚事务,回滚到最初，如果有保存点则会删除所有保存点
    ROLLBACK;

    #提交事务
    COMMIT;
  "
  不当操作导致事务隐式提交:
    情况1: 重复的开启事务会导致上一次事务被提交，START TRANSACTION、BEGIN....
    情况2: SET SESSION autocommit = OFF，当OFF切换到ON时，会自动提交上一次事务
    情况3: LOCK TABLES、UNLOCK TABLES
    情况4: 使用加载数据语句，LOAD DATA语句来批量往数据库中导入数据时
    情况5: 使用复制语句，START SLAVE、STOP SLAVE、RESET SLAVE、CHANGE MASTER TO
    情况6: 其他语句，ANALYZE TABLE、CACHE INDEX、CHECK TABLE、FLUSH、LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE、RESET
  事务分类(了解):
    概述: "
      SHOW SESSION VARIABLES LIKE '%completion_type%';
        SET SESSION completion_type = 0; #NO_CHAIN(默认)
          每次COMMIT后，都需要从新开启事务(START TRANSACTION或BEGIN)
        SET SESSION completion_type = 1; #CHAIN
          每次COMMIT后，相当于执行了COMMIT AND CHAIN，也就是自动会开启下一个相同事务(相同隔离级别的事务)
        SET SESSION completion_type = 2; #RELEASE
          每次COMMIT后，相当于执行了COMMIT AND RELEASE，也就是自动与服务器断开连接
    "
    扁平事务: "
      扁平事务是事务中最简单的一种，但是在实际生产环境中，使用最多的事务。在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，
      由COMMIT WORK或ROLLBACK WORK结束，期间的操作是原子的，要么都执行，要么都回滚，因此，扁平事务是应用程序成为原子操作的基本
      组成模块，常见数据库都会支持扁平事务。

      扁平事务主要限制是不能提交或回滚某一部分事务，或者分几个步骤提交。

      扁平事务一般有3种不同的结果
        1.事务成功完成，在平常应用中约占所有事务的96%
        2.应用程序要求停止事务，比如应用程序在捕获到异常时会回滚事务，约占事务的3%
        3.外界因素强制终止事务，如果连接超时或连接断开，约占所有事务的1%
    "
    带有保存点的扁平事务: "
      除了支持扁平事务支持的操作外，还允许在事务执行过程中回滚到同一事务中较早的一个状态。
      这是因为某些事务可能在执行过程中出现的错误并不会导致所有操作都无效，放弃整个事务不理，开销太大。
    "
    保存点: "
      用来通知事务系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存当时的状态。对于扁平事务来说，
      隐式的设置了一个保存点，然而在整个事务中，只有这个保存点，因此回滚只能回滚到事务开始时的状态。
    "
    链式事务: "
      链式事务是指一个事务由多个子事务链式组成，它可以被视为保存点模式的一个变种。带有保存点的扁平事务，
      当发生系统崩溃时，所有的保存点都将消失，这意味着当进行恢复时，事务需要从开始处重新执行，而不能从
      最近的一个保存点继续执行。链式事务的思想是，在提交一个事务时，释放不需要的数据对象，将必要的处理上下
      文隐式的传递给下一个要开始的事务，前一个子事务的提交操作和下一个事务的开始操作合并成一个原子操作，这
      意味着下一个事务将看到上一个事务的结果，就好像在事务中进行一样。这样在提交子事务时就可以释放不需要的
      数据对象，而不必等到整个事务完成后才释放。

      链式事务与带有保存点的扁平事务不同之处
        1.带有保存点的扁平事务能回滚到任意正确的保存点，而链式事务中的回滚仅限于当前事务 ，即只能恢复到最近的一个保存点。
        2.对于锁的处理，两者也不同，链式事务在执行COMMIT后即释放了当前所持有的锁，而带有保存点的扁平事务不影响至今为止所持有的锁。
    "
    嵌套事务: "
      嵌套事务是一个层次结构的框架，由一个顶层事务控制着各个层次的事务，顶层事务之下嵌套的事务被称为子事务，
      其控制着每一个局部的变换，子事务本身也可以是嵌套事务，因此，嵌套事务的层次结构可以看成是一颗树。
    "
    分布式事务: "
      分布式事务通常实在一个分布式环境下运行的扁平事务，因此需要根据数据所在的位置访问网络中不同节点的数据库资源。
      例如，一个银行用户从招商银行向工商银行转账1000元，这里需要用到分布式事务，因为不能仅调用某一家银行的数据库
      就完成任务。
    "
  事务隔离级别(存在问题):
    概述:
      - 数据库是C/S结构，每一次连接都是一个长连接，称为会话(session)，每一个会话都可以拥有自己的事务
    数据并发访问产生的问题:
      脏写: A事务修改了B事务未提交的数据
      脏读: A事务读取了B事务未提交的数据
      不可重复读: A事务每次读取【数据的值不一样或者行数变少】(B事务修改数据值或者删除了删除并且提交了)
      幻读: A事务每次读取【数据行数】变多(B事务增加数据并且提交了)，值得注意的是，对于事务B删除并提交的数据不算幻读，可以归纳到不可重复读。
    SQL标准的四种隔离级别(存在问题):
      概述:
        - 这个是SQL标准中的隔离级别，并非是MYSQL的最终结果
        - 隔离级别越高，性能越差，但是存在的并发问题越少，脏写 > 脏读 > 不可重复度 > 幻读
      参考表: "
        ORACLE支持：读已提交(READ COMMITTED)、串行化读(SERIALIZABLE默认)
        MYSQL支持: 4种，可重复读(REPEATABLE READ默认)

        读未提交(READ UNCOMMITTED)
        读已提交(READ COMMITTED)
        可重复读(REPEATABLE READ)
        串行化读(SERIALIZABLE)，会对SELECT查询出来的数据进行加S锁(行锁、隙锁、表锁)，所有并发问题都可以避免，但性能非常低。


        隔离级别   脏写 脏读  不可重复读  幻读  锁
        ------------------------------------
        读未提交   no  yes  yes       yes  no
        读已提交   no  no   yes       yes  no
        可重复读   no  no   no        yes  no
        串行化读   no  no   no        no   yes

        MYSQL默认隔离级别为可重复读，但是MYSQL对【幻读】已经解决。
        隔离级别   脏写 脏读  不可重复读  幻读  锁
        ------------------------------------
        可重复读   no  no   no        no  no
      "
  事务日志:
    REDO LOG(重做日志):
      概述:
        - 提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性。
        - REDO LOG是InnoDB存储引擎生成的日志，记录的是物理级别上的页修改操作，比如页号、偏移量等等，主要为了保证数据的可靠性。
      为什么存在REDO LOG: "
        一方面，缓冲池可以帮助我们消除CPU和磁盘之间的鸿沟，checkpoint机制可以保证数据的最落盘，然而由于checkpoint并不是每次变更的时候就会触发的，
        而是master线程隔一段时间去处理的。所以最坏的情况就是事务提交后，刚写完缓冲池，数据库宕机了，那么这段数据就是丢失的了，无法恢复。

        另一方面，事务包含持久性的特性，就是说对于一个已经提交的事务，在事务提交后即使系统发生了崩溃，这个事务对数据库中所做的更改也不能丢失。

        那么如何保证这个持久性呢？
          不太合理的做法，在事务提交完成值钱把该事务所修改的所有页面都刷新到磁盘，但是这个简单粗暴的做法有些问题。
            1.修改量与刷新磁盘工作严重不成比例，有时候我们仅仅修改了某个页面中的一个字节，但是我们知道在InnoDB中是以
              页为单位来进行磁盘IO的，也就是说我们在该事务提交时不得不将一个完整的数据页从内存中刷新到磁盘，一个数据页
              默认是16KB，只要修改1个字节就需要刷新16KB的数据到磁盘这个明显浪费了。
            2.随机IO刷新较慢，一个事务可能包含很多语句，即使是一条语句也可能修改许多数据页，假如该事务修改的这些数据页可能
              并不相邻，这就意味着在将某个事务修改的缓存池(Buffer pool)中的数据页刷新到磁盘时，需要进行很多随机IO，随机
              IO不顺序IO要慢，尤其多余传统的机械硬盘来说。
          合理的做法，我们只是想让已经提交的事务对数据中数据所做的修改永久生效，即使后来系统崩溃，在重启后也能把这种修改恢复出来，
          我们其实没有必要在每次事务提交时就把该事务在内存中修改过的全部数据页刷新到磁盘，只需要把修改的数据记录REDO LOG中。比
          如，某个事务将系统表空间中第10号数据页中偏移量为100处的那个字节的值1改为2，我们只需要记录一下，将第0号表空间的10号数据
          页的便宜量为100处的值更新为2.

        InnoDB存储引擎的事务采用了WAL技术(Write-Ahead Logging)，这种技术的思想就是先写日志，在写磁盘，只有日志写入成功，才算
        事务提交成功，这里的日志就是REDO LOG，当发生宕机旦数据未刷新到磁盘的时候，可以通过REDO LOG来恢复，保证ACID中的持久性，这
        就是REDO LOG的作用。

      "
      个人总结: "
        在事务执行过程中，当你COMMIT那一刻，事务已经结束了，此时只是对缓冲池的数据进行了修改，并非对磁盘数据进行修改(因为数据库有一个定时策略刷盘)，
        如果在这个时刻出现错误（宕机、停电、数据库错误），那么当数据库重新恢复时，就会利用REDO LOG来重新做持久化操作。
      "
      特点: "
        REDO LOG是顺序写入磁盘的，在执行事务过程中，每执行一条语句，就可能产生若干调REDO LOG，这些日志是按照产生的顺序写入磁盘的，也就是使用了顺序IO。

        事务执行过程中，REDO LOG不断记录，REDO LOG跟BIN LOG的区别，REDO LOG是存储引擎层产生的，而BIN LOG是数据层残生的。假设一个事务，对表做10万
        行的记录插入，在这个过程中，一直不断往REDO LOG顺序记录，而BIN LOG不会产生记录，直到这个事务提交，才会一次写入到BIN LOG文件中。
      "
      优点:
        - REOD LOG降低刷盘频率
        - REDO LOG占用的空间非常小，存储表空间ID、页号、偏移量以及需要更新的值，所需要的存储空间小，刷盘快。
      REDO LOG刷盘策略: "
        参考图 img_12_2REDO_LOG刷盘流程.png

        REDO LOG刷盘是从REDO LOG Buffer -> PAGE CACHE -> REDO LOG文件(ib_logfile0、ib_logfile1)

        默认的REDO LOG Buffer为16MB。最大值是4096MB，最小为1M
          SHOW GLOBAL VARIABLES LIKE '%innodb_log_buffer_size%'
        默认的REDO LOG文件(ib_logfile0、ib_logfile1)存储位置，默认是相对于数据目录位置的路径(/var/lib/mysql/)
          SHOW GLOBAL VARIABLES LIKE '%innodb_log_group_home_dir%'
        默认REDO LOG文件(ib_logfile0、ib_logfile1)的数量为2，最大可以为100个
          SHOW GLOBAL VARIABLES LIKE '%innodb_log_files_in_group%'
        默认REDO LOG文件大小48M，最大为512G
          SHOW GLOBAL VARIABLES LIKE '%innodb_log_file_size%'

        innodb_flush_log_at_trx_commit(☆)
            值为0时
              只能依靠master thread每隔1秒中进行一次重做日志的fsync操作，master thread是负载将换缓冲池中的数据异步刷新到磁盘。
              如果出现数据库挂或者服务器宕机，会丢失1秒的数据，这种情况下无法满足ACID中的D。
            值为1时(默认值)
              只要提交事务成功，就会立即刷盘，REDO LOG记录就一定在硬盘里面，就算操作系统宕机或者数据库挂了，也不会有任何数据丢失风险。
            值为2时
              只要事务提交成功，REDO LOG Buffer中的内容只写入文件系统缓存(page cache)
              如果仅仅只是MYSQL挂了，不会有任何数据丢失，但是操作系统宕机可能会有1秒数据的丢失(master thread会隔1秒做一次刷盘)，这种情况下无法满足ACID中的D。
      "
    UNDO LOG(回滚日志):
      概述:
        - 回滚行记录到某个特定版本，用来保证事务的原子性。一致性。
        - UNDO LOG在事务做DELETE、UPDATE、INSERT的操作时，其实是先要写入一个逆向的UNDO LOG(UNDO LOG不会记录SELECT的操作)。
        - UNDO LOG是InnoDB存储引擎生成的日志，记录的是逻辑操作日志，比如你做了INSERT，那么在UNDO LOG中则记录为DELETE，用于事务回滚和一致性非锁定读(MVCC讲解)
        - 事务需要保证原子性，要么都完成，要么都失败，如果出现错误(服务器宕机、操作系统错误、断点、ROLLBACK)，需要通过UNDO LOG进行回滚(逻辑恢复，物理开辟的空间是不能恢复的)
        - UNDO LOG也会产生REDO LOG，因为UNDO LOG也需要做持久性保护。
    操作一条数据执行过程: "
      img_13插入一条数据执行过程.png
      img_13_2更新一条数据执行过程.png
        第一步，先将原始的数据从磁盘中以数据页的方式读取内存中来。
        第二步，将逆向SQL语句写入UNDO LOG中
        第三步，修改数据缓冲池的的数据
        第二步，生成一条REDO LOG日志并写入REDO LOG Buffer中，记录的是数据被修改后的值。
        第三步，当事务COMMIT时，根据不同的刷盘策略，将REDO LOG Buffer中的内容刷盘到REDO LOG FILE
        第四步，不宕机情况下，定期将数据缓冲池中的数据刷到磁盘中，如果宕机情况下，则在MYSQL恢复的时候将REDO LOG日志回放，然后刷到磁盘中。
      "
  锁:
    概述:
      - 数据也是一种供许多用户共享的资源，为了保证数据一致性，需要对并发访问进行控制，因此产生了锁。
      - 锁机制也为实现MYSQL的各个隔离级别提供了保证。
      - 锁冲突也是影响数据库并发访问性能的一个重要因素。
      - 在出现锁的情况下(显式锁|隐式锁)，被扫描过的数据都会被锁上。(select * from t1 where id = 2 for share，id为varchar类型，此时锁的不单单是id为2的数据)
      - "
        因为锁会占用内存空间，因此锁空间的大小是有限制的(每个层级的锁数量是有限的)。当某个层级的锁数量超过了这个层级的阈值时，
        就会进行锁升级。锁升级就是用更大粒度的锁代替多个更小粒度的锁。比如在InnoDB中记录锁升级为表锁，这样做的好处是占用锁
        空间降低了，但是并发度也下降了。
      "
    并发事务访问相同记录(同一条、同一个区域):
      读读:
        - 读读情况，即并发事务相继读取相同的记录。读取操作本身不会对记录有任何影响，并不会引起什么问题，所以允许这种情况的发生。
      写写:
        - 写写情况，即并发事务相继对相同的记录做出改动，在这种情况下会出现脏写问题，任何一种隔离级别都不允许这种情况发生。
        - "
          在多个未提交事务相继多一条记录做出改动，需要让他们排队执行，这个排队的过程其实是通过锁机制来实现的。
          这个所谓的锁其实是一个内存中的结构，在事务执行前本来是没有锁的，也就是说一开始是没有锁结构和该记录
          进行关联，当一个事务想对这条记录做改动时，首先会看内存中有没有与这条记录关联的锁结构，当没有的时候
          就会在内存中生成一个锁结构与之关联。


          获取锁成功，is_waiting = false
          获取锁失败，is_waiting = true

          事务A对一条记录更改，会生成锁结构信息，事务B对同一条记录也更改，也会生成锁结构信息。如果A先改，那么
          A事务的锁结构is_waiting就为false，代表可以操作，此时B的锁结构is_waiting就为ture，只有当A事务
          改完，B事务的锁结构is_waiting才会更改为false。
        "
      读写:
        概述:
          - 读写这种情况下可能发生脏读、不可重复读、幻读的问题。
          - 各个数据库厂商对SQL标准的支持可能不一样，本来可重复读会存在幻读问题，但是在MYSQL的可重复隔离级别下已经解决了幻读的问题。
        并发事务访问相同记录(同一条、同一个区域)的解决方案:
          方案1(读操作利用MVCC，写操作加锁):
            概述:
              - "
                所谓的MVCC，就是生成一个ReadView，通过ReadView找到复合条件的记录版本(历史版本由UNDO LOG构建)。
                查询语句只能读到在生成ReadView之前已经提交事务所做的更改，在生成ReadView之前未提交的事务或者之后
                才开启的事务所在的更改是看不到的。而写操作肯定针的是最新版本的记录，读记录的历史版本和改动记录的最新
                版本本身并不冲突，也就是采用MVCC时，读写操作并不冲突。

                普通的SELECT语句在读已提交(READ COMMITTED)和可重复读(REPEATABLE READ)隔离级别下会利用MVCC读取记录
                  在读已提交(READ COMMITTED)隔离级别下，一个事务在执行过程中【每次都执行SELECT】操作时会生成一个ReadView，ReadView的存在本身就保证了事务不可以读取到未提交的数据，也就是避免了脏读现象。
                  在可重复读(REPEATABLE READ)隔离级别下，一个事务在执行过程中只有【第一次SELECT】操作时会生成一个ReadView，之后的SELECT操作都会复用这个ReadView，这样也就避免了不可重复读和幻读的问题。
              "
            MVCC:
              概述:
                - Multiversion Concurrency Control，简称MVCC，多版本并发控制
                - "
                  MVCC是通过数据行的多个版本(UNDO LOG)管理(ReadView)来实现数据库的并发控制，这项技术使得在InnoDB的事务隔离级别下执行一致性读操作有了保证。
                  换言之，如果有事务在修改并且提交了，使用MVCC可以获取到历史值，这样在做查询的时候就不用等待另一个事务释放锁。
                "
                - MVCC没有正式的标准，在不同的DBMS中MVCC的实现方式可能不同，MYSQL只有InnoDB中支持MVCC，其他存储引擎并不支持。
                - MVCC在MYSQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读写冲突，即使有读写冲突，也能做到不加锁。
              MVCC实现原理:
                - MVCC是基于【读已提交、可重复读】隔离级别实现的
                - MVCC实现依赖于 UNDO LOG、ReadView、隐藏字段。
              什么是ReadView: "
                在MVCC机制中，多个事务对同一行记录进行操作会产生多个历史快照，这些历史快照保存在Undo Log里。
                如果一个事务想要查询这行记录，需要读取哪个版本的行记录呢？这里就需要用到ReadView了，它帮我们
                解决了行的可见性问题。

                ReadView就是一个事务在使用MVCC机制进行快照读操作时产生的读视图(一个事务对应一个ReadView)。当事务启动时，
                会生成数据库系统当前的一个快照ReadView(数组结构)，用来记录并维护系统当前活跃事务的ID(活跃事务就是指未提交的事务)
              "
              ReadView结构:
                - creator_trx_id，创建ReadView的事务ID(只有执行INSERT、DELETE、UPDATE操作才会有事务ID，否则事务ID值默认为0)
                - trx_ids，在生成ReadView这一刻，有多少活跃的事务(有多少正在执行中的事务，并且未commit的事务)
                - up_limit_id，在活跃事务(trx_ids)中最小的事务ID
                - low_limit_id，记录数据库系统在下一次分配事务ID时的最大ID(整个数据库最大的事务ID)
              ReadView获取数据规则: "
                利用ReadView获取数据规则，从而知道UNDO LOG日志链中哪些数据是可以被这个事务访问，哪些数据室不可以被这个事务访问

                trx_id(Undo Log日志链中某一条记录)  = creator_trx_id，这个记录可以被此事务访问。
                trx_id(Undo Log日志链中某一条记录)  < up_limit_id，这个记录可以被此事务访问。
                trx_id(Undo Log日志链中某一条记录)  > low_limit_id，这个记录不可以被此事务访问。
                trx_id(Undo Log日志链中某一条记录) between (up_limit_id low_limit_id)
                  判断trx_id值是否在trx_ids列表
                    如果在，说明创建ReadView时生成该版本的事务还是活跃的，不可以访问
                    如果不在，说明创建ReadView时生成该版本的事务已经提交，可以访问
              "
              MVCC整体操作流程: "
                1.首先获取事务ID
                2.根据当前这个事务生成一个读视图(ReadView)
                3.将查询得到的数据，与ReadView中的事务ID进行比较
                4.如果不符合ReadView规则，就需要从Undo Log中获取历史快照数据
                5.最后返回符合规则的数据

                总结:
                  在InnoDB中，MVCC是通过Undo Log + Read View进行数据读取，Undo Log保存了历史快照，而Read View规则帮我们判断当前版本的数据是否可见。
              "
              快照读:
                概述:
                  - 快照读又叫一致性读，读取的是快照数据。快照读的实现是基于MVCC，避免了加锁操作，降低了开销。
                  - 既然是基于多版本，那么快照读可能读到的并不是最新版本数据，有可能是之前的历史版本数据。
                  - SELECT * FROM t1
                读已提交:
                  - 在事务执行过程中，在相同表中，每次SELECT都会创建一个新的读视图(ReadView)
                  - 就是因为每次都创建，恰好可以做到幻读问题。
                可重复读:
                  - 在事务执行过程中，在相同表中，第一次SELECT才会创建读视图(ReadView)
                  - 就是因为只创建一次，恰好解决了幻读的问题。
              当前读:
                - SELECT * FROM t1 FOR SHARE
                - SELECT * FROM t1 FOR UPDATE
              MVCC优点:
                - 读写之间阻塞问题，通过MVCC可以让读写操作相互不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务的并发处理能力。
                - 降低了死锁的概率，这是因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作也只是锁定必要的行。
          方案2(读加锁，写加锁):
        总结:
          - 采用读MVCC，写加锁的话，性能更高(可能历史数据的读取)
          - 采用读加锁，写加锁的话，彼此都需要排队，影响性能。(每次都是读到最新数据)
    MYSQL锁家族分类:
      概述:
        - 对于InnoDB存储引擎，支持行级锁和表级锁
        - 对于MYISAM存储引擎，只支持表级锁
      锁监控: "
        SHOW  STATUS LIKE '%innodb_row_lock%'
          #服务器启动到现在为止的统计，重启服务器则所有参数归0
          #Innodb_row_lock_current_waits 正在等待的锁数量
          #Innodb_row_lock_time 锁等待的总时长
          #Innodb_row_lock_time_avg 锁等待的平均时长
          #Innodb_row_lock_time_max 锁等待的最大时间
          #Innodb_row_lock_waits 锁等待的总次数

        MYSQL5.7及之前可以通过如下语句查看锁
          #事务相关信息
            SELECT * FROM information_schema.INNODB_TRX
          #查看所有阻塞的锁
            SELECT * FROM information_schema.INNODB_LOCK_WAITS
          #查看所有锁(只能看阻塞，非阻塞看不到)
            SELECT * FROM information_schema.INNODB_LOCKS

        MYSQL8.0可以通过如下语句查看锁
          #事务相关信息
            SELECT * FROM information_schema.INNODB_TRX
          #查看所有阻塞的锁
            SELECT * FROM performance_schema.data_lock_waits
          #查看所有锁(可以看到阻塞和非阻塞，比5.7要强)
            SELECT * FROM performance_schema.data_locks
      "
      对数据操作类型划分:
        排它锁(X锁):
          - 排它锁(X锁)与排它锁(X锁)互斥，排它锁(X锁)与共享锁(S锁)互斥
        共享锁(S锁):
          - 共享锁(S锁)与排它锁(X锁)互斥，共享锁(S锁)与共享锁(S锁)兼容
        锁定读:
          - "
            #查看锁阻塞的超时时间，默认为50秒
            SHOW SESSION VARIABLES LIKE '%innodb_lock_wait_timeout%'

            BEGIN;

            #加共享锁(S锁)
            	#MYSQL5.7及之前版本
            	SELECT * FROM t1 LOCK IN SHARE MODE ;
            	#MYSQL8.0支持
            	SELECT * FROM t1 FOR SHARE ;
            	SELECT * FROM t1 FOR SHARE NOWAIT;
            	SELECT * FROM t1 FOR SHARE SKIP LOCKED;
            #加排它锁(X锁)
            	#MYSQL5.7及之前版本
            	SELECT * FROM t1 FOR UPDATE;
            	#MYSQL8.0支持
            	SELECT * FROM t1 FOR UPDATE NOWAIT;
            	SELECT * FROM t1 FOR UPDATE SKIP LOCKED;

            COMMIT;

          "
        写操作:
          概述:
            - 大体的认为写操作都是加X锁，所以在写操作的时候，如果读操作也加锁(S锁、X锁)，那么就产生互斥效果。
          DELETE: "
            对一条记录做DELETE操作的过程，其实是现在B+tree中定位到这条记录的位置，然后获取这条记录的X锁，在执行delete mark操作。
          "
          UPDATE: "
            在多一条记录做UPDATE操作时分3种情况
              情况1，不改主键，列占用空间未发生变化
                先在B+tree中定位到这条记录的位置，然后在获取一下记录的X锁，最后在原记录的位置进行修改操作。
              情况2，不改主键，列占用空间发生变化
                先在B+tree中定位到这条记录的位置，然后在获取一下记录的X锁，将该记录标记为删除(把记录移入垃圾链表)，最后在插入
                一条新记录。新插入的记录由INSERT操作提供隐式锁进行保护。
              情况3，改主键
                修改了该记录的主键，则相当于在原记录上做DELETE操作之后再来一次INSERT操作，加锁操作就需要按照DELETE和INSERT的规则进行了。
          "
          INSERT: "
            一般情况下，新插入一条记录的操作并不加锁，但是通过一种称之为隐式锁的结构来保护这条新插入的记录在本事务提交之前不被别的事务访问。
          "
      锁粒度划分:
        概述:
          - 为了尽可能提高数据库并发访问，每次锁定数据范围越小越好。
          - 锁是很消耗资源的事情(涉及锁获取、锁检查、锁释放等动作)，因此数据系统需要在高并发和系统性能两方面平衡，这样就产生了锁粒度的概念。
        表级锁:
          表锁:
            概述:
              - 其实一个事务也可以在表级别进行加锁，称为表锁。
              - 对一个表加锁影响整个表中的记录，我们就说这个锁的粒度比较粗。
              - 任何存储引擎的表锁策略都是一样的。表锁的开销是最小的策略(因为粒度比较大)
              - 表锁会将整张表锁定，所以不存在死锁的问题。
              - 正因为表锁的粒度很大，所以如果出现锁竞争，那么会到并发访问大打折扣。
              - MYISAM支持表锁，InnoDB支持行锁、表锁(InnoDB中最好不要使用表锁)
            tops:
              - 需要注意的是，表级锁针对的是session生效(并非事务中)。
            使用: "
              DROP TABLE IF EXISTS t1;
              CREATE TABLE IF NOT EXISTS t1(
              	id INT PRIMARY KEY AUTO_INCREMENT,
              	name VARCHAR(10)
              )ENGINE = MYISAM;

              SHOW CREATE TABLE t1;

              INSERT INTO t1 VALUES(1,'eric');

              SELECT * FROM t1;


              #如果In_use = 1则为锁表
              SHOW OPEN TABLES WHERE `Table` = 't1';


              #为表加S锁
              	LOCK TABLES t1 READ;

              	#在当前session中，允许访问t1
              	SELECT * FROM t1;

              	#在当前session中，不允许访问其他表
              	SELECT * FROM t2;

              	#在当前session中，不允许修改t1的数据
              	UPDATE t1 SET `name` = 'eric1' WHERE id = 1;

              	#其他session中，允许访问t1
              	SELECT * FROM t1;
              	#其他session中，不允许修改t1
              	UPDATE t1 SET `name` = 'eric1' WHERE id = 1;


              #为表加X锁
              	LOCK TABLES t1 WRITE;

              	#在当前session中，允许访问t1
              	SELECT * FROM t1;

              	#在当前session中，不允许访问其他表
              	SELECT * FROM t2;

              	#在当前session中，允许修改t1的数据
              	UPDATE t1 SET `name` = 'eric1' WHERE id = 1;

              	#其他session中，不允许访问t1
              	SELECT * FROM t1;
              	#其他session中，不允许修改t1
              	UPDATE t1 SET `name` = 'eric1' WHERE id = 1;



              #释放表锁，只能在当前session中释放，否则需要用kill方式
              UNLOCK TABLES;
            "
          意向锁(自动加锁):
            概述:
              - InnoDB支持多粒度锁(行级，表级)，而意向锁(Intention Lock)就是其中的一种表级锁
              - 意向锁的存在是为了协调行锁和表锁的关系，支持表锁和行锁并存。
              - 意向锁是不与行级锁冲突的一种表锁
              - 意向锁是由存储引擎维护的，用户无法手动操作意向锁，在为数据加行级锁之前，InnoDB会先获取该数据行所在表对应的意向锁。
            说人话:
              - 意向锁的出现，是为了提高行级锁的性能，当为某些数据加锁(S锁、X锁)时，存储引擎会自动加上意向锁，方便别的事务在对数据加锁时更容易判断是否存在锁。
              - "
                如果我们给某些数据加上了锁(S锁、X锁)，存储引擎会自动给更大一级的空间(数据页、数据表)加上意向锁，告诉其它事务，这个数据页或数据表已经有人加锁(S锁、X锁)，
                这样当其他事务想要获取数据表的锁(S锁、X锁)时，只需要知道是否有人已经获取这些数据的意向锁即可。
              "
            使用: "
                DROP TABLE IF EXISTS t1;
                CREATE TABLE IF NOT EXISTS t1(
                	id INT PRIMARY KEY AUTO_INCREMENT,
                	name VARCHAR(10)
                )ENGINE = INNODB;

                SHOW CREATE TABLE t1;

                INSERT INTO t1 VALUES(1,'eric1');
                INSERT INTO t1 VALUES(2,'eric2');

                SELECT * FROM t1;


                BEGIN;

                #意向锁(IS锁)
                  SELECT * FROM t1 WHERE id = 1 LOCK IN SHARE MODE ;

                  #在别人没上表锁(S)之前，是可以修改的，如果上了则自己也修改不了，其他原则还是遵守那个S与S可以共存，S与X阻塞，X与X阻塞的规则
                  LOCK TABLES t1 READ;
                  UPDATE t1 SET `name` = 'eric12356' WHERE id = 1;


                #意向锁(IX锁)
                SELECT * FROM t1 WHERE id = 2  FOR UPDATE;

                #经过测试，写操作也会产生意向锁

                COMMIT;
            "
          元数据锁(MDL锁)(自动加锁):
            概述:
              - Metadata Lock，简称MDL锁
              - DML锁会自动加上，不需要人为干预。
              - "
                元数据S锁，对一个表做SELECT、DELETE、INSERT、UPDATE的时，不管你是否显示指定锁(FOR UPDATE、FOR SHARE)，都会存在元数据S锁
                  SELECT * FROM t1 LOCK IN SHARE MODE ;
                  SELECT * FROM t1 ;

                元数据X锁，对一个表做结构变更的时候，会存在元数据锁元数据X锁
                  ALTER TABLE t1 CHARACTER SET utf8;

                总结，还是遵守S与S共享，S与X互斥，X与X互斥原则。
              "
          自增锁:
            概述:
              - 使用自动增长约束(AUTO_INCREMENT)时，会存在自增锁(AUTO-INC锁)，该锁也是一种表级锁，对并发访问存在性能的影响。
              - "
                自增锁(AUTO-INC锁)是当向含有AUTO_INCREMENT的列插入数据时需要获取的一种特殊的表级锁，在执行插入语句时
                就在表级别加一个自增锁(AUTO-INC锁)，然后为每条待插入记录的AUTO_INCREMENT列分配递增的值，在该语句执行
                结束后，在把自增锁(AUTO-INC锁)释放掉。
              "
            插入数据分类:
              简单插入(Simple Inserts): "
                INSERT INTO t1 VALUES(1,'eric')
                INSERT INTO t1(id,name) VALUES(1,'eric')
                INSERT INTO t1(id,name) VALUES(1,'eric1'),(2,'eric2')
              "
              批量插入(Bulk Inserts): "
                INSERT INTO t1 SELECT t2
                INSERT INTO t1(id,name) SELECT t2
                INSERT INTO t1(id,name) SELECT 1,'eric'
              "
              混合插入(Mixed-Mode Inserts): "
                INSERT INTO t1(id,name) VALUES(1,'eric1'),(NULL,'eric2'),(3,'eric3')
              "
            案例: "
              一个事务在持有自增锁(AUTO-INC锁)时，其它事务的插入语句都要被阻塞(因为需要保证一个语句中分配的递增值是连续的)，所以并发性不高(每条插入语句都需要对这个表锁进行竞争)。
              所以InnoDB存储引擎通过SHOW GLOBAL VARIABLES LIKE '%innodb_autoinc_lock_mode%'提供不同的锁定机制，可以提高性能

                innodb_autoinc_lock_mode = 0
                  传统锁定模式，所有类型的INSERT语句都会获得一个特殊的表级自增锁(AUTO-INC锁)，用于插入含有AUTO_INCREMENT的列，即每当执行INSERT时都会得到一个表级的自增锁，
                  使得语句中生成的AUTO_INCREMENT为顺序，且在binlog中重放的时候，可以保证master和slave中的数据的AUTO_INCREMENT值是相同的。因为是表级锁，当在同一时间多个
                  事务中执行INSERT的时，对自增锁(AUTO-INC锁)的竞争会限制并发能力。

                innodb_autoinc_lock_mode = 1(MYSQL8.0之前默认)
                  对于批量插入(Bulk Inserts)模式，同一时刻只有一个语句可以持有自增锁(AUTO-INC锁)。
                  对于简单插入(Simple Inserts)模式，由于插入的行数预先知道，则在通过mutex(轻量锁)的控制下获得所需数量的自动递增值来避免表级自增锁(AUTO-INC锁)，它只在分配过程
                  的只需时间内保持，并不是直到语句执行完成。不使用表级自增锁(AUTO-INC锁)，除非表级自增锁(AUTO-INC锁)由另一个事务保持。如果另一个事务保持表级自增锁(AUTO-INC锁)，
                  则简单插入(Simple Inserts)模式需要等待自增锁(AUTO-INC锁)，如同它是一个批量插入(Bulk Inserts)模式。

                innodb_autoinc_lock_mode = 2(MYSQL8.0之后默认)
                  所有INSERT语句都不会使用表级自增锁(AUTO-INC锁)，并且可以同时执行多个语句。这是最快和最可扩展的锁定模式，但是当使用基于语句的复制或恢复方案时，从二进制日志重放SQL语句时，这是不安全的。
                  自动递增值保证在所有并发执行的所有类型的INSERT语句中是唯一且单调递增的。但是，由于多个语句可以同时生成数字(跨语句交叉编号)，为任何给定的语句插入的行生成的值可能不是连续的。
                  如果执行的语句是简单插入(Simple Inserts)模式，其中要插入的行数已经提前预知，除了混合插入(Mixed-Mode Inserts)之外，为单个语句生成的数字不会有间隙。
                  当执行批量插入(Bulk Inserts)模式时，在由任何给定语句分配的自动递增值中可能存在间隙。
            "
        行级锁:
          概述: 行级锁容易出现死锁现象
          记录锁(Record Locks):
            概述:
              - 行锁也称为记录锁，就是锁住某一行。行级锁只要存储引擎层实现。
              - MYISAM不支持行锁，InnoDB支持行锁。
            优点: 行锁锁定粒度小，发生锁冲突概率低，可以实现高并发。
            缺点: 对于锁的开销比较大，加锁会比较慢，容易出现死锁
            使用: "
              #查看锁阻塞的超时时间，默认为50秒
              SHOW SESSION VARIABLES LIKE '%innodb_lock_wait_timeout%'

              SELECT * FROM t1 WHERE id = 1 LOCK IN SHARE MODE ; 行级S锁
              SELECT * FROM t1 WHERE id = 1 FOR SHARE ; 行级S锁
              SELECT * FROM t1 WHERE id = 1 FOR UPDATE; 行级X锁
              UPDATE t1 SET f1 = 1 WHERE id = 1 行级X锁
              DELETE FROM t1 WHERE id = 1 行级X锁
            "
          间隙锁(Gap Locks)与临建锁(Next-Key Locks)与插入意向锁(Insert Intention Locks):
            概述:
              - MYSQL在可重复读隔离级别下解决了幻读问题，一种是MVCC方式，另一种是加锁方式。加锁方式可以采用间隙锁来防止幻读的出现。
            使用: "

              +----+--------+
              | id | name   |
              +----+--------+
              |  1 | eric1  |
              |  2 | eric2  |
              |  3 | eric3  |
              |  4 | eric4  |
              | 70 | eric70 |
              | 80 | eric80 |
              | 90 | eric90 |
              +----+--------+

              间隙锁场景

                SELECT * FROM t1 where id = 75 LOCK IN SHARE MODE ; 间隙锁范围在 70到80之间，不包括70和80

                SELECT * FROM t1 where id = 100 LOCK IN SHARE MODE ; 间隙锁范围在 91到正无穷

                #经过测试，写操作也会存在间隙锁

                总结
                  1.只要对不存在的记录上了锁，就出现间隙锁，间隙锁就会落在数据区间，或者是无穷大区间。
                  2.因为是不存在的记录，所以不分X锁或者是S锁，这两种间隙锁是等价的。
                  3.重点，间隙锁只有在可重复读隔离级别下才有效(REPEATABLE-READ、SERIALIZABLE)，因为这2种隔离级别都允许出现幻读，所以间隙锁是生效的。
                    REPEATABLE-READ，需要手动指定间隙锁
                    SERIALIZABLE，默认就会加隐式的间隙锁(无需手动指定)

              临建锁场景:

                SELECT * FROM t1 where id >= 70 and id <= 80  LOCK IN SHARE MODE ;  间隙锁范围在 70和80之间，并且包含70和80

                SELECT * FROM t1 where id >=90  LOCK IN SHARE MODE ; 间隙锁范围在 90到正无穷，包含90

                总结
                  1.临建锁是记录锁(行锁)和间隙锁的【合体】。

              插入意向锁场景:
                假如一个事务A加了间隙锁，事务B插入的记录刚好落在事务A间隙锁的区间，那么就会出现了【插入意向锁】，锁名为Insert Intention Lock。(在间隙锁或者临建锁中插入数据，会出现插入意向锁)
                插入意向锁是行级锁，并非是表级别的意向锁，两者是不同的区别。
                插入意向锁也是一种特殊的间隙锁。
            "
        页级锁: "
          页锁就是在b+tree的数据页上进行锁定，锁定粒度比记录锁要大，比表锁粒度要小，因为一个数据页中可以有多个记录。当我们使用页锁的时候，
          会出现数据浪费现象，但这样的浪费最多就是一个数据页上的数据行。页锁的开销介于表锁和记录锁之间，也是会出现死锁现象。
        "
      对待锁的态度划分:
        概述:
          - 乐观锁和悲观锁并不是真实的，而是一种锁的设计思想。
        悲观锁: "
          1.如果加锁都属于悲观锁。
          2.使用SELECT .... FOR UPDATE语句执行过程中所有扫描的行都会被锁上，因此在MYSQL中用悲观锁必须要保证有索引(避免全表扫描，从而所有数据被上锁)
          3.悲观锁不适用的场景较多，它存在一些不足，原因悲观锁大多数情况下依靠数据的锁机制来实现，以保证程序的并发访问，同时这样对数据库性能的开销营销影响很大，特别对于长事务，这样的开销往往无法承受(造成阻塞的现象)。
        "
        乐观锁: "
          乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，但是在更新的时候会判断一下在此期间别人有没有更新过这个数据。
          也就是不用需要通过数据库自身的锁机制，而是通过程序来实现。乐观锁适用于读比较多的场景，这样可以提高吞吐量。

          乐观锁【版本号】方式
            在表中设计一个版本字段version，第一次读的时候获取版本号，然后对数据进行更新或者删除时，会执行UPDATE t1 SET version = version+1 WHERE version = version(程序读出来的)
          乐观锁【时间戳】方式
            时间错和版本号方式一样，UPDATE t1 SET timestamp = timestamp(最新获取的) WHERE timestamp = timestamp(程序读出来的)

          总结:
            你能看到乐观锁就是程序有自己控制数据并发操作的，基本是通过给数据行增加一个单调递增的字段，从而正面当前拿到的数据是最近的(获取操作和更改操作，客观认为是原子性的)
        "
        区别:
          - 乐观锁适合读操作多的场景，可能造成CPU开销大(因为每次改不成功还得继续改)
          - 悲观锁适合写操作多的场景，并发性低(容易造成多事务之间阻塞现象)
      加锁方式:
        概述: "
          MYSQL8.0可以通过如下语句查看锁
            #查看所有阻塞的锁
            SELECT * FROM performance_schema.data_lock_waits
            #查看所有锁
            SELECT * FROM performance_schema.data_locks
        "
        隐式锁: "
          非人为指定而产生的锁称为隐式锁

          INSERT t1
          DELETE t1
          UPDATE t1
          ALTER TABLE
        "
        显示锁: "
          手动为SQL语句指定锁称为显示锁

          #查看锁阻塞的超时时间，默认为50秒
          SHOW SESSION VARIABLES LIKE '%innodb_lock_wait_timeout%'

          BEGIN;

          #加共享锁(S锁)
            #MYSQL5.7及之前版本
            SELECT * FROM t1 LOCK IN SHARE MODE ;
            #MYSQL8.0支持
            SELECT * FROM t1 FOR SHARE ;
            SELECT * FROM t1 FOR SHARE NOWAIT;
            SELECT * FROM t1 FOR SHARE SKIP LOCKED;
          #加排它锁(X锁)
            #MYSQL5.7及之前版本
            SELECT * FROM t1 FOR UPDATE;
            #MYSQL8.0支持
            SELECT * FROM t1 FOR UPDATE NOWAIT;
            SELECT * FROM t1 FOR UPDATE SKIP LOCKED;

          COMMIT;
        "
      其它锁:
        全局锁: "
          加上全局锁以后，所有表变为只读，一般用于备份
          FLUSH TABLES WITH READ LOCK;

          释放全局锁(表锁的释放指令一样)
          UNLOCK TABLES;
        "
        死锁: "
          #查看锁阻塞的超时时间，默认为50秒
          SHOW SESSION VARIABLES LIKE '%innodb_lock_wait_timeout%'

          如果事务与事务之间出现死锁，当innodb_lock_wait_timeout超时，则会选择成本最低的那个事务进行回滚(不死锁的情况下超时整个事务是不会全部回滚的，只有超时SQL语句中断)，
          InnoDB存储引擎会通过wait-for-graph算法(innodb_deadlock_detect = ON)来主动检测死锁问题。

        "
日志篇:
  常用的6种日志:
    慢查询日志:
      - 记录所有执行时间超过long_query_time的所有查询，方便对查询进行优化。
    通过查询日志:
      概述:
        - 记录所有连接的起始时间和终止时间，以及连接发送给数据库服务器的所有指令，对我们复原操作的实际场景、发现问题，甚至是对数据库操作的审计都有很大的帮助。
        - 记录所有数据操作，包括启动服务、停止服务器、DDL、DML...
      使用: "
        #查看通用查询日志存储路径
        SHOW GLOBAL VARIABLES LIKE '%general_log_file%'

        #查看通用查询日志是否开启
        SHOW GLOBAL VARIABLES LIKE '%general_log%'

        #开启通用查询日志，默认为关闭
        SET GLOBAL general_log = 'ON'

        #重新生成通用查询日志，先把文件移动或者改名
        #1.关闭后重新打开一次即可
        SET GLOBAL general_log = 'OFF'
        #2.在命令行执行，此命令可以使很多种日志文件重新生成，比如慢查询日志....
        mysqladmin -uroot -p123456 flush-logs  或者 flush logs;

      "
    错误日志:
      概述:
        - 记录MYSQL服务的启动、运行、停止时出现的问题(错误、警告、提示)，方便我们了解服务器的状态，从而对服务器进行维护。
        - 通过错误日志可以查看系统的运行状态，便于及时发现故障、修复故障。如果MYSQL服务出现异常，错误日志是发现问题、解决故障的首选。
      使用: "
        #因为在docker环境，所以为标准输出stderr，如果是本地环境则显示为路径 /var/log/mysqld.log
        #错误日志不允许设置为关闭
        SHOW GLOBAL VARIABLES LIKE '%log_error%'

        #重新生成错误日志，先把文件移动或者改名
        #在命令行执行，此命令可以使很多种日志文件重新生成，比如慢查询日志....
        mysqladmin -uroot -p123456 flush-logs  或者 flush logs;
      "
    二进制日志(bin log):
      概述:
        - binlog可以说是MYSQL中比较重要的日志，在日常开发及运维过程中经常用到。
        - 记录所有【更改数据】的语句(DDL、增、删、改)，可以用于主从服务器之间的数据同步，以及服务器遇到故障时数据的无损失恢复。
        - MYSQL数据库的数据备份、主备、主主、主从都离不开bin_log，需要依靠bin_log来同步数据，保证数据一致性。
        - 在数据库所做的DML、DDL都以【事件】的形式记录并保存在bin_log文件中
      应用场景:
        数据恢复:
          概述: 如果MYSQL数据库意外停止，可以通过二进制日志文件来查看用户执行了哪些操作，对数据库服务器文件做了哪些修改，然后根据二进制日志文件中的记录来恢复数据库服务器。
          使用: "
            #利用bin_log进行数据恢复
            SHOW BINLOG EVENTS IN 'binlog-xxx.000006'

            #恢复语句
            mysqlbinlog --no-defaults --start-position=219 --stop-position=417 --database=testDB /var/lib/mysql/binlog-xxx.000006 | mysql -uroot -p123456 -v testDB
          "
        数据复制: 由于日志的延续性和时效性，master把它的二进制日志传递给了slaves来达到一个主从数据一致的目的。
      binlog中的日志格式:
        概述:
          - SHOW  VARIABLES LIKE '%binlog_format%'
        STATEMENT:
          概述:
            - 记录整条SQL语句，binlog中的事件少，但是容易出现数据不一致(insert into t1 values(2,2,NOW()))
          优点:
            - 不需要记录每一行的变化，减少binlog日志量，文件较小
            - binlog中包含了所有数据库更改信息，可以根据来审核数据库的安全等情况
            - binlog可以用于实时的还原，而不仅仅用于复制
            - 主从版本可以不一样，从服务器版本可以比主服务器版本高
          缺点:
            - 不是所有的写操作语句都能被复制，尤其是包含不确定不确定操作的使用，例如SQL语句中包含函数(UUID()、NOW()、SYSDATE())
            - 写操作语句会比ROW产生更多的行级锁
            - 如果没有索引的情况下，写操作可能会全表扫描，从而产生很多行级X锁
            - 对于有AUTO_INCREMENT字段的InnoDB表而言，INSERT语句会阻塞其它的INSERT语句
            - 对于一些复杂的语句，在从服务器上的消耗资源情况会更严重，而ROW模式下，只会对那个发生变化的记录产生影响
            - 执行复杂语句如果出错的话，会消耗更多资源
            - 数据表必须和主服务器保持一致才行，否则可能会导致复制出错
        ROW(默认格式):
          概述:
            - 具体的值以及偏移量以事件的方式记录到binlog日志中，日志量大，但是数据一致性可靠
          优点:
            - 任何情况都可以被复制，这对复制来说是最安全可靠的(不会因为procedure、function、trigger的调用而导致数据不一致)
            - 多数情况下，从服务器上的表如何有主键的话，复制就会快了很多
            - 复制以下几种语句时行锁更少(INSERT...SELECT、INSERT包含AUTO_INCREMENT字段、没有附带条件、没有修改很多记录的UPDATE或DELETE语句)
            - 执行DML操作时锁更少
            - 从服务器上采用多线程来执行复制成为可能
          缺点:
            - binlog日志量大
            - 复杂的回滚时binlog中会包含大量的数据(而STATEMENT仅仅需要SQL语句即可)
            - 主服务器上执行UPDATE语句时，所有发生变化的记录都会写到binlog中，而STATEMENT模式只会写一次，这会导致频繁发生binlog的并发问题(binglog中也会有读写上锁的情况)
            - 无法从binlog中看到都复制了些什么语句(不能清晰的看到做了什么操作，不利于程序员观察日志)
        MIXED:
          概述:
            - 它是STATEMENT和ROW混合体，具体悬着哪种方式记录由服务器决定。
            - 在MIXED模式下，一般的语句修改使用STATEMENT格式保存binlog。如果出现函数，STATEMENT无法完成主从复制的操作，则采用ROW格式保存binlog
            - MYSQL会根据执行的每一条具体的SQL语句来区分对待记录的日志形式，也就是在STATEMENT和ROW之间选择一种。
      使用: "
        SHOW  VARIABLES LIKE '%log_bin%'

        	#sql_log_bin，此参数为session级别的系统变量，支持DML、DDL操作写到bin_log日志文件中
        		SET SESSION sql_log_bin = OFF #临时性关闭DML、DDL操作写到bin_log日志文件中

        	#log_bin_basename，bin_log日志文件存放的路径（binlog.000005，binlog.000006，binlog.000007，binlog.000008...）

        	#log_bin_index，bin_log索引文件，这个文件管理了所有的bin_log文件的目录

        	#log_bin_trust_function_creators，默认为关闭，表示不信任函数，防止从机做同步的时候出现数据不一致，例如主INSERT INTO t1(id,time) VALUES(1,NOW())，此时主从的NOW会不一样

        	#log_bin，5.7默认为关闭，8.0默认为开启，需要通过 my.cnf方式进行修改
        		#开启bin_log日志，在my.cnf中配置
        		#log_bin=binlog-name # 建议分开存储，避免磁盘出问题导致文件无法恢复log_bin=/home/logs/binlog-xxx
        		#server_id=1 如果当前server_id不存在则需要配置，否则开启bin_log失败



        SHOW  VARIABLES LIKE '%binlog%'

        	#binlog_expire_logs_seconds，bin_log日志过期时间，默认为12小时

        	#max_binlog_size，bin_log单个文件的最大字节，默认为1GB


        #查看目前所有的bin_log日志文件，以及大小，MYSQL8.0还支持查看是否加密过
        SHOW BINARY LOGS

        #通过文件删除，删除的是指定文件之前的文件
          PURGE [MASTER | BINARY] LOGS TO 'binlog-xxx.000007'
        #通过指定时间删除
          PURGE [MASTER | BINARY] LOGS BEFORE '20220105，可以通过mysqlbinlog命令查看日志时间戳在做转换'
        #重置bin_log文件(删除所有文件，并生成一个000001开始的文件，谨慎操作)
          RESET MASTER

        在命令行执行，此命令可以使很多种日志文件重新生成，比如慢查询日志....
        mysqladmin -uroot -p123456 flush-logs  或者 flush logs;

        #查看binlog日志
        	#方式1
        		#在命令行中查看bin_log日志文件里面的伪SQL
        		#mysqlbinlog --no-defaults -v --base64-output=DECODE-ROWS '/var/lib/mysql/binlog-xxx.000006' | tail -20
        	#方式2
        		#SHOW BINLOG EVENTS IN 'binlog-xxx.000006'
      "
    中继日志(relay log):
      - 用于主从架构中，从服务器用来存放主服务器二进制日志的一个中间文件，从服务器通过读取中级日志来同步主服务器上的操作。
      - 中继日志只在从服务器上存在。它的文件格式以及序号都bin log一样，只是文件名不一样。
      - 中继日志与bin log日志格式相同，所以也可以用mysqlbinlog工具进行查看。
      - SHOW VARIABLES LIKE '%relay%'
    数据定义语句日志:
      - 记录数据定义语句执行的元数据操作。
  缺点:
    - 日志功能会降低MYSQL数据库的性能。
    - 日志会占用大量的磁盘空间。
主从复制篇:
  概述:
    - 主从复制可以实现读写分离，利用主服务器完成写操作，利用从服务器完成读操作
    - 主从复制可以实现数据备份，利用从服务器同步主服务器上的数据(relay log备份bin log)
    - 主从复制可以实现高可用性，双主模式，一台服务器做主机，一台服务器做备机，一旦主机宕机，备机可以立马做响应
    - 主从复制原理，从库会从主库读取binlog进行数据同步
    - 设置延迟备库，在从库上操作CHANGE MASTER TO MASTER_DELAY = N 单位秒
  主从复制3个线程:
    二进制日志转存线程: "
      二进制日志转存线程(Binlog Dump Thread)是一个主库线程，当从库线程连接的时候，主库可以将二进制日志发送给从库，
      当主库读取binlog事件的时候，会在binlog上加锁(防止读写并发)，读完之后，在将所释放掉。
    "
    从库IO线程: "
      从库IO线程会连接到主库，向主库发送请求binlog，这时从库的IO线程就可以读取到主库的二进制日志转存线程发送的binlog更新部分，
      并且拷贝到本地的中继日志中(relay log)
    "
    从库SQL线程: "
      从库SQL线程会读取从库的中继日志(relay log)，并且执行日志中的事件，将从库中的数据做更新(保持与主库数据同步)
    "
  主从复制总结: "
    步骤1，master将写操作以事件的形式记录到binlog中，这些记录叫做二进制日志时间
    步骤2，slave将master的binlog中的时间拷贝到它的relay log中
    步骤3，slave重做中继日志中的事件，将DML DDL的改变用到自己的数据库中。MYSQL复制是异步的且串行化的，而且重启后从接入点开始复制。
  "
  主从复制使用: "
    #注意事项
     #要么主从都有相同数据库，在去搭建主从复制(因为DML、DDL都会以事件的方式写入bin_log)
     #要么主从都没有相同数据库，在去搭建主从复制(因为DML、DDL都会以事件的方式写入bin_log)

    #主从复制
    #master配置
    	#查看命令
    		SHOW VARIABLES LIKE '%log_bin%'
    		SHOW VARIABLES LIKE '%binlog%'
    	#如果是克隆，可能存在相同的数据库UUID，需要做更改，更改后重启即可
    		#cat /var/lib/mysql/auto.cnf
    	#my.cnf中的mysqld中必选参数
    		#必选参数
    			server_id = 1 #服务器唯一ID

    			log_bin = binlog-xxx #表示启用binlog并且设置文件名，默认在数据目录下，可以配置成绝对路径

    		#可选参数
    			read-only = 0 #0表示读写(默认)，1表示只读

    			binlog_expire_logs_seconds = 6000 #设置日志文件保留的时长，单位秒

    			max_binlog_size = 200M #单个binlog文件大小，默认为1GB

    			binlog-ignore-db = testdb #设置不需要同步的数据库，多个复制即可

    			binlog-do-db = db1 #设置需要同步的数据库，多个复制即可，默认全部记录

    			binlog_format = STATEMENT #设置binlog格式(ROW默认、STATEMENT、MIXED)
    	#建立可访问的账户并授权
    		#MYSQL5.7
    			GRANT REPLICATION SLAVE ON *.* TO 'test'@'%' IDENTIFIED BY '123456' #授予权限，并且修改密码(如果用户不存在，则会创建用户，并且设置密码)
    			FLUSH PRIVILEGES;
    		#MYSQL8.0
    			CREATE USER 'test'@'%' IDENTIFIED BY '123456' #创建用户
    			GRANT REPLICATION SLAVE ON *.* TO 'test'@'%'
    			ALTER USER 'test'@'%' IDENTIFIED WITH mysql_native_password BY '123456' #MYSQL8.0有模块密码加密的原因
    			FLUSH PRIVILEGES;

    #slave配置，SHOW VARIABLES LIKE '%relay%'
    	#查看命令
    		SHOW VARIABLES LIKE '%relay%'
    	#my.cnf中的mysqld中必选参数
    		#必选参数
    			server_id = 2 #服务器唯一ID
    		#可选参数
    			relay-log = mysql-relay #表示启用relaylog并且设置文件名，默认在数据目录下，可以配置成绝对路径


    #--------------------------------------------------------------------------------------#
    #当上面配置已经完成时
    	#master操作
    		SHOW MASTER STATUS #在master中记录file字段的值(binlog-xxx.000007)和Position的值(1404)，此时master不能在动了
    	#slave操作
    		#1.先检查之前机器是否有开启过中继日志(relay log)
    			#如果有
    				STOP SLAVE #停止
    				RESET SLAVE #清除之前的中继日志(relay log)，并重新启用新的relay log文件
    				CHANGE MASTER TO MASTER_HOST='192.168.0.201',MASTER_USER='test',MASTER_PASSWORD='123456',MASTER_LOG_FILE='binlog-xxx.000007',MASTER_LOG_POS=1404
    				START SLAVE #启动
    			#如果没有
    				CHANGE MASTER TO MASTER_HOST='192.168.0.201',MASTER_USER='test',MASTER_PASSWORD='123456',MASTER_LOG_FILE='binlog-xxx.000007',MASTER_LOG_POS=1404
    				START SLAVE #启动
    		#2.查看savle是否与master同步成功
    			SHOW SLAVE STATUS # Slave_IO_Running: Yes 并且 Slave_SQL_Running: Yes 证明成功

  "
  缺点: 主从复制的最大的问题就是【同步延迟】
备份与恢复篇:
  概述:
    - 在做恢复时，需要保证数据的主版本号一样(比如，mysql5.7.1可以对应5.7.1、5.7.2、5.7.3、5.7.4)
    - 逻辑备份与逻辑恢复适合InnoDB表
    - 物理备份与物理恢复适合MYISAM表
  逻辑备份与逻辑恢复:
    概述: 适用于各种场景
    使用: "
        #逻辑备份

            #备份一个数据库包括，存储过程和存储函数[--routines | -R]以及事件[--events | -E]
                mysqldump -uroot -p123456 -R -E db1 > ./test.sql

            #备份一个数据库
                mysqldump -uroot -p123456 db1 > ./test.sql


            #备份全部数据库
                #方式1
                    mysqldump -uroot -p123456 -A > ./test.sql
                #方式2
                    mysqldump -uroot -p123456 --all-databases > ./test.sql

            #备份部分数据库
                #方式1
                    mysqldump -uroot -p123456 -B db1 db2 db3 > ./test.sql
                #方式2
                    mysqldump -uroot -p123456 --databases db1 db2 db3 > ./test.sql




            #备份一个数据库中的部分表
                 mysqldump -uroot -p123456 db1 t1 t2 > ./test.sql


            #被一个表中的部分数据，注意where=''这里不能有空格
                mysqldump -uroot -p123456 db1 t1 --where=' id = 1 ' > ./test.sql


            #排除数据库的部分表
                mysqldump -uroot -p123456 db1 --ignore-table=db1.t1 --ignore-table=db1.t2 > ./test.sql


            #只备份表结构，不要数据
                #方式1
                    mysqldump -uroot -p123456 db1 -d > ./test.sql
                #方式2
                    mysqldump -uroot -p123456 db1 --no-data > ./test.sql

            #只备份数据，不要表结构
                #方式1
                    mysqldump -uroot -p123456 db1 -t > ./test.sql
                #方式2
                    mysqldump -uroot -p123456 db1 --no-create-info > ./test.sql


        #逻辑恢复

            #备份恢复
                #方式1
                    mysql -uroot -p123456 < ./test.sql
                #方式2
                    mysql -uroot -p123456 db1 < ./test.sql
                #方式3(需要登录mysql才能执行的命令)
                    source /root/test.sql


            #从全量备份中提取单库做恢复（全量备份里面会包含创建数据库语句，以及use db1语句，所以这里不需要指定数据库）
                #提起某一个数据库
                    sed -n '/^-- Current Database: `db1`/,/^-- Current Database: `/p' ./test.sql > ./extract-test.sql
                #恢复
                    mysql -uroot -p123456 < ./extract-test.sql

            #从单库备份中恢复部分表（单库备份里面不会包含创建数据库语句，以及use db1语句，所以这里不需要指定数据库）
                #提取表结构
                    cat ./test.sql | sed -e '/./{H;$!d;}' -e 'x;/CREATE TABLE `t1`/!d;q' > /root/structure-test.sql
                #提取数据
                    cat ./test.sql | grep --ignore-case 'insert into `class`' > /root/data-test.sql
                #恢复
                    source /root/structure-test.sql
                    source /root/data-test.sql

      "
    优点: 兼容性高、灵活方便、可跨版本
    缺点: 备份恢复时间长
  物理备份与物理恢复:
    概述: 大数量下的整体备份、恢复、迁移
    使用: "
      #物理备份
          #1.先加全局锁，防止数据不一致
              FLUSH TABLES WITH READ LOCK;
          #2.拷贝某个数据到一个备份目录
              cp -R ./mysql/data/db1 ./backup/
          #3.解开全局锁
              UNLOCK TABLES;

      #物理恢复
          #1.拷贝备份的文件到数据库目录下
              cp -R ./backup/db1	./mysql/data/
          #2.修改权限为mysql用户
              chown -R mysql:mysql ./mysql/data/db1
          #3.重启mysql服务器
              docker restart a54e855addcf
    "
    优点: 迁移速度快
    缺点: 需要停机，不灵活，可能有位置错误
  表的导入与导出:
    导出:
      方式1: "
        SHOW GLOBAL VARIABLES LIKE '%secure_file_priv%'

        #在my.cnf文件mysqld中修改
          secure_file_priv = empty #表示不限制文件生成的位置，这是不安全的设置
          secure_file_priv = '/var/lib/mysql-files/' #限制指定的位置输出
          secure_file_priv = NULL #禁止使用SELECT ... INTO OUTFILE方式

        #方式1
          SELECT * FROM t1 WHERE id = 1 INTO OUTFILE '/var/lib/mysql-files/test.txt'  #导出
          LOAD DATA INFILE '/var/lib/mysql-files/test.txt ' INTO TABLE t1  #导入

          SELECT * FROM t1 WHERE id = 1 INTO OUTFILE '/var/lib/mysql-files/test.txt' FIELDS TERMINATED BY ',' ENCLOSED BY '\"' #导出
          LOAD DATA INFILE '/var/lib/mysql-files/test.txt ' INTO TABLE t1 FIELDS TERMINATED BY ',' ENCLOSED BY '\"' #导入

        #方式2
          mysqldump -uroot -p123456 -T '/var/lib/mysql-files/' db1 t1 #导出
          mysqlimport -uroot -p123456 db1 '/var/lib/mysql-files/t1.txt' #导入，此方式需要根据文件名来找到对应的表名

          mysqldump -uroot -p123456 -T '/var/lib/mysql-files/' db1 t1 --fields-terminated-by=',' --fields-optionally-enclosed-by='\"'
          mysqlimport -uroot -p123456 db1 '/var/lib/mysql-files/t1.txt' --fields-terminated-by=',' --fields-optionally-enclosed-by='\"' #导入，此方式需要根据文件名来找到对应的表名
      "
      方式2: "
        #普通文本
        mysql -uroot -p123456 --execute='SELECT * FROM t1 WHERE id = 1' db1 > '/text.txt'
        mysql -uroot -p123456 --vertical --execute='SELECT * FROM t1 WHERE id = 1' db1 > '/text.txt'

        #xml格式
        mysql -uroot -p123456 --xml  --execute='SELECT * FROM t1 WHERE id = 1' aa > '/text1.xml'

        #html格式
        mysql -uroot -p123456 --html  --execute='SELECT * FROM t1 WHERE id = 1' aa > '/text1.html'
      "
  误操作建议:
    方案1: "
      建议打开安全模式，把sql_safe_updates参数设置为on，强制要求加where条件且where后需要是索引字段，否则必须使用limit。2者都不用就会报错
    "
    方案2: "
      误操作不小心drop table或者truncate table了

      可以考虑使用全量备份+增量日志(bin log)结合恢复
        1.新建立一个临时库，测试
        2.取最近一次全量备份，假设设置数据库是一天一备份，最近备份数据是当天凌晨2点
        3.去除凌晨2点之后的bin log日志
        4.剔除误删除数据的语句外，其它语句全部应用到临时库
        5.测试完毕之后，可以恢复到主库
    "


